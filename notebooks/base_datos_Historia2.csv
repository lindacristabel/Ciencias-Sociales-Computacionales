,Category,Namespace,Title,Summary,Content
0,"Category:Origins (id: 29739395, ns: 14)",0,Big Bang,"The Big Bang is a physical theory that describes how the universe expanded from an initial state of high density and temperature. It was first proposed in 1931 by Roman Catholic priest and physicist Georges Lemaître when he suggested the universe emerged from a ""primeval atom"". Various cosmological models of the Big Bang explain the evolution of the observable universe from the earliest known periods through its subsequent large-scale form. These models offer a comprehensive explanation for a broad range of observed phenomena, including the abundance of light elements, the cosmic microwave background (CMB) radiation, and large-scale structure. The overall uniformity of the universe, known as the flatness problem, is explained through cosmic inflation: a sudden and very rapid expansion of space during the earliest moments. However, physics currently lacks a widely accepted theory of quantum gravity that can successfully model the earliest conditions of the Big Bang.
Crucially, these models are compatible with the Hubble–Lemaître law—the observation that the farther away a galaxy is, the faster it is moving away from Earth. Extrapolating this cosmic expansion backwards in time using the known laws of physics, the models describe an increasingly concentrated cosmos preceded by a singularity in which space and time lose meaning (typically named ""the Big Bang singularity""). In 1964 the CMB was discovered, which convinced many cosmologists that the competing steady-state model of cosmic evolution was falsified, since the Big Bang models predict a uniform background radiation caused by high temperatures and densities in the distant past. A wide range of empirical evidence strongly favors the Big Bang event, which is now essentially universally accepted. Detailed measurements of the expansion rate of the universe place the Big Bang singularity at an estimated 13.787±0.020 billion years ago, which is considered the age of the universe.
There remain aspects of the observed universe that are not yet adequately explained by the Big Bang models. After its initial expansion, the universe cooled sufficiently to allow the formation of subatomic particles, and later atoms. The unequal abundances of matter and antimatter that allowed this to occur is an unexplained effect known as baryon asymmetry. These primordial elements—mostly hydrogen, with some helium and lithium—later coalesced through gravity, forming early stars and galaxies. Astronomers observe the gravitational effects of an unknown dark matter surrounding galaxies. Most of the gravitational potential in the universe seems to be in this form, and the Big Bang models and various observations indicate that this excess gravitational potential is not created by baryonic matter, such as normal atoms. Measurements of the redshifts of supernovae indicate that the expansion of the universe is accelerating, an observation attributed to an unexplained phenomenon known as dark energy.","[Section: Features of the models (1):
The Big Bang models offer a comprehensive explanation for a broad range of observed phenomena, including the abundances of the light elements, the CMB, large-scale structure, and Hubble's law. The models depend on two major assumptions: the universality of physical laws and the cosmological principle. The universality of physical laws is one of the underlying principles of the theory of relativity. The cosmological principle states that on large scales the universe is homogeneous and isotropic—appearing the same in all directions regardless of location.
These ideas were initially taken as postulates, but later efforts were made to test each of them. For example, the first assumption has been tested by observations showing that the largest possible deviation of the fine-structure constant over much of the age of the universe is of order 10−5. Also, general relativity has passed stringent tests on the scale of the Solar System and binary stars.
The large-scale universe appears isotropic as viewed from Earth. If it is indeed isotropic, the cosmological principle can be derived from the simpler Copernican principle, which states that there is no preferred (or special) observer or vantage point. To this end, the cosmological principle has been confirmed to a level of 10−5 via observations of the temperature of the CMB. At the scale of the CMB horizon, the universe has been measured to be homogeneous with an upper bound on the order of 10% inhomogeneity, as of 1995.
Subsections (2):
Section: Horizons (2):
An important feature of the Big Bang spacetime is the presence of particle horizons. Since the universe has a finite age, and light travels at a finite speed, there may be events in the past whose light has not yet had time to reach earth. This places a limit or a past horizon on the most distant objects that can be observed. Conversely, because space is expanding, and more distant objects are receding ever more quickly, light emitted by us today may never ""catch up"" to very distant objects. This defines a future horizon, which limits the events in the future that we will be able to influence. The presence of either type of horizon depends on the details of the Friedmann–Lemaître–Robertson–Walker metric that describes the expansion of the universe.
Our understanding of the universe back to very early times suggests that there is a past horizon, though in practice our view is also limited by the opacity of the universe at early times. So our view cannot extend further backward in time, though the horizon recedes in space. If the expansion of the universe continues to accelerate, there is a future horizon as well.
Subsections (0):

Section: Thermalization (2):
Some processes in the early universe occurred too slowly, compared to the expansion rate of the universe, to reach approximate thermodynamic equilibrium. Others were fast enough to reach thermalization. The parameter usually used to find out whether a process in the very early universe has reached thermal equilibrium is the ratio between the rate of the process (usually rate of collisions between particles) and the Hubble parameter. The larger the ratio, the more time particles had to thermalize before they were too far away from each other.
Subsections (0):
, Section: Timeline (1):
According to the Big Bang models, the universe at the beginning was very hot and very compact, and since then it has been expanding and cooling.
Subsections (5):
Section: Singularity (2):
In the absence of a perfect cosmological principle, extrapolation of the expansion of the universe backwards in time using general relativity yields an infinite density and temperature at a finite time in the past. This irregular behavior, known as the gravitational singularity, indicates that general relativity is not an adequate description of the laws of physics in this regime. Models based on general relativity alone cannot fully extrapolate toward the singularity. In some proposals, such as the emergent Universe models, the singularity is replaced by another cosmological epoch. A different approach identifies the initial singularity as a singularity predicted by some models of the Big Bang theory to have existed before the Big Bang event.
This primordial singularity is itself sometimes called ""the Big Bang"", but the term can also refer to a more generic early hot, dense phase of the universe. In either case, ""the Big Bang"" as an event is also colloquially referred to as the ""birth"" of our universe since it represents the point in history where the universe can be verified to have entered into a regime where the laws of physics as we understand them (specifically general relativity and the Standard Model of particle physics) work. Based on measurements of the expansion using Type Ia supernovae and measurements of temperature fluctuations in the cosmic microwave background, the time that has passed since that event—known as the ""age of the universe""—is 13.8 billion years.
Despite being extremely dense at this time—far denser than is usually required to form a black hole—the universe did not re-collapse into a singularity. Commonly used calculations and limits for explaining gravitational collapse are usually based upon objects of relatively constant size, such as stars, and do not apply to rapidly expanding space such as the Big Bang. Since the early universe did not immediately collapse into a multitude of black holes, matter at that time must have been very evenly distributed with a negligible density gradient.
Subsections (0):

Section: Inflation and baryogenesis (2):
The earliest phases of the Big Bang are subject to much speculation, given the lack of available data. In the most common models the universe was filled homogeneously and isotropically with a very high energy density and huge temperatures and pressures, and was very rapidly expanding and cooling. The period up to 10−43 seconds into the expansion, the Planck epoch, was a phase in which the four fundamental forces—the electromagnetic force, the strong nuclear force, the weak nuclear force, and the gravitational force, were unified as one. In this stage, the characteristic scale length of the universe was the Planck length, 1.6×10−35 m, and consequently had a temperature of approximately 1032 degrees Celsius. Even the very concept of a particle breaks down in these conditions. A proper understanding of this period awaits the development of a theory of quantum gravity. The Planck epoch was succeeded by the grand unification epoch beginning at 10−43 seconds, where gravitation separated from the other forces as the universe's temperature fell.
At approximately 10−37 seconds into the expansion, a phase transition caused a cosmic inflation, during which the universe grew exponentially, unconstrained by the light speed invariance, and temperatures dropped by a factor of 100,000. This concept is motivated by the flatness problem, where the density of matter and energy is very close to the critical density needed to produce a flat universe. That is, the shape of the universe has no overall geometric curvature due to gravitational influence. Microscopic quantum fluctuations that occurred because of Heisenberg's uncertainty principle were ""frozen in"" by inflation, becoming amplified into the seeds that would later form the large-scale structure of the universe. At a time around 10−36 seconds, the electroweak epoch begins when the strong nuclear force separates from the other forces, with only the electromagnetic force and weak nuclear force remaining unified.
Inflation stopped locally at around 10−33 to 10−32 seconds, with the observable universe's volume having increased by a factor of at least 1078. Reheating followed as the inflaton field decayed, until the universe obtained the temperatures required for the production of a quark–gluon plasma as well as all other elementary particles. Temperatures were so high that the random motions of particles were at relativistic speeds, and particle–antiparticle pairs of all kinds were being continuously created and destroyed in collisions. At some point, an unknown reaction called baryogenesis violated the conservation of baryon number, leading to a very small excess of quarks and leptons over antiquarks and antileptons—of the order of one part in 30 million. This resulted in the predominance of matter over antimatter in the present universe.
Subsections (0):

Section: Cooling (2):
The universe continued to decrease in density and fall in temperature, hence the typical energy of each particle was decreasing. Symmetry-breaking phase transitions put the fundamental forces of physics and the parameters of elementary particles into their present form, with the electromagnetic force and weak nuclear force separating at about 10−12 seconds.
After about 10−11 seconds, the picture becomes less speculative, since particle energies drop to values that can be attained in particle accelerators. At about 10−6 seconds, quarks and gluons combined to form baryons such as protons and neutrons. The small excess of quarks over antiquarks led to a small excess of baryons over antibaryons. The temperature was no longer high enough to create either new proton–antiproton or neutron–antineutron pairs. A mass annihilation immediately followed, leaving just one in 108 of the original matter particles and none of their antiparticles. A similar process happened at about 1 second for electrons and positrons. After these annihilations, the remaining protons, neutrons and electrons were no longer moving relativistically and the energy density of the universe was dominated by photons (with a minor contribution from neutrinos).
A few minutes into the expansion, when the temperature was about a billion kelvin and the density of matter in the universe was comparable to the current density of Earth's atmosphere, neutrons combined with protons to form the universe's deuterium and helium nuclei in a process called Big Bang nucleosynthesis (BBN). Most protons remained uncombined as hydrogen nuclei.
As the universe cooled, the rest energy density of matter came to gravitationally dominate that of the photon radiation. The recombination epoch began after about 379,000 years, when the electrons and nuclei combined into atoms (mostly hydrogen), which were able to emit radiation. This relic radiation, which continued through space largely unimpeded, is known as the cosmic microwave background.
Subsections (0):

Section: Structure formation (2):
After the recombination epoch, the slightly denser regions of the uniformly distributed matter gravitationally attracted nearby matter and thus grew even denser, forming gas clouds, stars, galaxies, and the other astronomical structures observable today. The details of this process depend on the amount and type of matter in the universe. The four possible types of matter are known as cold dark matter (CDM), warm dark matter, hot dark matter, and baryonic matter. The best measurements available, from the Wilkinson Microwave Anisotropy Probe (WMAP), show that the data is well-fit by a Lambda-CDM model in which dark matter is assumed to be cold. (Warm dark matter is ruled out by early reionization.) This CDM is estimated to make up about 23% of the matter/energy of the universe, while baryonic matter makes up about 4.6%.
In an ""extended model"" which includes hot dark matter in the form of neutrinos, then the ""physical baryon density"" 
  
    
      
        
          Ω
          
            b
          
        
        
          h
          
            2
          
        
      
    
    {\displaystyle \Omega _{\text{b}}h^{2}}
  
 is estimated at 0.023. (This is different from the 'baryon density' 
  
    
      
        
          Ω
          
            b
          
        
      
    
    {\displaystyle \Omega _{\text{b}}}
  
 expressed as a fraction of the total matter/energy density, which is about 0.046.) The corresponding cold dark matter density 
  
    
      
        
          Ω
          
            c
          
        
        
          h
          
            2
          
        
      
    
    {\displaystyle \Omega _{\text{c}}h^{2}}
  
 is about 0.11, and the corresponding neutrino density 
  
    
      
        
          Ω
          
            v
          
        
        
          h
          
            2
          
        
      
    
    {\displaystyle \Omega _{\text{v}}h^{2}}
  
 is estimated to be less than 0.0062.
Subsections (0):

Section: Cosmic acceleration (2):
Independent lines of evidence from Type Ia supernovae and the CMB imply that the universe today is dominated by a mysterious form of energy known as dark energy, which appears to homogeneously permeate all of space. Observations suggest that 73% of the total energy density of the present day universe is in this form. When the universe was very young it was likely infused with dark energy, but with everything closer together, gravity predominated, braking the expansion. Eventually, after billions of years of expansion, the declining density of matter relative to the density of dark energy allowed the expansion of the universe to begin to accelerate.
Dark energy in its simplest formulation is modeled by a cosmological constant term in Einstein field equations of general relativity, but its composition and mechanism are unknown. More generally, the details of its equation of state and relationship with the Standard Model of particle physics continue to be investigated both through observation and theory.
All of this cosmic evolution after the inflationary epoch can be rigorously described and modeled by the lambda-CDM model of cosmology, which uses the independent frameworks of quantum mechanics and general relativity. There are no easily testable models that would describe the situation prior to approximately 10−15 seconds. Understanding this earliest of eras in the history of the universe is one of the greatest unsolved problems in physics.
Subsections (0):
, Section: Concept history (1):

Subsections (2):
Section: Etymology (2):
English astronomer Fred Hoyle is credited with coining the term ""Big Bang"" during a talk for a March 1949 BBC Radio broadcast, saying: ""These theories were based on the hypothesis that all the matter in the universe was created in one big bang at a particular time in the remote past."" However, it did not catch on until the 1970s.
It is popularly reported that Hoyle, who favored an alternative ""steady-state"" cosmological model, intended this to be pejorative, but Hoyle explicitly denied this and said it was just a striking image meant to highlight the difference between the two models. Helge Kragh writes that the evidence for the claim that it was meant as a pejorative is ""unconvincing"", and mentions a number of indications that it was not a pejorative.
The term itself has been argued to be a misnomer because it evokes an explosion. The argument is that whereas an explosion suggests expansion into a surrounding space, the Big Bang only describes the intrinsic expansion of the contents of the universe. Another issue pointed out by Santhosh Mathew is that bang implies sound, which is not an important feature of the model. An attempt to find a more suitable alternative was not successful.
Subsections (0):

Section: Development (2):
The Big Bang models developed from observations of the structure of the universe and from theoretical considerations. In 1912, Vesto Slipher measured the first Doppler shift of a ""spiral nebula"" (spiral nebula is the obsolete term for spiral galaxies), and soon discovered that almost all such nebulae were receding from Earth. He did not grasp the cosmological implications of this fact, and indeed at the time it was highly controversial whether or not these nebulae were ""island universes"" outside our Milky Way. Ten years later, Alexander Friedmann, a Russian cosmologist and mathematician, derived the Friedmann equations from the Einstein field equations, showing that the universe might be expanding in contrast to the static universe model advocated by Albert Einstein at that time.
In 1924, American astronomer Edwin Hubble's measurement of the great distance to the nearest spiral nebulae showed that these systems were indeed other galaxies. Starting that same year, Hubble painstakingly developed a series of distance indicators, the forerunner of the cosmic distance ladder, using the 100-inch (2.5 m) Hooker telescope at Mount Wilson Observatory. This allowed him to estimate distances to galaxies whose redshifts had already been measured, mostly by Slipher. In 1929, Hubble discovered a correlation between distance and recessional velocity—now known as Hubble's law.
Independently deriving Friedmann's equations in 1927, Georges Lemaître, a Belgian physicist and Roman Catholic priest, proposed that the recession of the nebulae was due to the expansion of the universe. He inferred the relation that Hubble would later observe, given the cosmological principle. In 1931, Lemaître went further and suggested that the evident expansion of the universe, if projected back in time, meant that the further in the past the smaller the universe was, until at some finite time in the past all the mass of the universe was concentrated into a single point, a ""primeval atom"" where and when the fabric of time and space came into existence.
In the 1920s and 1930s, almost every major cosmologist preferred an eternal steady-state universe, and several complained that the beginning of time implied by the Big Bang imported religious concepts into physics; this objection was later repeated by supporters of the steady-state theory. This perception was enhanced by the fact that the originator of the Big Bang concept, Lemaître, was a Roman Catholic priest. Arthur Eddington agreed with Aristotle that the universe did not have a beginning in time, viz., that matter is eternal. A beginning in time was ""repugnant"" to him. Lemaître, however, disagreed:

If the world has begun with a single quantum, the notions of space and time would altogether fail to have any meaning at the beginning; they would only begin to have a sensible meaning when the original quantum had been divided into a sufficient number of quanta. If this suggestion is correct, the beginning of the world happened a little before the beginning of space and time.
During the 1930s, other ideas were proposed as non-standard cosmologies to explain Hubble's observations, including the Milne model, the oscillatory universe (originally suggested by Friedmann, but advocated by Albert Einstein and Richard C. Tolman) and Fritz Zwicky's tired light hypothesis.
After World War II, two distinct possibilities emerged. One was Fred Hoyle's steady-state model, whereby new matter would be created as the universe seemed to expand. In this model the universe is roughly the same at any point in time. The other was Lemaître's Big Bang theory, advocated and developed by George Gamow, who introduced BBN and whose associates, Ralph Alpher and Robert Herman, predicted the CMB. Ironically, it was Hoyle who coined the phrase that came to be applied to Lemaître's theory, referring to it as ""this big bang idea"" during a BBC Radio broadcast in March 1949. For a while, support was split between these two theories. Eventually, the observational evidence, most notably from radio source counts, began to favor Big Bang over steady state. The discovery and confirmation of the CMB in 1964 secured the Big Bang as the best theory of the origin and evolution of the universe.
In 1968 and 1970, Roger Penrose, Stephen Hawking, and George F. R. Ellis published papers where they showed that mathematical singularities were an inevitable initial condition of relativistic models of the Big Bang. Then, from the 1970s to the 1990s, cosmologists worked on characterizing the features of the Big Bang universe and resolving outstanding problems. In 1981, Alan Guth made a breakthrough in theoretical work on resolving certain outstanding theoretical problems in the Big Bang models with the introduction of an epoch of rapid expansion in the early universe he called ""inflation"". Meanwhile, during these decades, two questions in observational cosmology that generated much discussion and disagreement were over the precise values of the Hubble Constant and the matter-density of the universe (before the discovery of dark energy, thought to be the key predictor for the eventual fate of the universe).
In the mid-1990s, observations of certain globular clusters appeared to indicate that they were about 15 billion years old, which conflicted with most then-current estimates of the age of the universe (and indeed with the age measured today). This issue was later resolved when new computer simulations, which included the effects of mass loss due to stellar winds, indicated a much younger age for globular clusters.
Significant progress in Big Bang cosmology has been made since the late 1990s as a result of advances in telescope technology as well as the analysis of data from satellites such as the Cosmic Background Explorer (COBE), the Hubble Space Telescope and WMAP. Cosmologists now have fairly precise and accurate measurements of many of the parameters of the Big Bang model, and have made the unexpected discovery that the expansion of the universe appears to be accelerating.
Subsections (0):
, Section: Observational evidence (1):
The earliest and most direct observational evidence of the validity of the theory are the expansion of the universe according to Hubble's law (as indicated by the redshifts of galaxies), discovery and measurement of the cosmic microwave background and the relative abundances of light elements produced by Big Bang nucleosynthesis (BBN). More recent evidence includes observations of galaxy formation and evolution, and the distribution of large-scale cosmic structures, These are sometimes called the ""four pillars"" of the Big Bang models.
Precise modern models of the Big Bang appeal to various exotic physical phenomena that have not been observed in terrestrial laboratory experiments or incorporated into the Standard Model of particle physics. Of these features, dark matter is currently the subject of most active laboratory investigations. Remaining issues include the cuspy halo problem and the dwarf galaxy problem of cold dark matter. Dark energy is also an area of intense interest for scientists, but it is not clear whether direct detection of dark energy will be possible. Inflation and baryogenesis remain more speculative features of current Big Bang models. Viable, quantitative explanations for such phenomena are still being sought. These are unsolved problems in physics.
Subsections (7):
Section: Hubble's law and the expansion of the universe (2):
Observations of distant galaxies and quasars show that these objects are redshifted: the light emitted from them has been shifted to longer wavelengths. This can be seen by taking a frequency spectrum of an object and matching the spectroscopic pattern of emission or absorption lines corresponding to atoms of the chemical elements interacting with the light. These redshifts are uniformly isotropic, distributed evenly among the observed objects in all directions. If the redshift is interpreted as a Doppler shift, the recessional velocity of the object can be calculated. For some galaxies, it is possible to estimate distances via the cosmic distance ladder. When the recessional velocities are plotted against these distances, a linear relationship known as Hubble's law is observed:

  
    
      
        v
        =
        
          H
          
            0
          
        
        D
      
    
    {\displaystyle v=H_{0}D}
  

where

  
    
      
        v
      
    
    {\displaystyle v}
  
 is the recessional velocity of the galaxy or other distant object,

  
    
      
        D
      
    
    {\displaystyle D}
  
 is the proper distance to the object, and

  
    
      
        
          H
          
            0
          
        
      
    
    {\displaystyle H_{0}}
  
 is Hubble's constant, measured to be 70.4+1.3−1.4 km/s/Mpc by the WMAP.
Hubble's law implies that the universe is uniformly expanding everywhere. This cosmic expansion was predicted from general relativity by Friedmann in 1922 and Lemaître in 1927, well before Hubble made his 1929 analysis and observations, and it remains the cornerstone of the Big Bang model as developed by Friedmann, Lemaître, Robertson, and Walker.
The theory requires the relation 
  
    
      
        v
        =
        H
        D
      
    
    {\displaystyle v=HD}
  
 to hold at all times, where 
  
    
      
        D
      
    
    {\displaystyle D}
  
 is the proper distance, v is the recessional velocity, and 
  
    
      
        v
      
    
    {\displaystyle v}
  
, 
  
    
      
        H
      
    
    {\displaystyle H}
  
, and 
  
    
      
        D
      
    
    {\displaystyle D}
  
 vary as the universe expands (hence we write 
  
    
      
        
          H
          
            0
          
        
      
    
    {\displaystyle H_{0}}
  
 to denote the present-day Hubble ""constant""). For distances much smaller than the size of the observable universe, the Hubble redshift can be thought of as the Doppler shift corresponding to the recession velocity 
  
    
      
        v
      
    
    {\displaystyle v}
  
. For distances comparable to the size of the observable universe, the attribution of the cosmological redshift becomes more ambiguous, although its interpretation as a kinematic Doppler shift remains the most natural one.
An unexplained discrepancy with the determination of the Hubble constant is known as Hubble tension. Techniques based on observation of the CMB suggest a lower value of this constant compared to the quantity derived from measurements based on the cosmic distance ladder.
Subsections (0):

Section: Cosmic microwave background radiation (2):
In 1964, Arno Penzias and Robert Wilson serendipitously discovered the cosmic background radiation, an omnidirectional signal in the microwave band. Their discovery provided substantial confirmation of the big-bang predictions by Alpher, Herman and Gamow around 1950. Through the 1970s, the radiation was found to be approximately consistent with a blackbody spectrum in all directions; this spectrum has been redshifted by the expansion of the universe, and today corresponds to approximately 2.725 K. This tipped the balance of evidence in favor of the Big Bang model, and Penzias and Wilson were awarded the 1978 Nobel Prize in Physics.
The surface of last scattering corresponding to emission of the CMB occurs shortly after recombination, the epoch when neutral hydrogen becomes stable. Prior to this, the universe comprised a hot dense photon-baryon plasma sea where photons were quickly scattered from free charged particles. Peaking at around 372±14 kyr, the mean free path for a photon becomes long enough to reach the present day and the universe becomes transparent.

In 1989, NASA launched COBE, which made two major advances: in 1990, high-precision spectrum measurements showed that the CMB frequency spectrum is an almost perfect blackbody with no deviations at a level of 1 part in 104, and measured a residual temperature of 2.726 K (more recent measurements have revised this figure down slightly to 2.7255 K); then in 1992, further COBE measurements discovered tiny fluctuations (anisotropies) in the CMB temperature across the sky, at a level of about one part in 105. John C. Mather and George Smoot were awarded the 2006 Nobel Prize in Physics for their leadership in these results.
During the following decade, CMB anisotropies were further investigated by a large number of ground-based and balloon experiments. In 2000–2001, several experiments, most notably BOOMERanG, found the shape of the universe to be spatially almost flat by measuring the typical angular size (the size on the sky) of the anisotropies.
In early 2003, the first results of the Wilkinson Microwave Anisotropy Probe were released, yielding what were at the time the most accurate values for some of the cosmological parameters. The results disproved several specific cosmic inflation models, but are consistent with the inflation theory in general. The Planck space probe was launched in May 2009. Other ground and balloon-based cosmic microwave background experiments are ongoing.
Subsections (0):

Section: Abundance of primordial elements (2):
Using Big Bang models, it is possible to calculate the expected concentration of the isotopes helium-4 (4He), helium-3 (3He), deuterium (2H), and lithium-7 (7Li) in the universe as ratios to the amount of ordinary hydrogen. The relative abundances depend on a single parameter, the ratio of photons to baryons. This value can be calculated independently from the detailed structure of CMB fluctuations. The ratios predicted (by mass, not by abundance) are about 0.25 for 4He:H, about 10−3 for 2H:H, about 10−4 for 3He:H, and about 10−9 for 7Li:H.
The measured abundances all agree at least roughly with those predicted from a single value of the baryon-to-photon ratio. The agreement is excellent for deuterium, close but formally discrepant for 4He, and off by a factor of two for 7Li (this anomaly is known as the cosmological lithium problem); in the latter two cases, there are substantial systematic uncertainties. Nonetheless, the general consistency with abundances predicted by BBN is strong evidence for the Big Bang, as the theory is the only known explanation for the relative abundances of light elements, and it is virtually impossible to ""tune"" the Big Bang to produce much more or less than 20–30% helium. Indeed, there is no obvious reason outside of the Big Bang that, for example, the young universe before star formation, as determined by studying matter supposedly free of stellar nucleosynthesis products, should have more helium than deuterium or more deuterium than 3He, and in constant ratios, too.: 182–185
Subsections (0):

Section: Galactic evolution and distribution (2):
Detailed observations of the morphology and distribution of galaxies and quasars are in agreement with the current Big Bang models. A combination of observations and theory suggest that the first quasars and galaxies formed within a billion years after the Big Bang, and since then, larger structures have been forming, such as galaxy clusters and superclusters.
Populations of stars have been aging and evolving, so that distant galaxies (which are observed as they were in the early universe) appear very different from nearby galaxies (observed in a more recent state). Moreover, galaxies that formed relatively recently appear markedly different from galaxies formed at similar distances but shortly after the Big Bang. These observations are strong arguments against the steady-state model. Observations of star formation, galaxy and quasar distributions and larger structures, agree well with Big Bang simulations of the formation of structure in the universe, and are helping to complete details of the theory.
Subsections (0):

Section: Primordial gas clouds (2):
In 2011, astronomers found what they believe to be pristine clouds of primordial gas by analyzing absorption lines in the spectra of distant quasars. Before this discovery, all other astronomical objects have been observed to contain heavy elements that are formed in stars. Despite being sensitive to carbon, oxygen, and silicon, these three elements were not detected in these two clouds. Since the clouds of gas have no detectable levels of heavy elements, they likely formed in the first few minutes after the Big Bang, during BBN.
Subsections (0):

Section: Other lines of evidence (2):
The age of the universe as estimated from the Hubble expansion and the CMB is now in agreement with other estimates using the ages of the oldest stars, both as measured by applying the theory of stellar evolution to globular clusters and through radiometric dating of individual Population II stars. It is also in agreement with age estimates based on measurements of the expansion using Type Ia supernovae and measurements of temperature fluctuations in the cosmic microwave background. The agreement of independent measurements of this age supports the Lambda-CDM (ΛCDM) model, since the model is used to relate some of the measurements to an age estimate, and all estimates turn agree. Still, some observations of objects from the relatively early universe (in particular quasar APM 08279+5255) raise concern as to whether these objects had enough time to form so early in the ΛCDM model.
The prediction that the CMB temperature was higher in the past has been experimentally supported by observations of very low temperature absorption lines in gas clouds at high redshift. This prediction also implies that the amplitude of the Sunyaev–Zel'dovich effect in clusters of galaxies does not depend directly on redshift. Observations have found this to be roughly true, but this effect depends on cluster properties that do change with cosmic time, making precise measurements difficult.
Subsections (0):

Section: Future observations (2):
Future gravitational-wave observatories might be able to detect primordial gravitational waves, relics of the early universe, up to less than a second after the Big Bang.
Subsections (0):
, Section: Problems and related issues in physics (1):
As with any theory, a number of mysteries and problems have arisen as a result of the development of the Big Bang models. Some of these mysteries and problems have been resolved while others are still outstanding. Proposed solutions to some of the problems in the Big Bang model have revealed new mysteries of their own. For example, the horizon problem, the magnetic monopole problem, and the flatness problem are most commonly resolved with inflation theory, but the details of the inflationary universe are still left unresolved and many, including some founders of the theory, say it has been disproven. What follows are a list of the mysterious aspects of the Big Bang concept still under intense investigation by cosmologists and astrophysicists.
Subsections (6):
Section: Baryon asymmetry (2):
It is not yet understood why the universe has more matter than antimatter. It is generally assumed that when the universe was young and very hot it was in statistical equilibrium and contained equal numbers of baryons and antibaryons. However, observations suggest that the universe, including its most distant parts, is made almost entirely of normal matter, rather than antimatter. A process called baryogenesis was hypothesized to account for the asymmetry. For baryogenesis to occur, the Sakharov conditions must be satisfied. These require that baryon number is not conserved, that C-symmetry and CP-symmetry are violated and that the universe depart from thermodynamic equilibrium. All these conditions occur in the Standard Model, but the effects are not strong enough to explain the present baryon asymmetry.
Subsections (0):

Section: Dark energy (2):
Measurements of the redshift–magnitude relation for type Ia supernovae indicate that the expansion of the universe has been accelerating since the universe was about half its present age. To explain this acceleration, general relativity requires that much of the energy in the universe consists of a component with large negative pressure, dubbed ""dark energy"".
Dark energy, though speculative, solves numerous problems. Measurements of the cosmic microwave background indicate that the universe is very nearly spatially flat, and therefore according to general relativity the universe must have almost exactly the critical density of mass/energy. But the mass density of the universe can be measured from its gravitational clustering, and is found to have only about 30% of the critical density. Since theory suggests that dark energy does not cluster in the usual way it is the best explanation for the ""missing"" energy density. Dark energy also helps to explain two geometrical measures of the overall curvature of the universe, one using the frequency of gravitational lenses, and the other using the characteristic pattern of the large-scale structure--baryon acoustic oscillations--as a cosmic ruler.
Negative pressure is believed to be a property of vacuum energy, but the exact nature and existence of dark energy remains one of the great mysteries of the Big Bang. Results from the WMAP team in 2008 are in accordance with a universe that consists of 73% dark energy, 23% dark matter, 4.6% regular matter and less than 1% neutrinos. According to theory, the energy density in matter decreases with the expansion of the universe, but the dark energy density remains constant (or nearly so) as the universe expands. Therefore, matter made up a larger fraction of the total energy of the universe in the past than it does today, but its fractional contribution will fall in the far future as dark energy becomes even more dominant.
The dark energy component of the universe has been explained by theorists using a variety of competing theories including Einstein's cosmological constant but also extending to more exotic forms of quintessence or other modified gravity schemes. A cosmological constant problem, sometimes called the ""most embarrassing problem in physics"", results from the apparent discrepancy between the measured energy density of dark energy, and the one naively predicted from Planck units.
Subsections (0):

Section: Dark matter (2):
During the 1970s and the 1980s, various observations showed that there is not sufficient visible matter in the universe to account for the apparent strength of gravitational forces within and between galaxies. This led to the idea that up to 90% of the matter in the universe is dark matter that does not emit light or interact with normal baryonic matter. In addition, the assumption that the universe is mostly normal matter led to predictions that were strongly inconsistent with observations. In particular, the universe today is far more lumpy and contains far less deuterium than can be accounted for without dark matter. While dark matter has always been controversial, it is inferred by various observations: the anisotropies in the CMB, galaxy cluster velocity dispersions, large-scale structure distributions, gravitational lensing studies, and X-ray measurements of galaxy clusters.
Indirect evidence for dark matter comes from its gravitational influence on other matter, as no dark matter particles have been observed in laboratories. Many particle physics candidates for dark matter have been proposed, and several projects to detect them directly are underway.
Additionally, there are outstanding problems associated with the currently favored cold dark matter model which include the dwarf galaxy problem and the cuspy halo problem. Alternative theories have been proposed that do not require a large amount of undetected matter, but instead modify the laws of gravity established by Newton and Einstein; yet no alternative theory has been as successful as the cold dark matter proposal in explaining all extant observations.
Subsections (0):

Section: Horizon problem (2):
The horizon problem results from the premise that information cannot travel faster than light. In a universe of finite age this sets a limit—the particle horizon—on the separation of any two regions of space that are in causal contact. The observed isotropy of the CMB is problematic in this regard: if the universe had been dominated by radiation or matter at all times up to the epoch of last scattering, the particle horizon at that time would correspond to about 2 degrees on the sky. There would then be no mechanism to cause wider regions to have the same temperature.: 191–202 
A resolution to this apparent inconsistency is offered by inflation theory in which a homogeneous and isotropic scalar energy field dominates the universe at some very early period (before baryogenesis). During inflation, the universe undergoes exponential expansion, and the particle horizon expands much more rapidly than previously assumed, so that regions presently on opposite sides of the observable universe are well inside each other's particle horizon. The observed isotropy of the CMB then follows from the fact that this larger region was in causal contact before the beginning of inflation.: 180–186 
Heisenberg's uncertainty principle predicts that during the inflationary phase there would be quantum thermal fluctuations, which would be magnified to a cosmic scale. These fluctuations served as the seeds for all the current structures in the universe.: 207  Inflation predicts that the primordial fluctuations are nearly scale invariant and Gaussian, which has been confirmed by measurements of the CMB.: sec 6 
A related issue to the classic horizon problem arises because in most standard cosmological inflation models, inflation ceases well before electroweak symmetry breaking occurs, so inflation should not be able to prevent large-scale discontinuities in the electroweak vacuum since distant parts of the observable universe were causally separate when the electroweak epoch ended.
Subsections (0):

Section: Magnetic monopoles (2):
The magnetic monopole objection was raised in the late 1970s. Grand unified theories (GUTs) predicted topological defects in space that would manifest as magnetic monopoles. These objects would be produced efficiently in the hot early universe, resulting in a density much higher than is consistent with observations, given that no monopoles have been found. This problem is resolved by cosmic inflation, which removes all point defects from the observable universe, in the same way that it drives the geometry to flatness.
Subsections (0):

Section: Flatness problem (2):
The flatness problem (also known as the oldness problem) is an observational problem associated with a FLRW. The universe may have positive, negative, or zero spatial curvature depending on its total energy density. Curvature is negative if its density is less than the critical density; positive if greater; and zero at the critical density, in which case space is said to be flat. Observations indicate the universe is consistent with being flat.
The problem is that any small departure from the critical density grows with time, and yet the universe today remains very close to flat. Given that a natural timescale for departure from flatness might be the Planck time, 10−43 seconds, the fact that the universe has reached neither a heat death nor a Big Crunch after billions of years requires an explanation. For instance, even at the relatively late age of a few minutes (the time of nucleosynthesis), the density of the universe must have been within one part in 1014 of its critical value, or it would not exist as it does today.
Subsections (0):
, Section: Misconceptions (1):
One of the common misconceptions about the Big Bang model is that it fully explains the origin of the universe. However, the Big Bang model does not describe how energy, time, and space were caused, but rather it describes the emergence of the present universe from an ultra-dense and high-temperature initial state. It is misleading to visualize the Big Bang by comparing its size to everyday objects. When the size of the universe at Big Bang is described, it refers to the size of the observable universe, and not the entire universe.
Another common misconception is that the Big Bang must be understood as the expansion of space and not in terms of the contents of space exploding apart. In fact, either description can be accurate. The expansion of space (implied by the FLRW metric) is only a mathematical convention, corresponding to a choice of coordinates on spacetime. There is no generally covariant sense in which space expands.
The recession speeds associated with Hubble's law are not velocities in a relativistic sense (for example, they are not related to the spatial components of 4-velocities). Therefore, it is not remarkable that according to Hubble's law, galaxies farther than the Hubble distance recede faster than the speed of light. Such recession speeds do not correspond to faster-than-light travel.
Many popular accounts attribute the cosmological redshift to the expansion of space. This can be misleading because the expansion of space is only a coordinate choice. The most natural interpretation of the cosmological redshift is that it is a Doppler shift.
Subsections (0):
, Section: Implications (1):
Given current understanding, scientific extrapolations about the future of the universe are only possible for finite durations, albeit for much longer periods than the current age of the universe. Anything beyond that becomes increasingly speculative. Likewise, at present, a proper understanding of the origin of the universe can only be subject to conjecture.
Subsections (3):
Section: Pre–Big Bang cosmology (2):
The Big Bang explains the evolution of the universe from a starting density and temperature that is well beyond humanity's capability to replicate, so extrapolations to the most extreme conditions and earliest times are necessarily more speculative. Lemaître called this initial state the ""primeval atom"" while Gamow called the material ""ylem"". How the initial state of the universe originated is still an open question, but the Big Bang model does constrain some of its characteristics. For example, if specific laws of nature were to come to existence in a random way, inflation models show, some combinations of these are far more probable, partly explaining why our Universe is rather stable. Another possible explanation for the stability of the Universe could be a hypothetical multiverse, which assumes every possible universe to exist, and thinking species could only emerge in those stable enough. A flat universe implies a balance between gravitational potential energy and other energy forms, requiring no additional energy to be created.
The Big Bang theory, built upon the equations of classical general relativity, indicates a singularity at the origin of cosmic time, and such an infinite energy density may be a physical impossibility. However, the physical theories of general relativity and quantum mechanics as currently realized are not applicable before the Planck epoch, and correcting this will require the development of a correct treatment of quantum gravity. Certain quantum gravity treatments, such as the Wheeler–DeWitt equation, imply that time itself could be an emergent property. As such, physics may conclude that time did not exist before the Big Bang.
While it is not known what could have preceded the hot dense state of the early universe or how and why it originated, or even whether such questions are sensible, speculation abounds on the subject of ""cosmogony"".
Some speculative proposals in this regard, each of which entails untested hypotheses, are:

The simplest models, in which the Big Bang was caused by quantum fluctuations. That scenario had very little chance of happening, but, according to the totalitarian principle, even the most improbable event will eventually happen. It took place instantly, in our perspective, due to the absence of perceived time before the Big Bang.
Emergent Universe models, which feature a low-activity past-eternal era before the Big Bang, resembling ancient ideas of a cosmic egg and birth of the world out of primordial chaos.
Models in which the whole of spacetime is finite, including the Hartle–Hawking no-boundary condition. For these cases, the Big Bang does represent the limit of time but without a singularity. In such a case, the universe is self-sufficient.
Brane cosmology models, in which inflation is due to the movement of branes in string theory; the pre-Big Bang model; the ekpyrotic model, in which the Big Bang is the result of a collision between branes; and the cyclic model, a variant of the ekpyrotic model in which collisions occur periodically. In the latter model the Big Bang was preceded by a Big Crunch and the universe cycles from one process to the other.
Eternal inflation, in which universal inflation ends locally here and there in a random fashion, each end-point leading to a bubble universe, expanding from its own big bang.
Proposals in the last two categories see the Big Bang as an event in either a much larger and older universe or in a multiverse.
Subsections (0):

Section: Ultimate fate of the universe (2):
Before observations of dark energy, cosmologists considered two scenarios for the future of the universe. If the mass density of the universe were greater than the critical density, then the universe would reach a maximum size and then begin to collapse. It would become denser and hotter again, ending with a state similar to that in which it started—a Big Crunch.
Alternatively, if the density in the universe were equal to or below the critical density, the expansion would slow down but never stop. Star formation would cease with the consumption of interstellar gas in each galaxy; stars would burn out, leaving white dwarfs, neutron stars, and black holes. Collisions between these would result in mass accumulating into larger and larger black holes. The average temperature of the universe would very gradually asymptotically approach absolute zero—a Big Freeze. Moreover, if protons are unstable, then baryonic matter would disappear, leaving only radiation and black holes. Eventually, black holes would evaporate by emitting Hawking radiation. The entropy of the universe would increase to the point where no organized form of energy could be extracted from it, a scenario known as heat death.
Modern observations of accelerating expansion imply that more and more of the currently visible universe will pass beyond our event horizon and out of contact with us. The eventual result is not known. The ΛCDM model of the universe contains dark energy in the form of a cosmological constant. This theory suggests that only gravitationally bound systems, such as galaxies, will remain together, and they too will be subject to heat death as the universe expands and cools. Other explanations of dark energy, called phantom energy theories, suggest that ultimately galaxy clusters, stars, planets, atoms, nuclei, and matter itself will be torn apart by the ever-increasing expansion in a so-called Big Rip.
Subsections (0):

Section: Religious and philosophical interpretations (2):
As a description of the origin of the universe, the Big Bang has significant bearing on religion and philosophy. As a result, it has become one of the liveliest areas in the discourse between science and religion. Some believe the Big Bang implies a creator, while others argue that Big Bang cosmology makes the notion of a creator superfluous.
Subsections (0):
, Section: See also (1):
Anthropic principle – Hypothesis about sapient life and the universe
Big Bounce – Model for the origin of the universe
Big Crunch – Theoretical scenario for the ultimate fate of the universe
Cold Big Bang – Designation of an absolute zero temperature at the beginning of the Universe
Cosmic Calendar – Method to visualize the chronology of the universe
Cosmogony – Branch of science or a theory concerning the origin of the universe
Eureka: A Prose Poem – Lengthy non-fiction work by American author Edgar Allan Poe, a Big Bang speculation
Future of an expanding universe – Future scenario if the expansion of the universe will continue forever or not
Heat death of the universe – Possible fate of the universe. Also known as the Big Chill and the Big Freeze
Non-standard cosmology – Models of the universe which deviate from then-current scientific consensus
Shape of the universe – Local and global geometry of the universe
Steady-state model – Model of the universe – alternative to the Big Bang model, a discredited theory that denied the Big Bang and posited that the universe always existed
Subsections (0):
, Section: Notes (1):

Subsections (0):
, Section: References (1):

Subsections (1):
Section: Bibliography (2):

Subsections (0):
, Section: Further reading (1):
Alpher, Ralph A.; Herman, Robert (August 1988). ""Reflections on Early Work on 'Big Bang' Cosmology"". Physics Today. 41 (8): 24–34. Bibcode:1988PhT....41h..24A. doi:10.1063/1.881126.
Barrow, John D. (1994). The Origin of the Universe. Science Masters. London: Weidenfeld & Nicolson. ISBN 978-0-297-81497-9. LCCN 94006343. OCLC 490957073.
Davies, Paul (1992). The Mind of God: The Scientific Basis for a Rational World. New York: Simon & Schuster. ISBN 978-0-671-71069-9. LCCN 91028606. OCLC 59940452.
Lineweaver, Charles H.; Davis, Tamara M. (March 2005). ""Misconceptions about the Big Bang"" (PDF). Scientific American. Vol. 292, no. 3. pp. 36–45. Archived (PDF) from the original on 9 October 2019. Retrieved 23 December 2019.
Mather, John C.; Boslough, John (1996). The Very First Light: The True Inside Story of the Scientific Journey Back to the Dawn of the Universe (1st ed.). New York: Basic Books. ISBN 978-0-465-01575-7. LCCN 96010781. OCLC 34357391.
Riordan, Michael; Zajc, William A. (May 2006). ""The First Few Microseconds"" (PDF). Scientific American. Vol. 294, no. 5. pp. 34–41. Bibcode:2006SciAm.294e..34R. doi:10.1038/scientificamerican0506-34a. Archived (PDF) from the original on 30 November 2014.
Singh, Simon (2005) [First U.S. edition published 2004]. Big Bang: The Origin of the Universe (Harper Perennial; illustrated ed.). New York, New York: Harper Perennial. ISBN 978-0007162215.
Weinberg, Steven (1993) [Originally published 1977]. The First Three Minutes: A Modern View of the Origin of the Universe (Updated ed.). New York: Basic Books. ISBN 978-0-465-02437-7. LCCN 93232406. OCLC 488469247. 1st edition is available from the Internet Archive. Retrieved 23 December 2019.
Subsections (0):
, Section: External links (1):

Once Upon a Universe Archived 22 June 2020 at the Wayback Machine – STFC funded project explaining the history of the universe in easy-to-understand language
""Big Bang Cosmology"" – NASA/WMAP Science Team
""The Big Bang"" – NASA Science
""Big Bang, Big Bewilderment"" – Big bang model with animated graphics by Johannes Koelman
Cosmology at Curlie
""The Trouble With ""The Big Bang"""" – A rash of recent articles illustrates a longstanding confusion over the famous term. by Sabine Hossenfelde
Subsections (0):
]"
1,"Category:Origins (id: 29739395, ns: 14)",0,Origin of birds,"The scientific question of within which larger group of animals birds evolved has traditionally been called the ""origin of birds"". The present scientific consensus is that birds are a group of maniraptoran theropod dinosaurs that originated during the Mesozoic Era.
A close relationship between birds and dinosaurs was first proposed in the nineteenth century after the discovery of the primitive bird Archaeopteryx in Germany. Birds and extinct non-avian dinosaurs share many unique skeletal traits. Moreover, fossils of more than thirty species of non-avian dinosaur with preserved feathers have been collected. There are even very small dinosaurs, such as Microraptor and Anchiornis, which have long, vaned arm and leg feathers forming wings. The Jurassic basal avialan Pedopenna also shows these long foot feathers. Paleontologist Lawrence Witmer concluded in 2009 that this evidence is sufficient to demonstrate that avian evolution went through a four-winged stage. Fossil evidence also demonstrates that birds and dinosaurs shared features such as hollow, pneumatized bones, gastroliths in the digestive system, nest-building, and brooding behaviors.
Although the origin of birds has historically been a contentious topic within evolutionary biology, only a few scientists still dispute the dinosaurian origin of birds, suggesting descent from other types of archosaurian reptiles. Within the consensus that supports dinosaurian ancestry, the exact sequence of evolutionary events that gave rise to the early birds within maniraptoran theropods is disputed. The origin of bird flight is a separate but related question for which there are also several proposed answers.","[Section: Research history (1):

Subsections (6):
Section: Huxley, Archaeopteryx and early research (2):
Scientific investigation into the origin of birds began shortly after the 1859 publication of Charles Darwin's On the Origin of Species. In 1860, a fossilized feather was discovered in Germany's Late Jurassic Solnhofen limestone. Christian Erich Hermann von Meyer described this feather as Archaeopteryx lithographica the next year. Richard Owen described a nearly complete skeleton in 1863, recognizing it as a bird despite many features reminiscent of reptiles, including clawed forelimbs and a long, bony tail.
Biologist Thomas Henry Huxley, known as ""Darwin's Bulldog"" for his tenacious support of the new theory of evolution by means of natural selection, almost immediately seized upon Archaeopteryx as a transitional fossil between birds and reptiles. Starting in 1868, and following earlier suggestions by Carl Gegenbaur, and Edward Drinker Cope, Huxley made detailed comparisons of Archaeopteryx with various prehistoric reptiles and found that it was most similar to dinosaurs like Hypsilophodon and Compsognathus. The discovery in the late 1870s of the iconic ""Berlin specimen"" of Archaeopteryx, complete with a set of reptilian teeth, provided further evidence. Like Cope, Huxley proposed an evolutionary relationship between birds and dinosaurs. Although Huxley was opposed by the very influential Owen, his conclusions were accepted by many biologists, including Baron Franz Nopcsa, while others, notably Harry Seeley, argued that the similarities were due to convergent evolution.
Subsections (0):

Section: Heilmann and the thecodont hypothesis (2):
A turning point came in the early twentieth century with the writings of Gerhard Heilmann of Denmark. An artist by trade, Heilmann had a scholarly interest in birds and from 1913 to 1916, expanding on earlier work by Othenio Abel, published the results of his research in several parts, dealing with the anatomy, embryology, behavior, paleontology, and evolution of birds. His work, originally written in Danish as Vor Nuvaerende Viden om Fuglenes Afstamning, was compiled, translated into English, and published in 1926 as The Origin of Birds.

Like Huxley, Heilmann compared Archaeopteryx and other birds to an exhaustive list of prehistoric reptiles, and also came to the conclusion that theropod dinosaurs like Compsognathus were the most similar. However, Heilmann noted that birds had clavicles (collar bones) fused to form a bone called the furcula (""wishbone""), and while clavicles were known in more primitive reptiles, they had not yet been recognized in dinosaurs. Since he was a firm believer in an interpretation of Dollo's law that stated that evolution was not ""reversible"", Heilmann could not accept that clavicles were lost in dinosaurs and re-evolved in birds. He was therefore forced to rule out dinosaurs as bird ancestors and ascribe all of their similarities to convergent evolution. Heilmann stated that bird ancestors would instead be found among the more primitive ""thecodont"" grade of reptiles. Heilmann's extremely thorough approach ensured that his book became a classic in the field, and its conclusions on bird origins, as with most other topics, were accepted by nearly all evolutionary biologists for the next four decades.
Clavicles are relatively delicate bones and therefore in danger of being destroyed or at least damaged beyond recognition. Nevertheless, some fossil theropod clavicles had actually been excavated before Heilmann wrote his book, but these had been misidentified.
The absence of clavicles in dinosaurs became the orthodox view despite the discovery of clavicles in the primitive theropod Segisaurus in 1936. The next report of clavicles in a dinosaur was in a Russian article in 1983.
Contrary to what Heilmann believed, paleontologists now accept that clavicles and in most cases furculae are a standard feature not just of theropods but of saurischian dinosaurs. Up to late 2007 ossified furculae (i.e. made of bone rather than cartilage) have been found in all types of theropods except the most basal ones, Eoraptor and Herrerasaurus. The original report of a furcula in the primitive theropod Segisaurus (1936) was confirmed by a re-examination in 2005. Joined, furcula-like clavicles have also been found in Massospondylus, an Early Jurassic sauropodomorph.
Subsections (0):

Section: Ostrom, Deinonychus, and the dinosaur renaissance (2):
The tide began to turn against the 'thecodont' hypothesis after the 1964 discovery of a new theropod dinosaur in Montana. In 1969, this dinosaur was described and named Deinonychus by John Ostrom of Yale University. The next year, Ostrom redescribed a specimen of Pterodactylus in the Dutch Teylers Museum as another skeleton of Archaeopteryx. The specimen consisted mainly of a single wing and its description made Ostrom aware of the similarities between the wrists of Archaeopteryx and Deinonychus.
In 1972, British paleontologist Alick Walker hypothesized that birds arose not from 'thecodonts' but from crocodile ancestors like Sphenosuchus. Ostrom's work with both theropods and early birds led him to respond with a series of publications in the mid-1970s in which he laid out the many similarities between birds and theropod dinosaurs, resurrecting the ideas first put forth by Huxley over a century before. Ostrom's recognition of the dinosaurian ancestry of birds, along with other new ideas about dinosaur metabolism, activity levels, and parental care, began what is known as the dinosaur renaissance, which began in the 1960s and, according to some, continues to this day.
Ostrom's revelations also coincided with the increasing adoption of phylogenetic systematics (cladistics), which began in the 1960s with the work of Willi Hennig. Cladistics is an exact method of arranging species based strictly on their evolutionary relationships, which are calculated by determining the evolutionary tree implying the least number of changes in their anatomical characteristics. In the 1980s, cladistic methodology was applied to dinosaur phylogeny for the first time by Jacques Gauthier and others, showing unequivocally that birds were a derived group of theropod dinosaurs. Early analyses suggested that dromaeosaurid theropods like Deinonychus were particularly closely related to birds, a result that has been corroborated many times since.
Subsections (0):

Section: Feathered dinosaurs in China (2):
The early 1990s saw the discovery of spectacularly preserved bird fossils in several Early Cretaceous geological formations in the northeastern Chinese province of Liaoning. In 1996, Chinese paleontologists described Sinosauropteryx as a new genus of bird from the Yixian Formation, but this animal was quickly recognized as a more basal theropod dinosaur closely related to Compsognathus. Surprisingly, its body was covered by long filamentous structures. These were dubbed 'protofeathers' and considered homologous with the more advanced feathers of birds, although some scientists disagree with this assessment. Chinese and North American scientists described Caudipteryx and Protarchaeopteryx soon after. Based on skeletal features, these animals were non-avian dinosaurs, but their remains bore fully formed feathers closely resembling those of birds. ""Archaeoraptor"", described without peer review in a 1999 issue of National Geographic, turned out to be a smuggled forgery, but authentic remains continue to pour out of the Yixian, both legally and illegally. Feathers or ""protofeathers"" have been found on a wide variety of theropods in the Yixian. The morphological gap between non-avian theropods and birds is further closed by the discoveries of extremely bird-like non-avian dinosaurs, as well as non-avian dinosaur-like basal birds.
Subsections (0):

Section: Digit homology (2):
There is a debate between embryologists and paleontologists whether the hands of theropod dinosaurs and birds are essentially different, based on phalangeal counts—a count of the number of phalanges (finger bones) in the hand.
Embryologists and some paleontologists who oppose the bird-dinosaur link have long numbered the digits of birds II-III-IV on the basis of multiple studies of the development in the egg. This is based on the fact that in most amniotes, the first digit to form in a 5-fingered hand is digit IV, which develops a primary axis. Therefore, embryologists have identified the primary axis in birds as digit IV, and the surviving digits as II-III-IV. The fossils of advanced theropod (Tetanurae) hands appear to have the digits I-II-III (some genera within Avetheropoda also have a reduced digit IV). 
If this is true, then the II-III-IV development of digits in birds is an indication against theropod (dinosaur) ancestry. However, with no ontogenical (developmental) basis to definitively state which digits are which on a theropod hand (because no non-avian theropods can be observed growing and developing today), the labelling of the theropod hand is not absolutely conclusive.
Paleontologists have traditionally identified avian digits as I-II-III. They argue that the digits of birds number I-II-III, just as those of theropod dinosaurs do, by the conserved phalangeal formula. The phalangeal count for archosaurs is 2-3-4-5-3; many archosaur lineages have a reduced number of digits, but have the same phalangeal formula in the digits that remain. In other words, paleontologists assert that archosaurs of different lineages tend to lose the same digits when digit loss occurs, from the outside to the inside. The three digits of dromaeosaurs and Archaeopteryx have the same phalangeal formula of I-II-III as digits I-II-III of basal archosaurs. Therefore, the lost digits would be V and IV. If this is true, then modern birds would also possess digits I-II-III. 
Also, one 1999 publication proposed a frame-shift in the digits of the theropod line leading to birds (thus making digit I into digit II, II to III, and so forth).
However, such frame shifts are rare in amniotes and—to be consistent with the theropod origin of birds—would have had to occur solely in the bird-theropod lineage forelimbs and not the hindlimbs (a condition unknown in any animal).
This is called Lateral Digit Reduction (LDR) versus Bilateral Digit Reduction (BDR) (see also Limusaurus).
A small minority, known by the acronym BAND (Birds Are Not Dinosaurs), including ornithologists Alan Feduccia and Larry Martin, continues to assert that birds are more closely related to earlier reptiles, such as Longisquama or Euparkeria, than to dinosaurs. Embryological studies of bird developmental biology have raised questions about digit homology in bird and dinosaur forelimbs. However, due to the cogent evidence provided by comparative anatomy and phylogenetics, as well as the dramatic feathered dinosaur fossils from China, the idea that birds are derived dinosaurs, first championed by Huxley and later by Nopcsa and Ostrom, enjoys near-unanimous support among today's paleontologists.
An alternative to the frame-shift hypothesis is the axis-shift. According to this explanation, the primary limb axis in birds runs through digit III instead of IV. This idea is supported by palaeontological observations, which determine the phalangeal formula 2-3-4-1-X for the last common ancestor of ceratosaurs (including Limusaurus) and tetanurans (including the tridactyl forms with the phalangeal formula 2-3-4-X-X).
Some later embryological data support the identification of bird digits as I, II, III as in their theropod ancestors.
Subsections (0):

Section: Thermogenic muscle hypothesis (2):
A 2011 publication suggested that selection for the expansion of skeletal muscle, rather than the evolution of flight, was the driving force for the emergence of this clade. Muscles became larger in prospectively endothermic saurians, according to this hypothesis, as a response to the loss of the vertebrate mitochondrial uncoupling protein, UCP1. In mammals, UCP1 functions within brown adipose tissue, which is thermogenic to protect newborns against hypothermia. In modern birds, skeletal muscle serves a similar function and is presumed to have done so in their ancestors. In this view, bipedality and other avian skeletal alterations were side effects of muscle hyperplasia, with further evolutionary modifications of the forelimbs, including adaptations for flight or swimming, and vestigiality, being secondary consequences of two-leggedness.
Subsections (0):
, Section: Phylogeny (1):
Archaeopteryx has historically been considered the first bird, or Urvogel. Although newer fossil discoveries filled the gap between theropods and Archaeopteryx, as well as the gap between Archaeopteryx and modern birds, phylogenetic taxonomists, in keeping with tradition, almost always use Archaeopteryx as a specifier to help define Aves. Aves has more rarely been defined as a crown group consisting only of modern birds. Nearly all palaeontologists regard birds as coelurosaurian theropod dinosaurs. Within Coelurosauria, multiple cladistic analyses have found support for a clade named Maniraptora, consisting of therizinosauroids, oviraptorosaurs, troodontids, dromaeosaurids, and birds. Of these, dromaeosaurids and troodontids are usually united in the clade Deinonychosauria, which is a sister group to birds (together forming the node-clade Eumaniraptora) within the stem-clade Paraves.
Other studies have proposed alternative phylogenies, in which certain groups of dinosaurs usually considered non-avian may have evolved from avian ancestors. For example, a 2002 analysis found that oviraptorosaurs were basal avians. Alvarezsaurids, known from Asia and the Americas, have been variously classified as basal maniraptorans, paravians, the sister taxon of ornithomimosaurs, as well as specialized early birds. The genus Rahonavis, originally described as an early bird, has been identified as a non-avian dromaeosaurid in several studies. Dromaeosaurids and troodontids themselves have also been suggested to lie within Aves rather than just outside it.
Subsections (0):
, Section: Features linking birds and dinosaurs (1):
Many anatomical features are shared by birds and other theropod dinosaurs.
Subsections (9):
Section: Feathers (2):
Archaeopteryx, the first good example of a ""feathered dinosaur"", was discovered in 1861. The first specimen was found in the Solnhofen limestone in southern Germany, which is a lagerstätte, a rare and remarkable geological formation known for its superbly detailed fossils. Archaeopteryx is a transitional fossil, with features clearly intermediate between those of non-avian theropod dinosaurs and birds. Discovered just two years after Darwin's seminal Origin of Species, its discovery spurred the nascent debate between proponents of evolutionary biology and creationism. This early bird is so dinosaur-like that, without a clear impression of feathers in the surrounding rock, at least one specimen was mistaken for Compsognathus.

Since the 1990s, a number of additional feathered dinosaurs have been found, providing even stronger evidence of the close relationship between dinosaurs and modern birds. The first of these were initially described as simple filamentous protofeathers, which were reported in dinosaur lineages as primitive as compsognathids and tyrannosauroids. However, feathers indistinguishable from those of modern birds were soon after found in non-avialan dinosaurs as well.
A small minority of researchers have claimed that the simple filamentous ""protofeather"" structures are simply the result of the decomposition of collagen fiber under the dinosaurs' skin or in fins along their backs, and that species with unquestionable feathers, such as oviraptorosaurs and dromaeosaurs are not dinosaurs, but true birds unrelated to dinosaurs. However, a majority of studies have concluded that feathered dinosaurs are in fact dinosaurs, and that the simpler filaments of unquestionable theropods represent simple feathers. Some researchers have demonstrated the presence of color-bearing melanin in the structures—which would be expected in feathers but not collagen fibers. Others have demonstrated, using studies of modern bird decomposition, that even advanced feathers appear filamentous when subjected to the crushing forces experienced during fossilization, and that the supposed ""protofeathers"" may have been more complex than previously thought. Detailed examination of the ""protofeathers"" of Sinosauropteryx prima showed that individual feathers consisted of a central quill (rachis) with thinner barbs branching off from it, similar to but more primitive in structure than modern bird feathers.
The 2022 description of branched feathers in the pterosaur Tupandactylus provides strong evidence that ""pycnofibers"" are not actually a distinct integument unrelated to origin of feathers. The most parsimonious scenario is the presence of feathers in the last common ancestor of pterosaurs and dinosaurs already in the Early Triassic. Tupandactylus's melanosomes indicate visual signalling was an important factor in the evolution of feathers.
Subsections (0):

Section: Skeleton (2):
Because feathers are often associated with birds, feathered dinosaurs are often touted as the ""missing link"" between birds and other dinosaurs. However, the multiple skeletal features also shared by the two groups represent the more important proof for paleontologists.
Comparisons of bird and dinosaur skeletons, as well as cladistic analysis, strengthens the case for the link, particularly for a branch of theropods called Maniraptora. Skeletal similarities include the skull, tooth build, neck, uncinate processes on the ribs, an open hip socket, a retroverted long pubis, flexible wrist (semi-lunate carpal), long arms, three-fingered hand, general pectoral girdle, shoulder blade, furcula, and breast bones. Almost all skeletal traits of Archaeopteryx can be found in non-avian maniraptorans.
A study comparing embryonic, juvenile and adult archosaur skulls concluded that bird skulls are derived from those of theropod dinosaurs by progenesis, a type of paedomorphic heterochrony, which resulted in retention of juvenile characteristics of their ancestors.
Subsections (0):

Section: Lungs (2):
Large meat-eating dinosaurs had a complex system of air sacs similar to those found in modern birds, according to an investigation led by Patrick M. O'Connor of Ohio University. In theropod dinosaurs (carnivores that walked on two legs and had birdlike feet) flexible soft tissue air sacs likely pumped air through the stiff lungs, as is the case in birds. ""What was once formally considered unique to birds was present in some form in the ancestors of birds"", O'Connor said.
Subsections (0):

Section: Heart (2):
Computed tomography (CT) scans conducted in 2000 of the chest cavity of a specimen of the ornithopod Thescelosaurus found the apparent remnants of a complex four-chambered heart, much like those found in today's mammals and birds. The idea is controversial within the scientific community, criticised for being bad anatomical science or simply wishful thinking, It is also not very surprising as crocodilians also possess four-chambered hearts.
A study published in 2011 applied multiple lines of inquiry to the question of the object's identity, including more advanced CT scanning, histology, X-ray diffraction, X-ray photoelectron spectroscopy, and scanning electron microscopy. From these methods, the authors found that: the object's internal structure does not include chambers but is made up of three unconnected areas of lower density material, and is not comparable to the structure of an ostrich's heart; the ""walls"" are composed of sedimentary minerals not known to be produced in biological systems, such as goethite, feldspar minerals, quartz, and gypsum, as well as some plant fragments; carbon, nitrogen, and phosphorus, chemical elements important to life, were lacking in their samples; and cardiac cellular structures were absent. There was one possible patch with animal cellular structures. The authors found their data supported identification as a concretion of sand from the burial environment, not the heart, with the possibility that isolated areas of tissues were preserved.
The question of how this find reflects metabolic rate and dinosaur internal anatomy is moot, though, regardless of the object's identity. Both modern crocodilians and birds, the closest living relatives of dinosaurs, have four-chambered hearts (albeit modified in crocodilians), so dinosaurs probably had them as well; the structure is not necessarily tied to metabolic rate.
Subsections (0):

Section: Sleeping posture (2):
Fossils of the troodonts Mei and Sinornithoides demonstrate that the dinosaurs slept like certain modern birds, with their heads tucked under their arms. This behavior, which may have helped to keep the head warm, is also characteristic of modern birds.
Subsections (0):

Section: Reproductive biology (2):
When laying eggs, female birds grow a special type of bone in their limbs. This medullary bone forms as a calcium-rich layer inside the hard outer bone, and is used as a calcium source to make eggshells. The presence of endosteally derived bone tissues lining the interior marrow cavities of portions of a Tyrannosaurus rex specimen's hind limb suggested that T. rex used similar reproductive strategies, and revealed that the specimen is female. Further research has found medullary bone in the theropod Allosaurus and ornithopod Tenontosaurus. Because the line of dinosaurs that includes Allosaurus and Tyrannosaurus diverged from the line that led to Tenontosaurus very early in the evolution of dinosaurs, this suggests that dinosaurs in general produced medullary tissue.
Subsections (0):

Section: Brooding and care of young (2):
Several Citipati specimens have been found resting over the eggs in its nest in a position most reminiscent of brooding.
Numerous dinosaur species, for example Maiasaura, have been found in herds mixing both very young and adult individuals, suggesting rich interactions between them.
A dinosaur embryo was found without teeth, which suggests some parental care was required to feed the young dinosaur, possibly the adult dinosaur regurgitated food into the young dinosaur's mouth (see altricial). This behaviour is seen in numerous bird species; parent birds regurgitate food into the hatchling's mouth.
Subsections (0):

Section: Gizzard stones (2):
Both birds and dinosaurs use gizzard stones. These stones are swallowed by animals to aid digestion and break down food and hard fibres once they enter the stomach. When found in association with fossils, gizzard stones are called gastroliths.
Gizzard stones are also found in some fish (mullets, mud shad, and the gillaroo, a type of trout) and in crocodiles.
Subsections (0):

Section: Molecular evidence (2):
On several occasions, the extraction of DNA and proteins from Mesozoic dinosaurs fossils has been claimed, allowing for a comparison with birds. Several proteins have putatively been detected in dinosaur fossils, including hemoglobin. In 2023, beta-protein structures were reported from the feathers of the dinosaur Sinornithosaurus and the early bird Confuciusornis. This confirms that ancient feathers had a composition similar to that of modern birds. Some fossil feathers were reported to have a composition rich in alpha proteins, but fossilization experiments demonstrate that this protein composition is simply an artefact of preservation, because beta-sheet protein structures are readily transformed to alpha-helices during thermal maturation.
In the March 2005 issue of Science, Dr. Mary Higby Schweitzer and her team announced the discovery of flexible material resembling actual soft tissue inside a 68-million-year-old Tyrannosaurus rex leg bone of specimen MOR 1125 from the Hell Creek Formation in Montana. The seven collagen types obtained from the bone fragments, compared to collagen data from living birds (specifically, a chicken), suggest that older theropods and birds are closely related. The soft tissue allowed a molecular comparison of cellular anatomy and protein sequencing of collagen tissue published in 2007, both of which indicated that T. rex and birds are more closely related to each other than either is to Alligator. A second molecular study robustly supported the relationship of birds to dinosaurs, though it did not place birds within Theropoda, as expected. This study utilized eight additional collagen sequences extracted from a femur of the ""mummified"" Brachylophosaurus canadensis specimen MOR 2598, a hadrosaur. However, these results have been very controversial. No other peptides of a Mesozoic age have been reported. In 2008, it was suggested that the presumed soft tissue was in fact a bacterial microfilm. In response, it was argued that these very microfilms protected the soft tissue. Another objection was that the results could have been caused by contamination. In 2015, under more controlled conditions safeguarding against contamination, the peptides were still identified. In 2017, a study found that a peptide was present in the bone of the modern ostrich that was identical to that found in the Tyrannosaurus and Brachylophosaurus specimens, highlighting the danger of a cross-contamination.
The successful extraction of ancient DNA from dinosaur fossils has been reported on two separate occasions, but upon further inspection and peer review, neither of these reports could be confirmed.
Subsections (0):
, Section: Origin of bird flight (1):
Debates about the origin of bird flight are almost as old as the idea that birds evolved from dinosaurs, which arose soon after the discovery of Archaeopteryx in 1862. Two theories have dominated most of the discussion since then: the cursorial (""from the ground up"") theory proposes that birds evolved from small, fast predators that ran on the ground; the arboreal (""from the trees down"") theory proposes that powered flight evolved from unpowered gliding by arboreal (tree-climbing) animals. A more recent theory, ""wing-assisted incline running"" (WAIR), is a variant of the cursorial theory and proposes that wings developed their aerodynamic functions as a result of the need to run quickly up very steep slopes such as trees, which would help small feathered dinosaurs escape from predators.
In March 2018, scientists reported that Archaeopteryx was likely capable of flight, but in a manner substantially different from that of modern birds.
Subsections (5):
Section: Cursorial (""from the ground up"") theory (2):
The cursorial theory of the origin of flight was first proposed by Samuel Wendell Williston, and elaborated upon by Baron Nopcsa. This hypothesis proposes that some fast-running animals with long tails used their arms to keep their balance while running. Modern versions of this theory differ in many details from the Williston-Nopcsa version, mainly as a result of discoveries since Nopcsa's time.
Nopcsa theorized that increasing the surface area of the outstretched arms could have helped small cursorial predators keep their balance, and that the scales of the forearms elongated, evolving into feathers. The feathers could also have been used to trap insects or other prey. Progressively, the animals leapt for longer distances, helped by their evolving wings. Nopcsa also proposed three stages in the evolution of flight. First, animals developed passive flight, in which developing wing structures served as a sort of parachute. Second, they achieved active flight by flapping the wings. He used Archaeopteryx as an example of this second stage. Finally, birds gained the ability to soar.

While some authors had rejected the homology between feathers and scales due to their different proteins, recent studies provide evidence that those structures do share a common origin. However, Nopcsa's theory assumes that feathers evolved as part of the evolution of flight, and recent discoveries show that feathers evolved millions of years before flight.
Feathers are very common in coelurosaurian dinosaurs (including the early tyrannosauroid Dilong). Modern birds are classified as coelurosaurs by nearly all palaeontologists, though not by a few ornithologists. The modern version of the ""from the ground up"" hypothesis argues that birds' ancestors were small, feathered, ground-running predatory dinosaurs (rather like roadrunners in their hunting style) that used their forelimbs for balance while pursuing prey, and that the forelimbs and feathers later evolved in ways that provided gliding and then powered flight. The most widely suggested original functions of feathers include thermal insulation and competitive displays, as in modern birds.
All of the Archaeopteryx fossils come from marine sediments, and it has been suggested that wings may have helped the birds run over water in the manner of the Jesus Christ Lizard (common basilisk).
Most recent opposition to the ""from the ground up"" hypothesis attempt to refute the modern version's assumption that birds are modified coelurosaurian dinosaurs. The criticism is based on embryological analyses that suggest birds' wings are formed from digits 2, 3, and 4, (corresponding to the index, middle, and ring fingers in humans. The first of a bird's three digits forms the alula, which they use to avoid stalling in low-speed flight—for example, when landing). The hands of coelurosaurs, however, are formed by digits 1, 2, and 3 (thumb and first two fingers in humans). However, these embryological analyses were immediately challenged on the embryological grounds that the ""hand"" often develops differently in clades that have lost some digits in the course of their evolution, and that birds' ""hands"" do develop from digits 1, 2, and 3. For more information about this subject, see ""Digit homology"".
Fowler et al. (2011) proposed a model explaining how dromaeosaurids may have hunted. The animal would use its wing as stabilizers while standing on top of its prey eating it alive in the manner of an eagle or a hawk. The authors consider this an important addition to the topic of how flapping movements evolved, arguing they likely precede flight.
Subsections (0):

Section: Wing-assisted incline running (2):
The wing-assisted incline running (WAIR) hypothesis was prompted by observation of young chukar chicks, and proposes that wings developed their aerodynamic functions as a result of the need to run quickly up very steep slopes such as tree trunks, for example to escape from predators. This makes it a specialized type of cursorial (""from the ground up"") theory. Note that in this scenario birds need downforce to give their feet increased grip. But early birds, including Archaeopteryx, lacked the shoulder mechanism by which modern birds' wings produce swift, powerful upstrokes. Since the downforce WAIR depends on is generated by upstrokes, it seems that early birds were incapable of WAIR. Because WAIR is a behavioural trait without osteological specializations, the phylogenetic placement of the flight stroke before the divergence of the Neornithes, the group which contains all extant birds, makes it impossible to determine if WAIR is ancestral to the avian flight stroke or derived from it.
Subsections (0):

Section: Arboreal (""from the trees down"") theory (2):
Most versions of the arboreal hypothesis state that the ancestors of birds were very small dinosaurs that lived in trees, springing from branch to branch. This small dinosaur already had feathers, which were co-opted by evolution to produce longer, stiffer forms that were useful in aerodynamics, eventually producing wings. Wings would have then evolved and become increasingly refined as devices to give the leaper more control, to parachute, to glide, and to fly in stepwise fashion. The arboreal hypothesis also notes that, for arboreal animals, aerodynamics are far more energy efficient, since such animals simply fall to achieve minimum gliding speeds.
Several small dinosaurs from the Jurassic or Early Cretaceous, all with feathers, have been interpreted as possibly having arboreal and/or aerodynamic adaptations. These include Scansoriopteryx, Epidexipteryx, Microraptor, Pedopenna, and Anchiornis. Anchiornis is particularly important to this subject, as it lived at the beginning of the Late Jurassic, long before Archaeopteryx.
Analysis of the proportions of the toe bones of the most primitive birds Archaeopteryx and Confuciusornis, compared to those of living species, suggest that the early species may have lived both on the ground and in trees.
One study suggested that the earliest birds and their immediate ancestors did not climb trees. This study determined that the amount of toe claw curvature of early birds was more like that seen in modern ground-foraging birds than in perching birds.
Subsections (0):

Section: Diminished significance of Archaeopteryx (2):
Archaeopteryx was the first and for a long time the only known feathered Mesozoic animal. As a result, discussion of the evolution of birds and of bird flight centered on Archaeopteryx at least until the mid-1990s.

There has been debate about whether Archaeopteryx could really fly. It appears that Archaeopteryx had the brain structures and inner-ear balance sensors that birds use to control their flight. Archaeopteryx also had a wing feather arrangement like that of modern birds and similarly asymmetrical flight feathers on its wings and tail. But Archaeopteryx lacked the shoulder mechanism by which modern birds' wings produce swift, powerful upstrokes (see diagram above of supracoracoideus pulley); this may mean that it and other early birds were incapable of flapping flight and could only glide.
But the discovery since the early 1990s of many feathered dinosaurs means that Archaeopteryx is no longer the key figure in the evolution of bird flight. Other small feathered coelurosaurs from the Cretaceous and Late Jurassic show possible precursors of avian flight. These include Rahonavis, a ground-runner with a Velociraptor-like raised sickle claw on the second toe, that some paleontologists assume to have been better adapted for flight than Archaeopteryx, Scansoriopteryx, an arboreal dinosaur that may support the ""from the trees down"" theory, and Microraptor, an arboreal dinosaur possibly capable of powered flight but, if so, more like a biplane, as it had well-developed feathers on its legs. As early as 1915, some scientists argued that the evolution of bird flight may have gone through a four-winged (or tetrapteryx) stage.
Hartman et al. (2019) found that, because of how basal flying paravians are phylogenetically distributed, flight most likely evolved five times among paravians instead of only once. Yi, Archaeopteryx, Rahonavis and Microraptor were thus considered examples of convergent evolution instead of precursors of bird flight.
Subsections (0):

Section: Secondary flightlessness in dinosaurs (2):
A minority hypothesis, credited to the books Predatory Dinosaurs of the World (1988) and Dinosaurs of the Air (2002) by scientific illustrator Gregory Paul, suggests that some groups of non-flying carnivorous dinosaurs — especially deinonychosaurs, but perhaps others such as oviraptorosaurs, therizinosaurs, alvarezsaurids and ornithomimosaurs — actually descend from birds or other flighted maniraptorans. Paul also proposed that the ancestors of these groups were more advanced in their flight adaptations than Archaeopteryx. The hypothesis would mean that Archaeopteryx is less closely related to extant birds than these dinosaurs are. In 2016, Paul suggested that omnivoropterygid avialans were closely related to oviraptorosaurs and that jeholornithid avialans were closely related to therizinosaurs; he considered them to not be avians but suggested that they shared a flighted ancestor.
Mayr et al. (2005) analyzed a new, tenth specimen of Archaeopteryx, and concluded that Archaeopteryx was the sister clade to the Deinonychosauria, but that the more advanced bird Confuciusornis was within the Dromaeosauridae. This paper, however, excluded all other birds and thus did not sample their character distributions. The paper was criticized by Corfe and Butler (2006) who found the authors could not support their conclusions statistically. Mayr et al. agreed that the statistical support for the authors' earlier paper was weak but stated that it is also weak for the alternative scenarios.
Most subsequent cladistic analyses, an exception being that of Hartman and colleagues (2019), do not support Paul's hypothesis about the position of Archaeopteryx. Instead, they indicate that Archaeopteryx is closer to birds, within the clade Avialae, than it is to deinonychosaurs or oviraptorosaurs. Microraptor, Pedopenna, and Anchiornis all have winged feet, share many features, and lie close to the base of the clade Paraves. This suggests that the ancestral paravian may have been a four-winged glider. Deinonychus may also display partial volancy, with the young being capable of flight or gliding and the adults being flightless. In 2018, a study concluded that the last common ancestor of the Pennaraptora had joint surfaces on the fingers, and between the metatarsus and the wrist, that were optimised to stabilise the hand in flight. This was seen as an indication for secondary flightlessness in heavy basal members of that group.
In Euornithes, the earliest unequivocal example of secondary flightlessness is Patagopteryx.
Subsections (0):
, Section: See also (1):
Dinosaurs portal
Subsections (0):
, Section: Footnotes (1):

Subsections (0):
, Section: References (1):

Subsections (0):
, Section: External links (1):

‘Dinosaurs Among Us’ Retraces an Evolutionary Path from Dinosaurs to Birds, NY Times, March 28, 2016
DinoBuzz A popular-level discussion of the dinosaur-bird hypothesis
Archaeopteryx - FAQs from the Usenet newsgroup talk.origins.
Dinosaurs among us Article and Video  American Museum of Natural History exhibit of dinosaur evolution leading to birds
Subsections (0):
]"
2,"Category:Origins (id: 29739395, ns: 14)",0,Cradle of civilization,"A cradle of civilization is a location and a culture where civilization was developed independent of other civilizations in other locations. The formation of urban settlements (cities) is the primary characteristic of a society that can be characterized as ""civilized"". Other characteristics of civilization include a sedentary non-nomadic population, monumental architecture, the existence of social classes and inequality, and the creation of a writing system for communication. The transition from simpler societies to the complex society of a civilization is gradual.
Scholars generally acknowledge six cradles of civilization: Mesopotamia, Ancient Egypt, Ancient India, and China are believed to be the earliest in Afro-Eurasia (previously called the Old World), while the Caral-Supe civilization of coastal Peru and the Olmec civilization of Mexico are believed to be the earliest in Americas - previously known in  Western literature as the New World. All of the cradles of civilization depended upon agriculture for sustenance (except possibly Caral-Supe which may have depended initially on marine resources). All depended upon farmers producing an agricultural surplus to support the centralized government, political leaders, priests, and public works of the urban centers of the early civilizations.
Less formally, the term ""cradle of civilization"" is often used to refer to other historic ancient civilizations, such as Greece or Rome, which have both been called the ""cradle of Western civilization"".","[Section: Rise of civilization (1):
The earliest signs of a process leading to sedentary culture can be seen in the Levant to as early as 12,000 BC, when the Natufian culture became sedentary; it evolved into an agricultural society by 10,000 BC. The importance of water to safeguard an abundant and stable food supply, due to favourable conditions for hunting, fishing and gathering resources including cereals, provided an initial wide spectrum economy that triggered the creation of permanent villages.
The earliest proto-urban settlements with several thousand inhabitants emerged in the Neolithic which began in Western Asia in 10,000 BC. The first cities to house several tens of thousands were Uruk, Ur, Kish and Eridu in Mesopotamia, followed by Susa in Elam and Memphis in Egypt, all by the 31st century BC (see Historical urban community sizes).
Historic times are marked apart from prehistoric times when ""records of the past begin to be kept for the benefit of future generations""—in written or oral form. If the rise of civilization is taken to coincide with the development of writing out of proto-writing, then the Near Eastern Chalcolithic (the transitional period between the Neolithic and the Bronze Age during the 4th millennium BC) and the development of proto-writing in Harappa in the Indus Valley of South Asia around 3,300 BC are the earliest instances, followed by Chinese proto-writing evolving into the oracle bone script, and again by the emergence of Mesoamerican writing systems from about 900 BC.
In the absence of written documents, most aspects of the rise of early civilizations are contained in archaeological assessments that document the development of formal institutions and the material culture. A ""civilized"" way of life is ultimately linked to conditions coming almost exclusively from intensive agriculture. Gordon Childe defined the development of civilization as the result of two successive revolutions: the Neolithic Revolution of Western Asia, triggering the development of settled communities, and the Urban revolution which also first emerged in Western Asia, which enhanced tendencies towards dense settlements, specialized occupational groups, social classes, exploitation of surpluses, monumental public buildings and writing. Few of those conditions, however, are unchallenged by the records: dense cities were not attested in Egypt's Old Kingdom (unlike Mesopotamia) and cities had a dispersed population in the Maya area; the Incas lacked writing although they could keep records with Quipus which might also have had literary uses; and often monumental architecture preceded any indication of village settlement. For instance, in present-day Louisiana, researchers have determined that cultures that were primarily nomadic organized over generations to build earthwork mounds at seasonal settlements as early as 3400 BC. Rather than a succession of events and preconditions, the rise of civilization could equally be hypothesized as an accelerated process that started with incipient agriculture and culminated in the Oriental Bronze Age.
Subsections (0):
, Section: Single or multiple cradles (1):
Scholars once thought that civilization began in the Fertile Crescent and spread out from there by influence. Scholars now believe that civilizations arose independently at several locations in both hemispheres. They have observed that sociocultural developments occurred along different timeframes. ""Sedentary"" and ""nomadic"" communities continued to interact considerably; they were not strictly divided among widely different cultural groups. The concept of a cradle of civilization has a focus where the inhabitants came to build cities, to create writing systems, to experiment in techniques for making pottery and using metals, to domesticate animals, and to develop complex social structures involving class systems.
Today, scholarship generally identifies six areas where civilization emerged independently: the Fertile Crescent, including Mesopotamia and the Levant; the Nile Valley; the Indo-Gangetic Plain; the North China Plain; the Andean Coast; and the Mesoamerican Gulf Coast.
Subsections (0):
, Section: Cradles of civilization (1):

Subsections (5):
Section: Fertile Crescent (2):
The Fertile Crescent comprises a crescent-shaped region of elevated terrain in West Asia, encompassing regions of modern-day Israel, the Palestinian territories, Lebanon, Syria, Jordan, Turkey, and Iraq, extending to the Zagros Mountains in Iran. It stands as one of the earliest regions globally where agricultural practices emerged, marking the advent of sedentary farming communities.
By 10,200 BC, fully developed Neolithic cultures, characterized by the Pre-Pottery Neolithic A (PPNA) and Pre-Pottery Neolithic B (7600 to 6000 BC) phases, emerged within the Fertile Crescent. These cultures diffused eastward into South Asia and westward into Europe and North Africa. Among the notable PPNA settlements is Jericho, located in the Jordan Valley, believed to be the world's earliest established city, with initial settlement dating back to around 9600 BC and fortification occurring around 6800 BC.
Current theories and findings identify the Fertile Crescent as the first and oldest cradle of civilization. Examples of sites in this area are the early Neolithic site of Göbekli Tepe (9500–8000 BC) and Çatalhöyük (7500–5700 BC).
Subsections (2):
Section: Mesopotamia (3):
In Mesopotamia (a region encompassing modern Iraq and bordering regions of Southeast Turkey, Northeast Syria and Northwest Iran), the convergence of the Tigris and Euphrates rivers produced rich fertile soil and a supply of water for irrigation. Neolithic cultures emerged in the region from 8000 BC onwards. The civilizations that emerged around these rivers are the earliest known non-nomadic agrarian societies. It is because of this that the Fertile Crescent region, and Mesopotamia in particular, are often referred to as the cradle of civilization. The period known as the Ubaid period (c. 6500 to 3800 BC) is the earliest known period on the alluvial plain, although it is likely earlier periods exist obscured under the alluvium. It was during the Ubaid period that the movement toward urbanization began. Agriculture and animal husbandry were widely practiced in sedentary communities, particularly in Northern Mesopotamia (later Assyria), and intensive irrigated hydraulic agriculture began to be practiced in the south.
Around 6000 BC, Neolithic settlements began to appear all over Egypt. Studies based on morphological, genetic, and archaeological data have attributed these settlements to migrants from the Fertile Crescent in the Near East arriving in Egypt and North Africa during the Egyptian and North African Neolithic Revolution and bringing agriculture to the region. Tell el-'Oueili is the oldest Sumerian site settled during this period, around 5400 BC, and the city of Ur also first dates to the end of this period. In the south, the Ubaid period lasted from around 6500 to 3800 BC.
Sumerian civilization coalesced in the subsequent Uruk period (4000 to 3100 BC). Named after the Sumerian city of Uruk, this period saw the emergence of urban life in Mesopotamia and, during its later phase, the gradual emergence of the cuneiform script. Proto-writing in the region dates to around 3800 BC, with the earliest texts dating to 3300 BC; early cuneiform writing emerged in 3000 BC. It was also during this period that pottery painting declined as copper started to become popular, along with cylinder seals. Sumerian cities during the Uruk period were probably theocratic and were most likely headed by a priest-king (ensi), assisted by a council of elders, including both men and women. It is quite possible that the later Sumerian pantheon was modeled upon this political structure.
The Jemdet Nasr period, which is generally dated from 3100 to 2900 BC and succeeds the Uruk period, is known as one of the formative stages in the development of the cuneiform script. The oldest clay tablets come from Uruk and date to the late fourth millennium BC, slightly earlier than the Jemdet Nasr Period. By the time of the Jemdet Nasr Period, the script had already undergone a number of significant changes. It originally consisted of pictographs, but by the time of the Jemdet Nasr Period it was already adopting simpler and more abstract designs. It is also during this period that the script acquired its iconic wedge-shaped appearance.
Uruk trade networks started to expand to other parts of Mesopotamia and as far as North Caucasus, and strong signs of governmental organization and social stratification began to emerge, leading to the Early Dynastic Period (c. 2900 BC). After the Early Dynastic period began, there was a shift in control of the city-states from the temple establishment headed by council of elders led by a priestly ""En"" (a male figure when it was a temple for a goddess, or a female figure when headed by a male god) towards a more secular Lugal (Lu = man, Gal = great). The Lugals included such legendary patriarchal figures as Enmerkar, Lugalbanda and Gilgamesh, who supposedly reigned shortly before the historic record opens around 2700 BC, when syllabic writing started to develop from the early pictograms. The center of Sumerian culture remained in southern Mesopotamia, even though rulers soon began expanding into neighboring areas. Neighboring Semitic groups, including the Akkadian speaking Semites (Assyrians, Babylonians) who lived alongside the Sumerians in Mesopotamia, adopted much of Sumerian culture for their own. The earliest ziggurats began near the end of the Early Dynastic Period, although architectural precursors in the form of raised platforms date back to the Ubaid period. The Sumerian King List dates to the early second millennium BC. It consists of a succession of royal dynasties from different Sumerian cities, ranging back into the Early Dynastic Period. Each dynasty rises to prominence and dominates the region, only to be replaced by the next. The document was used by later Mesopotamian kings to legitimize their rule. While some of the information in the list can be checked against other texts such as economic documents, much of it is probably purely fictional, and its use as a historical document is limited.
Eannatum, the Sumerian king of Lagash, established the first verifiable empire in history in 2500 BC. The neighboring Elam, in modern Iran, was also part of the early urbanization during the Chalcolithic period. Elamite states were among the leading political forces of the Ancient Near East. The emergence of Elamite written records from around 3000 BC also parallels Sumerian history, where slightly earlier records have been found. During the 3rd millennium BC, there developed a very intimate cultural symbiosis between the Sumerians and the Akkadians. Akkadian gradually replaced Sumerian as a spoken language somewhere between the 3rd and the 2nd millennia BC. The Semitic-speaking Akkadian empire emerged around 2350 BC under Sargon the Great. The Akkadian Empire reached its political peak between the 24th and 22nd centuries BC. Under Sargon and his successors, the Akkadian language was briefly imposed on neighboring conquered states such as Elam and Gutium. After the fall of the Akkadian Empire and the overthrow of the Gutians, there was a brief reassertion of Sumerian dominance in Mesopotamia under the Third Dynasty of Ur. After the final collapse of Sumerian hegemony in Mesopotamia around 2004 BC, the Semitic Akkadian people of Mesopotamia eventually coalesced into two major Akkadian-speaking nations: Assyria in the north (whose earliest kings date to the 25th century BC), and, a few centuries later, Babylonia in the south, both of which (Assyria in particular) would go on to form powerful empires between the 20th and 6th centuries BC. The Sumerians were eventually absorbed into the Semitic Assyrian-Babylonian population.
Subsections (0):

Section: Ancient Egypt (3):
The developed Neolithic cultures belonging to the phases Pre-Pottery Neolithic A (10,200 BC) and Pre-Pottery Neolithic B (7600 to 6000 BC) appeared in the fertile crescent and from there spread eastwards and westwards. Contemporaneously, a grain-grinding culture using the earliest type of sickle blades had replaced the culture of hunters, fishers, and gathering people using stone tools along the Nile. Geological evidence and computer climate modeling studies also suggest that natural climate changes around 8000 BC began to desiccate the extensive pastoral lands of northern Africa, eventually forming the Sahara. Continued desiccation forced the early ancestors of the Egyptians to settle around the Nile more permanently and to adopt a more sedentary lifestyle. The oldest fully developed neolithic culture in Egypt is Fayum A culture that began around 5500 B.C.
By about 5500 BC, small tribes living in the Nile valley had developed into a series of inter-related cultures as far south as Sudan, demonstrating firm control of agriculture and animal husbandry, and identifiable by their pottery and personal items, such as combs, bracelets, and beads. The largest of these early cultures in northern Upper Egypt was the Badari, which probably originated in the Western Desert; it was known for its high quality ceramics, stone tools, and use of copper. The oldest known domesticated bovine in Africa are from Fayum dating to around 4400 BC. The Badari cultures was followed by the Naqada culture, which brought a number of technological improvements. As early as the first Naqada Period, Amratia, Egyptians imported obsidian from Ethiopia, used to shape blades and other objects from flakes. By 3300 BC, just before the first Egyptian dynasty, Egypt was divided into two kingdoms, known as Upper Egypt to the south, and Lower Egypt to the north.
Egyptian civilization begins during the second phase of the Naqada culture, known as the Gerzeh period, around 3500 BC and coalesces with the unification of Upper and Lower Egypt around 3150 BC. Farming produced the vast majority of food; with increased food supplies, the populace adopted a much more sedentary lifestyle, and the larger settlements grew to cities of about 5,000 residents. It was in this time that the city dwellers started using mud brick to build their cities, and the use of the arch and recessed walls for decorative effect became popular. Copper instead of stone was increasingly used to make tools and weaponry. Symbols on Gerzean pottery also resemble nascent Egyptian hieroglyphs. Early evidence also exists of contact with the Near East, particularly Canaan and the Byblos coast, during this time. Concurrent with these cultural advances, a process of unification of the societies and towns of the upper Nile River, or Upper Egypt, occurred. At the same time the societies of the Nile Delta, or Lower Egypt, also underwent a unification process. During his reign in Upper Egypt, King Narmer defeated his enemies on the Delta and merged both the Kingdom of Upper and Lower Egypt under his single rule.
The Early Dynastic Period of Egypt immediately followed the unification of Upper and Lower Egypt. It is generally taken to include the First and Second Dynasties, lasting from the Naqada III archaeological period until about the beginning of the Old Kingdom, c. 2686 BC. With the First Dynasty, the capital moved from Thinis to Memphis with a unified Egypt ruled by a god-king. The hallmarks of ancient Egyptian civilization, such as art, architecture and many aspects of religion, took shape during the Early Dynastic period. The strong institution of kingship developed by the pharaohs served to legitimize state control over the land, labor, and resources that were essential to the survival and growth of ancient Egyptian civilization.
Major advances in architecture, art, and technology were made during the subsequent Old Kingdom, fueled by the increased agricultural productivity and resulting population, made possible by a well-developed central administration. Some of ancient Egypt's crowning achievements, the Giza pyramids and Great Sphinx, were constructed during the Old Kingdom. Under the direction of the vizier, state officials collected taxes, coordinated irrigation projects to improve crop yield, drafted peasants to work on construction projects, and established a justice system to maintain peace and order. Along with the rising importance of a central administration there arose a new class of educated scribes and officials who were granted estates by the pharaoh in payment for their services. Pharaohs also made land grants to their mortuary cults and local temples, to ensure that these institutions had the resources to worship the pharaoh after his death. Scholars believe that five centuries of these practices slowly eroded the economic power of the pharaoh, and that the economy could no longer afford to support a large centralized administration. As the power of the pharaoh diminished, regional governors called nomarchs began to challenge the supremacy of the pharaoh. This, coupled with severe droughts between 2200 and 2150 BC, is assumed to have caused the country to enter the 140-year period of famine and strife known as the First Intermediate Period.
Subsections (0):

Section: Ancient India (2):
One of the earliest Neolithic sites in the Indian subcontinent is Bhirrana along the ancient Ghaggar-Hakra riverine system in the present day state of Haryana in India, dating to around 7600 BC. Other early sites include Lahuradewa in the Middle Ganges region and Jhusi near the confluence of Ganges and Yamuna rivers, both dating to around 7000 BC.
The aceramic Neolithic at Mehrgarh in present-day Pakistan lasts from 7000 to 5500 BC, with the ceramic Neolithic at Mehrgarh lasting up to 3300 BC; blending into the Early Bronze Age. Mehrgarh is one of the earliest sites with evidence of farming and herding in the Indian subcontinent. It is likely that the culture centered around Mehrgarh migrated into the Indus Valley in present-day Pakistan and became the Indus Valley Civilisation. The earliest fortified town in the region is found at Rehman Dheri, dated 4000 BC in Khyber Pakhtunkhwa close to River Zhob Valley in present-day Pakistan . Other fortified towns found to date are at Amri (3600–3300 BC), Kot Diji in Sindh, and at Kalibangan (3000 BC) at the Hakra River.
The Indus Valley Civilization starts around 3300 BC with what is referred to as the Early Harappan Phase (3300 to 2600 BC), although at the start this was still a village-based culture, leaving mostly pottery for archaeologists. The earliest examples of the Indus script date to this period, as well as the emergence of citadels representing centralised authority and an increasingly urban quality of life. Trade networks linked this culture with related regional cultures and distant sources of raw materials, including lapis lazuli and other materials for bead-making. By around 2600 BC, villagers had domesticated numerous crops, including peas, sesame seeds, dates, and cotton, as well as animals, including the water buffalo.
2600 to 1900 BC marks the Mature Harappan Phase during which Early Harappan communities turned into large urban centers including Harappa, Dholavira, Mohenjo-Daro, Lothal, Rupar, and Rakhigarhi, and more than 1,000 towns and villages, often of relatively small size. Mature Harappans evolved new techniques in metallurgy and produced copper, bronze, lead, and tin and displayed advanced levels of engineering. As seen in Harappa, Mohenjo-daro and the recently partially excavated Rakhigarhi, this urban plan included the world's first known urban sanitation systems: see hydraulic engineering of the Indus Valley civilization. Within the city, individual homes or groups of homes obtained water from wells. From a room that appears to have been set aside for bathing, waste water was directed to covered drains, which lined the major streets. Houses opened only to inner courtyards and smaller lanes. The housebuilding in some villages in the region still resembles in some respects the housebuilding of the Harappans. The advanced architecture of the Harappans is shown by their impressive dockyards, granaries, warehouses, brick platforms, and protective walls. The massive walls of Indus cities most likely protected the Harappans from floods and may have dissuaded military conflicts.
The people of the Indus Civilization achieved great accuracy in measuring length, mass, and time. They were among the first to develop a system of uniform weights and measures. A comparison of available objects indicates large scale variation across the Indus territories. Their smallest division, which is marked on an ivory scale found in Lothal in Gujarat, was approximately 1.704 mm, the smallest division ever recorded on a scale of the Bronze Age. Harappan engineers followed the decimal division of measurement for all practical purposes, including the measurement of mass as revealed by their hexahedron weights. These chert weights were in a ratio of 5:2:1 with weights of 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 50, 100, 200, and 500 units, with each unit weighing approximately 28 grams, similar to the English Imperial ounce or Greek uncia, and smaller objects were weighed in similar ratios with the units of 0.871. However, as in other cultures, actual weights were not uniform throughout the area. The weights and measures later used in Kautilya's Arthashastra (4th century BC) are the same as those used in Lothal.
Around 1800 BC, signs of a gradual decline began to emerge, and by around 1700 BC most of the cities had been abandoned. Suggested contributory causes for the localisation of the IVC include changes in the course of the river, and climate change that is also signalled for the neighbouring areas of the Middle East. As of 2016 many scholars believe that drought led to a decline in trade with Egypt and Mesopotamia contributing to the collapse of the Indus Civilization. The Ghaggar-Hakra system was rain-fed, and water-supply depended on the monsoons. The Indus Valley climate grew significantly cooler and drier from about 1800 BC, linked to a general weakening of the monsoon at that time. The Indian monsoon declined and aridity increased, with the Ghaggar-Hakra retracting its reach towards the foothills of the Himalaya, leading to erratic and less extensive floods that made inundation agriculture less sustainable. Aridification reduced the water supply enough to cause the civilization's demise, and to scatter its population eastward. As the monsoons kept shifting south, the floods grew too erratic for sustainable agricultural activities. The residents then migrated away into smaller communities. However trade with the old cities did not flourish. The small surplus produced in these small communities did not allow development of trade, and the cities died out. The Indo-Aryan peoples migrated into the Indus River Valley during this period and began the Vedic age of India. The Indus Valley Civilization did not disappear suddenly and many elements of the civilization continued in later Indian subcontinent and Vedic cultures.
Subsections (0):

Section: Ancient China (2):
Drawing on archaeology, geology and anthropology, modern scholars do not see the origins of the Chinese civilization or history as a linear story but rather the history of the interactions of different and distinct cultures and ethnic groups that influenced each other's development. The specific cultural regions that developed Chinese civilization were the Yellow River civilization, the Yangtze civilization, and Liao civilization. Early evidence for Chinese millet agriculture is dated to around 7000 BC, with the earliest evidence of cultivated rice found at Chengtoushan near the Yangtze River, dated to 6500 BC. Chengtoushan may also be the site of the first walled city in China. By the beginning of the Neolithic Revolution, the Yellow River valley began to establish itself as a center of the Peiligang culture, which flourished from 7000 to 5000 BC, with evidence of agriculture, constructed buildings, pottery, and burial of the dead. With agriculture came increased population, the ability to store and redistribute crops, and the potential to support specialist craftsmen and administrators. Its most prominent site is Jiahu. Some scholars have suggested that the Jiahu symbols (6600 BC) are the earliest form of proto-writing in China. However, it is likely that they should not be understood as writing itself, but as features of a lengthy period of sign-use, which led eventually to a fully-fledged system of writing. Archaeologists believe that the Peiligang culture was egalitarian, with little political organization.
It eventually evolved into the Yangshao culture (5000 to 3000 BC), and their stone tools were polished and highly specialized. They may also have practiced an early form of silkworm cultivation. The main food of the Yangshao people was millet, with some sites using foxtail millet and others broom-corn millet, though some evidence of rice has been found.  The exact nature of Yangshao agriculture, small-scale slash-and-burn cultivation versus intensive agriculture in permanent fields, is currently a matter of debate. Once the soil was exhausted, residents picked up their belongings, moved to new lands, and constructed new villages. However, Middle Yangshao settlements such as Jiangzhi contain raised-floor buildings that may have been used for the storage of surplus grains. Grinding stones for making flour were also found.
Later, Yangshao culture was superseded by the Longshan culture, which was also centered on the Yellow River from about 3000 to 1900 BC, its most prominent site being Taosi. The population expanded dramatically during the 3rd millennium BC, with many settlements having rammed earth walls.  It decreased in most areas around 2000 BC until the central area evolved into the Bronze Age Erlitou culture. The earliest bronze artifacts have been found in the Majiayao culture site (3100 to 2700 BC).
Chinese civilization begins during the second phase of the Erlitou period (1900 to 1500 BC), with Erlitou considered the first state level society of East Asia. There is considerable debate whether Erlitou sites correlate to the semi-legendary Xia dynasty. The Xia dynasty (2070 to 1600 BC) is the first dynasty to be described in ancient Chinese historical records such as the Bamboo Annals, first published more than a millennium later during the Western Zhou period. Although Xia is an important element in Chinese historiography, there is to date no contemporary written evidence to corroborate the dynasty. Erlitou saw an increase in bronze metallurgy and urbanization and was a rapidly growing regional center with palatial complexes that provide evidence for social stratification. The Erlitou civilization is divided into four phases, each of roughly 50 years. During Phase I, covering 100 hectares (250 acres), Erlitou was a rapidly growing regional center with estimated population of several thousand but not yet an urban civilization or capital. Urbanization began in Phase II, expanding to 300 ha (740 acres) with a population around 11,000.  A palace area of 12 ha (30 acres) was demarcated by four roads. It contained the 150x50 m Palace 3, composed of three courtyards along a 150-meter axis, and Palace 5.  A bronze foundry was established to the south of the palatial complex that was controlled by the elite who lived in palaces. The city reached its peak in Phase III, and may have had a population of around 24,000. The palatial complex was surrounded by a two-meter-thick rammed-earth wall, and Palaces 1, 7, 8, 9 were built.  The earthwork volume of rammed earth for the base of largest Palace 1 is 20,000 m³ at least. Palaces 3 and 5 were abandoned and replaced by 4,200-square-meter (45,000 sq ft) Palace 2 and Palace 4. In Phase IV, the population decreased to around 20,000, but building continued. Palace 6 was built as an extension of Palace 2, and Palaces 10 and 11 were built.  Phase IV overlaps with the Lower phase of the Erligang culture (1600–1450 BC). Around 1600 to 1560 BC, about 6 km northeast of Erlitou, a culturally Erligang walled city was built at Yanshi, which coincides with an increase in production of arrowheads at Erlitou. This situation might indicate that the Yanshi city was competing for power and dominance with Erlitou. Production of bronzes and other elite goods ceased at the end of Phase IV, at the same time as the Erligang city of Zhengzhou was established 85 km (53 mi) to the east. There is no evidence of destruction by fire or war, but, during the Upper Erligang phase (1450–1300 BC), all the palaces were abandoned, and Erlitou was reduced to a village of 30 ha (74 acres).
The earliest traditional Chinese dynasty for which there is both archeological and written evidence is the Shang dynasty (1600 to 1046 BC). Shang sites have yielded the earliest known body of Chinese writing, the oracle bone script, mostly divinations inscribed on bones. These inscriptions provide critical insight into many topics from the politics, economy, and religious practices to the art and medicine of this early stage of Chinese civilization. Some historians argue that Erlitou should be considered an early phase of the Shang dynasty. The U.S. National Gallery of Art defines the Chinese Bronze Age as the period between about 2000 and 771 BC; a period that begins with the Erlitou culture and ends abruptly with the disintegration of Western Zhou rule. The Sanxingdui culture is another Chinese Bronze Age society, contemporaneous to the Shang dynasty, however they developed a different method of bronze-making from the Shang.
Subsections (0):

Section: Ancient Andes (2):
The earliest evidence of agriculture in the Andean region dates to around 9000 BC in Ecuador at sites of the Las Vegas culture. The bottle gourd may have been the first plant cultivated. The oldest evidence of canal irrigation in South America dates to 4700 to 2500 BC in the Zaña Valley of northern Peru. The earliest urban settlements of the Andes, as well as North and South America, are dated to 3500 BC at Huaricanga, in the Fortaleza area, and Sechin Bajo near the Sechin River. Both sites are in Peru.
The Caral-Supe or Norte Chico civilization is understood to have emerged around 3200 BC, as it is at that point that large-scale human settlement and communal construction across multiple sites becomes clearly apparent. In the early 21st century, Peruvian archaeologist Ruth Shady established Caral-Supe as the oldest known civilization in the Americas. The civilization flourished near the Pacific coast in the valleys of three small rivers, the Fortaleza, the Pativilca, and the Supe. These river valleys each have large clusters of sites. Further south, there are several associated sites along the Huaura River. Notable settlements include the cities of Caral, the largest and most complex Preceramic site, and Aspero. Norte Chico is distinguished by its density of large sites with immense architecture. Haas argues that the density of sites in such a small area is globally unique for a nascent civilization. During the third millennium BC, Norte Chico may have been the most densely populated area of the world (excepting, possibly, northern China). The Supe, Pativilca, Fortaleza, and Huaura River valleys each have several related sites.
Norte Chico is unusual in that it completely lacked ceramics and apparently had almost no visual art. Nevertheless, the civilization exhibited impressive architectural feats, including large earthwork platform mounds and sunken circular plazas, and an advanced textile industry. The platform mounds, as well as large stone warehouses, provide evidence for a stratified society and a centralized authority necessary to distribute resources such as cotton. However, there is no evidence of warfare or defensive structures during this period. Originally, it was theorized that, unlike other early civilizations, Norte Chico developed by relying on maritime food sources in place of a staple cereal. This hypothesis, the Maritime Foundation of Andean Civilization, is still hotly debated; however, most researches now agree that agriculture played a central role in the civilization's development while still acknowledging a strong supplemental reliance on maritime proteins.
The Norte Chico chiefdoms were ""...almost certainly theocratic, though not brutally so,"" according to Mann. Construction areas show possible evidence of feasting, which would have included music and likely alcohol, suggesting an elite able to both mobilize and reward the population. The degree of centralized authority is difficult to ascertain, but architectural construction patterns are indicative of an elite that, at least in certain places at certain times, wielded considerable power: while some of the monumental architecture was constructed incrementally, other buildings, such as the two main platform mounds at Caral, appear to have been constructed in one or two intense construction phases. As further evidence of centralized control, Haas points to remains of large stone warehouses found at Upaca, on the Pativilca, as emblematic of authorities able to control vital resources such as cotton. Economic authority would have rested on the control of cotton and edible plants and associated trade relationships, with power centered on the inland sites. Haas tentatively suggests that the scope of this economic power base may have extended widely: there are only two confirmed shore sites in the Norte Chico (Aspero and Bandurria) and possibly two more, but cotton fishing nets and domesticated plants have been found up and down the Peruvian coast. It is possible that the major inland centers of Norte Chico were at the center of a broad regional trade network centered on these resources.
Discover magazine, citing Shady, suggests a rich and varied trade life: ""[Caral] exported its own products and those of Aspero to distant communities in exchange for exotic imports: Spondylus shells from the coast of Ecuador, rich dyes from the Andean highlands, hallucinogenic snuff from the Amazon."" (Given the still limited extent of Norte Chico research, such claims should be treated circumspectly.) Other reports on Shady's work indicate Caral traded with communities in the Andes and in the jungles of the Amazon basin on the opposite side of the Andes.
Leaders' ideological power was based on apparent access to deities and the supernatural. Evidence regarding Norte Chico religion is limited: an image of the Staff God, a leering figure with a hood and fangs, has been found on a gourd dated to 2250 BC. The Staff God is a major deity of later Andean cultures, and Winifred Creamer suggests the find points to worship of common symbols of gods. As with much other research at Norte Chico, the nature and significance of the find has been disputed by other researchers. The act of architectural construction and maintenance may also have been a spiritual or religious experience: a process of communal exaltation and ceremony. Shady has called Caral ""the sacred city"" (la ciudad sagrada): socio-economic and political focus was on the temples, which were periodically remodeled, with major burnt offerings associated with the remodeling.
Bundles of strings uncovered at Norte Chico sites have been identified as quipu, a type of pre-writing recording device. Quipu are thought to encode numeric information, but some have conjectured that quipu have been used to encode other forms of data, possibly including literary or musical applications. However, the exact use of quipu by the Norte Chico and later Andean cultures has been widely debated. The presence of quipu and the commonality of religious symbols suggests a cultural link between Norte Chico and later Andean cultures.
Circa 1800 BC, the Norte Chico civilization began to decline, with more powerful centers appearing to the south and north along the coast and to the east inside the belt of the Andes. Pottery eventually developed in the Amazon Basin and spread to the Andean culture region around 2000 BC. The next major civilization to arise in the Andes would be the Chavín culture at Chavín de Huantar, located in the Andean highlands of the present-day Ancash Region. It is believed to have been built around 900 BC and was the religious and political center of the Chavín people.
Subsections (0):

Section: Mesoamerica (2):
Maize is believed to have been first domesticated in southern Mexico about 7000 BC. The Coxcatlan Caves in the Valley of Tehuacán provide evidence for agriculture in components dated between 5000 and 3400 BC. Similarly, sites such as Sipacate in Guatemala provide maize pollen samples dating to 3500 BC. Around 1900 BC, the Mokaya domesticated one of the dozen species of cacao. A Mokaya archaeological site provides evidence of cacao beverages dating to this time. The Mokaya are also thought to have been among the first cultures in Mesoamerica to develop a hierarchical society. What would become the Olmec civilization had its roots in early farming cultures of Tabasco, which began around 5100 to 4600 BC.
The emergence of the Olmec civilization has traditionally been dated to around 1600 to 1500 BC. Olmec features first emerged in the city of San Lorenzo Tenochtitlán, fully coalescing around 1400 BC. The rise of civilization was assisted by the local ecology of well-watered alluvial soil, as well as by the transportation network provided by the Coatzacoalcos River basin. This environment encouraged a densely concentrated population, which in turn triggered the rise of an elite class and an associated demand for the production of the symbolic and sophisticated luxury artifacts that define Olmec culture. Many of these luxury artifacts were made from materials such as jade, obsidian, and magnetite, which came from distant locations and suggest that early Olmec elites had access to an extensive trading network in Mesoamerica. The aspect of Olmec culture perhaps most familiar today is their artwork, particularly the Olmec colossal heads. San Lorenzo was situated in the midst of a large agricultural area. San Lorenzo seems to have been largely a ceremonial site, a town without city walls, centered in the midst of a widespread medium-to-large agricultural population. The ceremonial center and attendant buildings could have housed 5,500 while the entire area, including hinterlands, could have reached 13,000. It is thought that while San Lorenzo controlled much or all of the Coatzacoalcos basin, areas to the east (such as the area where La Venta would rise to prominence) and north-northwest (such as the Tuxtla Mountains) were home to independent polities. San Lorenzo was all but abandoned around 900 BC at about the same time that La Venta rose to prominence. A wholesale destruction of many San Lorenzo monuments also occurred circa 950 BC, which may indicate an internal uprising or, less likely, an invasion. The latest thinking, however, is that environmental changes may have been responsible for this shift in Olmec centers, with certain important rivers changing course.
La Venta became the cultural capital of the Olmec concentration in the region until its abandonment around 400 BC; constructing monumental architectural achievements such as the Great Pyramid of La Venta. It contained a ""concentration of power"", as reflected by the sheer enormity of the architecture and the extreme value of the artifacts uncovered. La Venta is perhaps the largest Olmec city and it was controlled and expanded by an extremely complex hierarchical system with a king, as the ruler and the elites below him. Priests had power and influence over life and death and likely great political sway as well. Unfortunately, not much is known about the political or social structure of the Olmec, though new dating techniques might, at some point, reveal more information about this elusive culture. It is possible that the signs of status exist in the artifacts recovered at the site such as depictions of feathered headdresses or of individuals wearing a mirror on their chest or forehead. ""High-status objects were a significant source of power in the La Venta polity political power, economic power, and ideological power. They were tools used by the elite to enhance and maintain rights to rulership"". It has been estimated that La Venta would need to be supported by a population of at least 18,000 people during its principal occupation. To add to the mystique of La Venta, the alluvial soil did not preserve skeletal remains, so it is difficult to observe differences in burials. However, colossal heads provide proof that the elite had some control over the lower classes, as their construction would have been extremely labor-intensive. ""Other features similarly indicate that many laborers were involved"". In addition, excavations over the years have discovered that different parts of the site were likely reserved for elites and other parts for non-elites. This segregation of the city indicates that there must have been social classes and therefore social inequality.
The exact cause of the decline of the Olmec culture is uncertain. Between 400 and 350 BC, the population in the eastern half of the Olmec heartland dropped precipitously. This depopulation was probably the result of serious environmental changes that rendered the region unsuited for large groups of farmers, in particular changes to the riverine environment that the Olmec depended upon for agriculture, hunting and gathering, and transportation. These changes may have been triggered by tectonic upheavals or subsidence, or the silting up of rivers due to agricultural practices. Within a few hundred years of the abandonment of the last Olmec cities, successor cultures became firmly established. The Tres Zapotes site, on the western edge of the Olmec heartland, continued to be occupied well past 400 BC, but without the hallmarks of the Olmec culture. This post-Olmec culture, often labeled Epi-Olmec, has features similar to those found at Izapa, some 550 km (330 miles) to the southeast.
The Olmecs are sometimes referred to as the mother culture of Mesoamerica, as they were the first Mesoamerican civilization and laid many of the foundations for the civilizations that followed. However, the causes and degree of Olmec influences on Mesoamerican cultures has been a subject of debate over many decades. Practices introduced by the Olmec include ritual bloodletting and the Mesoamerican ballgame; hallmarks of subsequent Mesoamerican societies such as the Maya and Aztec. Although the Mesoamerican writing system would fully develop later, early Olmec ceramics show representations that may be interpreted as codices.
Subsections (0):
, Section: Cradle of Western civilization (1):
The origins of Western civilization can be traced back to the ancient Mediterranean world. There is academic consensus that Classical Greece was a major culture that provided the foundation of modern Western culture, philosophy, democracy, art, science, aesthetics, theatre, as well as building designs and proportions and architecture.
Along with Greece, Ancient Rome has sometimes been described as a birthplace or as the cradle of Western Civilization because of the role the city had in politics, republicanism, law, architecture, warfare and Western Christianity.
Western Civilization is also closely associated with Christianity, the predominant religion in the West, which has its origins in Judaism – the ethnic religion of the Jewish people – and Greco-Roman philosophy. Christianity emerged as a sect within Judaism and inherited many of its foundational beliefs, scriptures, and ethical principles from Jewish tradition. Christian ethics, influenced by its Jewish roots, has significantly influenced the foundational principles of Western societies.
The blending of Greco-Roman and Judeo-Christian traditions in shaping Western civilization has led scholars to describe it as emerging from the legacies of Athens and Jerusalem, or Athens, Jerusalem, and Rome.
Subsections (0):
, Section: Other uses (1):
The phrase ""cradle of civilization"".... plays a certain role in national mysticism. It has been used in Eastern as well as Western cultures, for instance, in Indian nationalism (In Search of the Cradle of Civilization 1995) and Taiwanese nationalism (Taiwan;— The Cradle of Civilization 2002). The terms also appear in esoteric pseudohistory, such as the Urantia Book, claiming the title for ""the second Eden"", or the pseudoarchaeology related to Megalithic Britain (Civilization One 2004,
Ancient Britain: The Cradle of Civilization 1921).
Subsections (0):
, Section: Timeline (1):
The following timeline shows a timeline of cultures, with the approximate dates of the emergence of civilization (as discussed in the article) in the featured areas, the primary cultures associated with these early civilizations. It is important to note that the timeline is not indicative of the beginning of human habitation, the start of a specific ethnic group, or the development of Neolithic cultures in the area – any of which often occurred significantly earlier than the emergence of civilization proper.
The dates given are only approximate as the development of civilization was incremental and the exact date when ""civilization"" began for a given culture is subject to interpretation.
Subsections (0):
, Section: See also (1):
Chronology of the ancient Near East
Cradle of Humankind
River valley civilization
Human history
Civilization state
Skara Brae and Barnhouse Settlement 3180 BC.
Old Europe (archaeology)
Subsections (0):
, Section: Notes (1):

Subsections (0):
, Section: References (1):

Subsections (2):
Section: Citations (2):

Subsections (0):

Section: Sources (2):

Subsections (0):
, Section: External links (1):
 Media related to Cradle of civilization at Wikimedia Commons
Subsections (0):
]"
3,"Category:Origins (id: 29739395, ns: 14)",0,Cosmogony,Cosmogony is any model concerning the origin of the cosmos or the universe.,"[Section: Overview (1):

Subsections (2):
Section: Scientific theories (2):
In astronomy, cosmogony refers to the study of the origin of particular astrophysical objects or systems, and is most commonly used in reference to the origin of the universe, the Solar System, or the Earth–Moon system. The prevalent cosmological model of the early development of the universe is the Big Bang theory.
Sean M. Carroll, who specializes in theoretical cosmology and field theory, explains two competing explanations for the origins of the singularity, which is the center of a space in which a characteristic is limitless (one example is the singularity of a black hole, where gravity is the characteristic that becomes limitless — infinite).
It is generally thought that the universe began at a point of singularity, but among Modern Cosmologists and Physicists, a singularity usually represents a lack of understanding, and in the case of Cosmology/Cosmogony, requires a theory of quantum gravity to understand. When the universe started to expand, what is colloquially known as the Big Bang occurred, which evidently began the universe. The other explanation, held by proponents such as Stephen Hawking, asserts that time did not exist when it emerged along with the universe. This assertion implies that the universe does not have a beginning, as time did not exist ""prior"" to the universe. Hence, it is unclear whether properties such as space or time emerged with the singularity and the known universe.
Despite the research, there is currently no theoretical model that explains the earliest moments of the universe's existence (during the Planck epoch) due to a lack of a testable theory of quantum gravity. Nevertheless, researchers of string theory, its extensions (such as M-theory), and of loop quantum cosmology, like Barton Zwiebach and Washington Taylor, have proposed solutions to assist in the explanation of the universe's earliest moments. Cosmogonists have only tentative theories for the early stages of the universe and its beginning. The proposed theoretical scenarios include string theory, M-theory, the Hartle–Hawking initial state, emergent Universe, string landscape, cosmic inflation, the Big Bang, and the ekpyrotic universe. Some of these proposed scenarios, like the string theory, are compatible, whereas others are not.
Subsections (0):

Section: Mythology (2):
In mythology, creation or cosmogonic myths are narratives describing the beginning of the universe or cosmos.
Some methods of the creation of the universe in mythology include:

the will or action of a supreme being or beings,
the process of metamorphosis,
the copulation of female and male deities,
from chaos,
or via a cosmic egg.
Creation myths may be etiological, attempting to provide explanations for the origin of the universe. For instance, Eridu Genesis, the oldest known creation myth, contains an account of the creation of the world in which the universe was created out of a primeval sea (Abzu). Creation myths vary, but they may share similar deities or symbols. For instance, the ruler of the gods in Greek mythology, Zeus, is similar to the ruler of the gods in Roman mythology, Jupiter. Another example is the ruler of the gods in Tagalog mythology, Bathala, who is similar to various rulers of certain pantheons within Philippine mythology such as the Bisaya's Kaptan.
Subsections (0):
, Section: Compared with cosmology (1):
In the humanities, the distinction between cosmogony and cosmology is blurred. For example, in theology, the cosmological argument for the existence of God (pre-cosmic cosmogonic bearer of personhood) is an appeal to ideas concerning the origin of the universe and is thus cosmogonical. Some religious cosmogonies have an impersonal first cause (for example Taoism).
However, in astronomy, cosmogony can be distinguished from cosmology, which studies the universe and its existence, but does not necessarily inquire into its origins. There is therefore a scientific distinction between cosmological and cosmogonical ideas. Physical cosmology is the science that attempts to explain all observations relevant to the development and characteristics of the universe on its largest scale. Some questions regarding the behaviour of the universe have been described by some physicists and cosmologists as being extra-scientific or metaphysical. Attempted solutions to such questions may include the extrapolation of scientific theories to untested regimes (such as the Planck epoch), or the inclusion of philosophical or religious ideas.
Subsections (0):
, Section: See also (1):
Anthropic principle – Hypothesis about sapient life and the universe
Cosmography – Science that maps the universe
Chronology of the universe – History and future of the universe
Ultimate fate of the universe – Theories about the end of the universe
Why there is anything at all
Subsections (0):
, Section: References (1):

Subsections (0):
, Section: External links (1):
 Media related to Cosmogony at Wikimedia Commons
Subsections (0):
]"
4,"Category:Origins (id: 29739395, ns: 14)",0,Domestication of the dog,"The domestication of the dog was the process which led to the domestic dog. This included the dog's genetic divergence from the wolf, its domestication, and the emergence of the first dogs. Genetic studies suggest that all ancient and modern dogs share a common ancestry and descended from an ancient, now-extinct wolf population – or closely related wolf populations – which was distinct from the modern wolf lineage. The dog's similarity to the grey wolf is the result of substantial dog-into-wolf gene flow, with the modern grey wolf being the dog's nearest living relative. An extinct Late Pleistocene wolf may have been the ancestor of the dog.
The dog is a wolf-like canid. The genetic divergence between the dog's ancestor and modern wolves occurred between 40,000 and 30,000 years ago, just before or during the Last Glacial Maximum (20,000–27,000 years ago). This timespan represents the upper time-limit for the commencement of domestication because it is the time of divergence but not the time of domestication, which occurred later.
One of the most important transitions in human history was the domestication of animals, which began with the long-term association between wolves and hunter–gatherers more than 30,000 years ago. The dog was the first species and the only large carnivore to have been domesticated. The domestication of the dog occurred due to variation among the common ancestor wolf population in the fight-or-flight response where the common ancestor wolves with less aggression and aversion but greater altruism towards humans received fitness benefits (similar processes applied to humans), and thus the domestication of the dog is a prominent example of social selection (rather than artificial selection). The archaeological record and genetic analysis show the remains of the Bonn-Oberkassel dog buried beside humans 14,200 years ago to be the first undisputed dog, with disputed remains occurring 36,000 years ago.
The domestication of the dog predates agriculture, and it was not until 11,000 years ago in the Holocene era that people living in the Near East entered to relationships with wild populations of aurochs, boar, sheep, and goats. Where the domestication of the dog took place remains debated; however, literature reviews of the evidence find that the dog was domesticated in Eurasia, with the most plausible proposals being Central Asia, East Asia, and Western Europe. By the close of the most recent Ice Age 11,700 years ago, five ancestral lineages had diversified from each other and were represented through ancient dog samples found in the Levant (7,000 years before present YBP), Karelia (10,900 YBP), Lake Baikal (7,000 YBP), ancient America (4,000 YBP), and in the New Guinea singing dog (present day).
In 2021, a literature review of the current evidence infers that domestication of the dog began in Siberia 26,000-19,700 years ago by Ancient North Eurasians, then later dispersed eastwards into the Americas and westwards across Eurasia. This hypothesis is derived from when genetic divergences are inferred to have happened, ancient dog remains dating to this time and place have not been discovered, but archaeological excavation in those regions is rather limited.
The oldest known dog skeletons were found in the Altai Mountains of Siberia and a cave in Belgium, dated ~33,000 years ago. According to studies, this may indicate that the domestication of dogs occurred simultaneously in different geographic locations.","[Section: Divergence from wolves (1):
Genetic studies indicate that the grey wolf is the closest living relative of the dog. Attempting to reconstruct the dog's lineage through the phylogenetic analysis of DNA sequences from modern dogs and wolves has given conflicting results for several reasons. Firstly, studies indicate that an extinct Late Pleistocene wolf is the nearest common ancestor to the dog, with modern wolves not being directly ancestral to it. Secondly, the genetic divergence (split) between the dog's ancestor and modern wolves occurred over a short period of time, so that the time of the divergence is difficult to date (referred to as incomplete lineage sorting). This is complicated further by the cross-breeding that has occurred between dogs and wolves since domestication (referred to as post-domestication gene flow). Finally, there have been only tens of thousands of generations of dogs since domestication, so few mutations between dog and wolf have occurred; this sparsity makes the timing of domestication difficult to date.
Subsections (5):
Section: Pleistocene wolves (2):
The Late Pleistocene era was a time of glaciation, climate change, and the advance of humans into isolated areas. During the Late Pleistocene glaciation, a vast mammoth steppe stretched from Spain eastwards across Eurasia and over Beringia into Alaska and the Yukon. The close of this era was characterized by a series of severe and rapid climate oscillations with regional temperature changes of up to 16 °C (29 °F), which has been correlated with megafaunal extinctions. There is no evidence of megafaunal extinctions at the height of the Last Glacial Maximum (26,500 YBP), indicating that increasing cold and glaciation were not factors. Multiple events appear to have caused the rapid replacement of one species by another one within the same genus, or one population by another within the same species, across a broad area. As some species became extinct, so too did the predators that depended on them (coextinction).
The grey wolf is one of the few large carnivores to survive the Late Pleistocene megafaunal extinctions, but similar to many other megafaunal species it experienced a global population decline towards the end of this era, which was associated with extinctions of ecomorphs and phylogeographic shifts in populations. Grey wolf mitochondrial genomes (excluding the Himalayan wolf and the Indian plains wolf) indicate that the most recent common ancestor for all C. lupus specimens studied – modern and extinct – dates to 80,000 YBP, and this is more recent than the time suggested by the fossil record. The fossil record suggests that the earliest grey wolf specimens were found in what was once eastern Beringia at Old Crow, Yukon, in Canada and at Cripple Creek Sump, Fairbanks, in Alaska. The age is not agreed but could date 1 million YBP. All modern wolves (excluding the Himalayan wolf and the Indian plains wolf) show a most recent common ancestor dating to 32,000 YBP, which coincides with the commencement of their global demographic decline.

The origin of dogs is couched in the biogeography of wolf populations that lived during the Late Pleistocene. The fossil record shows evidence of changes in the morphology and body size of wolves during the Late Pleistocene, which may be due to differences in their prey size. Wolf skeletal development can be changed due to a preference for larger prey which results in larger wolves. Considerable morphological diversity existed among grey wolves by the Late Pleistocene. These are regarded as having been more cranio-dentally robust than modern grey wolves, often with a shortened rostrum, the pronounced development of the temporalis muscle, and robust premolars. It is proposed that these features were specialized adaptations for the processing of carcass and bone associated with the hunting and scavenging of Pleistocene megafauna. Compared with modern wolves, some Pleistocene wolves showed an increase in tooth breakage that is similar to that seen in the extinct dire wolf. This suggests that these either often processed carcasses, or that they competed with other carnivores and needed to quickly consume their prey. The frequency and location of tooth fractures found in these wolves compared with the modern spotted hyena indicates that these wolves were habitual bone crackers. These ancient wolves carried mitochondrial lineages which cannot be found among modern wolves, which implies that the ancient wolves went extinct.
Grey wolves suffered a species-wide population bottleneck (reduction) approximately 25,000 YBP during the Last Glacial Maximum. This was followed by a single population of modern wolves expanding out of a Beringia refuge to repopulate the wolf's former range, replacing the remaining Late Pleistocene wolf populations across Eurasia and North America as they did so. This source population probably did not give rise to dogs, but it admixed with dogs which allowed them to gain coat colour genes that are also related to immunity. There is little genetic information available on the ancient wolves that existed prior to the bottleneck. However, studies show that one or more of these ancient populations is more directly ancestral to dogs than are modern wolves, and conceivably these were more prone to domestication by the first humans to expand into Eurasia.
An apex predator sits on the top trophic level of the food chain, while a mesopredator sits further down the food chain and is dependent on smaller animals. Towards the end of the Pleistocene era, most of today's apex predators were mesopredators and this included the wolf. During the ecological upheaval associated with the close of the Late Pleistocene, one type of wolf population rose to become today's apex predator and another joined with humans to become an apex consumer. The domestication of this lineage ensured its evolutionary success through its expansion into a new ecological niche.
For a long time scientists assumed that dogs evolved from the modern grey wolf. But a study published in 2014 concluded that this was incorrect, and that dogs are descended from an extinct type of wolf.

It was such a long standing view that the gray wolf that we know today was around for hundreds of thousands of years and that dogs derived from them. We're very surprised that they're not.
Subsections (0):

Section: Time of genetic divergence (2):
The date estimated for the divergence of a domestic lineage from a wild one does not necessarily indicate the start of the domestication process but it does provide an upper boundary. The divergence of the lineage that led to the domestic horse from the lineage that led to the modern Przewalski's horse is estimated to have occurred around 45,000 YBP but the archaeological record indicates 5,500 YBP. The variance can be due to modern wild populations not being the direct ancestor of the domestic ones, or to a divergence caused by changes in the climate, topography, or other environmental influences. Recent studies indicate that a genetic divergence occurred between the dog's and modern wolves 20,000–40,000 YBP; however, this is the upper time-limit for domestication because it represents the time of divergence and not the time of domestication.
In 2013, the mitochondrial DNA (mDNA) sequencing of ancient wolves together with whole genome sequencing of modern dogs and wolves indicated a divergence time of 19,000–32,000 YBP. In 2014, another study indicated 11,000–16,000 YBP based on the modern wolf's mutation rate. The first draft genome sequence of a Pleistocene wolf was published in 2015. This wolf from the Taymyr Peninsula belonged to a population that had diverged from the ancestors of both modern wolves and dogs. Radiocarbon dating indicates its age to be 35,000 YBP, and this age could then be used to calibrate the wolf's mutation rate, indicating that the genetic divergence between the dog's ancestor and modern wolves occurred before the Last Glacial Maximum, between 27,000 and 40,000 YBP. When the Pleistocene wolf's mutation rate was applied to the timing of the earlier 2014 study which had originally used the modern wolf's mutation rate, that study gave the same result of 27,000–40,000 YBP. In 2017, a study compared the nuclear genome (from the cell nucleus) of three ancient dog specimens and found evidence of a single dog-wolf divergence occurring between 36,900 and 41,500 YBP.
Prior to genetic divergence, the population of wolves ancestral to the dog outnumbered all other wolf populations, and after divergence the dog population underwent a population reduction to be much lower.
In 2020, a genomic study of Eurasian wolves found that they and the dog share a common ancestor which is dated to 36,000 YBP. This finding supports the theory that all modern wolves descend from a single population which expanded after the Last Glacial Maximum and replaced other wolf populations that were adapted to different climatic conditions, and the finding of dog-like fossils dated over 30,000 YBP.
Subsections (0):

Section: Place of genetic divergence (2):

Subsections (2):
Section: Based on modern DNA (3):
Genetic studies have found that the modern dogs from Southeast Asia and South China show greater genetic diversity than those dogs from other regions, suggesting that this was the place of their origin. A similar study found greater genetic diversity in African village dogs than in breed dogs. An East Asian origin has been questioned because dog fossils have been found in Europe dating around 15,000 YBP but only 12,000 YBP in far eastern Russia. The reply is that archaeological studies in East Asia lag behind those in Europe, and that the environmental conditions in southern East Asia do not favour the preservation of fossils. Although primitive forms of the dog may have existed in Europe in the past, the genetic evidence indicates that these were later replaced by dogs that have migrated from southern East Asia. In 2017, a literature review found that this East Asian study sampled only east Asian indigenous dogs and compared their patterns of genetic diversity to those of breed dogs from other geographic regions. As it is known that the genetic bottlenecks associated with formation of breeds strongly reduce genetic diversity, this was not an appropriate comparison.
One DNA study concluded that dogs originated in Central Asia because dogs from there exhibit the lowest levels of linkage disequilibrium. In 2017, a literature review found that because it is known that the genetic bottlenecks associated with formation of breeds raise linkage disequilibrium, the comparison of purebred with village dogs was not appropriate.
Another DNA study indicated that dogs originated in the Middle East due to the sharing of DNA between dogs and Middle Eastern grey wolves. In 2011, a study found this indication to be incorrect because there had been hybridization between dogs and Middle Eastern grey wolves. In 2012, a study indicated that dogs derived from wolves originating in the Middle East and Europe and this was consistent with the archaeological record. In 2014, a genomic study found that no modern wolf from any region was any more genetically closer to the dog than any other, implying that the dog's ancestor was extinct.
Subsections (0):

Section: Based on ancient DNA (3):
In 2018, a literature review found that most genetic studies conducted over the last two decades were based on modern dog breeds and extant wolf populations, with their findings dependent on a number of assumptions. These studies assumed that the extant wolf was the ancestor of the dog, and did not consider genetic admixture between wolves and dogs, or the impact of incomplete lineage sorting. These pre-genomic studies have suggested an origin of dogs in Southeast Asia, East Asia, Central Asia, the Middle East, or Europe. More recently, the field of Paleogenomics applies the latest molecular technologies to fossil remains that still contain useful ancient DNA.
Subsections (3):
Section: Arctic Siberia (4):
In 2015, a study recovered mDNA from ancient canid specimens that were discovered on Zhokhov Island and the Yana river, arctic Siberia. These specimens included the mandible of a 360,000–400,000 YBP Canis c.f. variabilis (where c.f. is a Latin term meaning uncertain). Phylogenetic analyses of these canids revealed nine mDNA haplotypes not detected before. The Canis c.f. variabilis specimen clustered with other wolf samples from across Russia and Asia. The mDNA haplotypes of one 8,750 YBP specimen and some 28,000 YBP specimens matched with those of geographically widely-spread modern dogs. One 47,000 YBP canid from Duvanny Yar (which was once a part of western Beringia) was distinct from wolves but was only a few mutations away from those haplotypes found in modern dogs. The authors concluded that the structure of the modern dog gene pool was contributed to from ancient Siberian wolves and possibly from Canis c.f. variabilis.
Subsections (0):

Section: Southern Siberia (4):
See further: Altai dog
In 2013, a study looked at the well-preserved skull and left mandible of a dog-like canid that was excavated from Razboinichya Cave in the Altai Mountains of southern Siberia. It was dated to 33,300 YBP, which predates the oldest evidence from Western Europe and the Near East The mDNA analysis found it to be more closely related to dogs than wolves. Later in 2013, another study found that the canid could not be classified as a dog or wolf because it fell between both. In 2017, evolutionary biologists reviewed all of the evidence available on dog divergence and supported the specimens from the Altai mountains as being those of dogs from a lineage that is now extinct, and that was derived from a population of small wolves that is also now extinct.
Subsections (0):

Section: Europe (4):
Phylogenetic analysis showed that modern dog mDNA haplotypes resolve into four monophyletic clades designated by researchers as clades A-D.
In 2013, a study sequenced the complete and partial mitochondrial genomes of 18 fossil canids from the Old and New Worlds whose dates range from 1,000 to 36,000 YBP, and compared these with the complete mitochondrial genome sequences from modern wolves and dogs. Clade A included 64% of the modern dogs sampled, and these are a sister group to a clade containing three fossil pre-Columbian New World dogs dated between 1,000 and 8,500 YBP. This finding supports the hypothesis that pre-Columbian New World dogs share ancestry with modern dogs and that they likely arrived with the first humans to the New World. Together, clade A and the pre-Columbian fossil dogs were the sister group to a 14,500 YBP wolf found in the Kesslerloch cave near Thayngen in the canton of Schaffhausen, Switzerland, with a most recent common ancestor estimated to 32,100 YBP.
Clade B included 22% of the dog sequences which related to modern wolves from Sweden and Ukraine, with a common recent ancestor estimated to 9,200 YBP. However, this relationship might represent mitochondrial genome introgression from wolves because dogs were domesticated by this time. Clade C included 12% of the dogs sampled and these were sister to two ancient dogs from the Bonn-Oberkassel cave (14,700 YBP) and the Kartstein cave (12,500 YBP) near Mechernich in Germany, with a common recent ancestor estimated to 16,000–24,000 YBP. Clade D contained sequences from 2 Scandinavian breeds – the Jamthund and Norwegian Elkhound – and is the sister group to another 14,500 YBP wolf sequence also from the Kesserloch cave, with a common recent ancestor estimated to 18,300 YBP. Its branch is phylogenetically rooted in the same sequence as the ""Altai dog"" (not a direct ancestor). The data from this study indicated a European origin for dogs that was estimated at 18,800–32,100 YBP based on the genetic relationship of 78% of the sampled dogs with ancient canid specimens found in Europe. The data supports the hypothesis that dog domestication preceded the emergence of agriculture and was initiated close to the Last Glacial Maximum when hunter-gatherers preyed on megafauna.
The study found that three ancient Belgium canids (the 36,000 YBP ""Goyet dog"" cataloged as Canis species, along with two specimens dated 30,000 YBP and 26,000 YBP cataloged as Canis lupus) formed an ancient clade that was the most divergent group. The study found that the skulls of the ""Goyet dog"" and the ""Altai dog"" had some dog-like characteristics and proposed that this may have represented an aborted domestication episode. If so, there may have been originally more than one ancient domestication event for dogs as there was for domestic pigs.
One review considered why the domestication of the wolf occurred so late and at such high latitudes, when humans were living alongside wolves in the Middle East for the past 75,000 years. The proposal is that domestication was a cultural innovation caused through a long and stressful event, which was climate change. Domestication may have happened during one of the five cold Heinrich events that occurred after the arrival of humans in West Europe 37,000, 29,000, 23,000, 16,500, and 12,000 YBP. The theory is that the extreme cold during one of these events caused humans to either shift their location, adapt through a breakdown in their culture and change of their beliefs, or adopt innovative approaches. The adoption of the large wolf/dog was an adaptation to this hostile environment.
A criticism of the European proposal is that dogs in East Asia show more genetic diversity. However, dramatic differences in genetic diversity can be influenced both by an ancient and recent history of inbreeding. A counter-comment is that the modern European breeds only emerged in the 19th century, and that throughout history global dog populations experienced numerous episodes of diversification and homogenization, with each round further reducing the power of genetic data derived from modern breeds to help infer their early history.
In 2019, study of wolf samples from northern Italy using very short lengths of mDNA found that two specimens found in the Cava Filo archaeological site near San Lazzaro di Savena, Bologna fell within the domestic dog clade A haplogroup, with one being radio-carbon dated 24,700 YBP and the other stratigraphy dated to 20,000 YBP. The 24,700 YBP specimen matched the haplotype of ancient Bulgarian dogs, 2 historical sled dogs from the North American arctic, and 97 modern dogs. The 20,000 YBP specimen matched the haplotype of ancient Iberian and ancient Bulgarian dogs, Roman dogs from Iberia, and 2 historical sled dogs from the North American arctic. Four dog specimens found in the Bronze Age town of Via Ordiere, Solarolo, Italy dated to 3,600–3,280 years ago shared haplotypes with Late Pleistocene wolves and modern dogs.
In 2020, dog remains were found in two caves, Paglicci Cave and Grotta Romanelli in Apulia, southern Italy. These were dated 14,000 YBP and are the oldest dog remains found in the Mediterranean Basin. One specimen was retrieved from a layer where the sediment was dated 20,000 YBP, indicating the possibility of an earlier timing. The specimens were genetically related to the 14,000 YBP Bonn-Oberkassel dog from Germany and other early dogs from western and central Europe which all fall within the domestic dog mDNA haplogroup C, indicating that these were all derived from a common ancestor. Using genetic timing, this clade's most recent common ancestor dates to 28,500 YBP.
Subsections (0):

Section: Morphological divergence (2):
The first dogs were certainly wolflike; however, the phenotypic changes that coincided with the dog–wolf genetic divergence are not known. Identifying the earliest dogs is difficult because the key morphological characters that are used by zooarchaeologists to differentiate domestic dogs from their wild wolf ancestors (size and position of teeth, dental pathologies, and size and proportion of cranial and postcranial elements) were not yet fixed during the initial phases of the domestication process. The range of natural variation among these characters that may have existed in ancient wolf populations, and the time it took for these traits to appear in dogs, are unknown.
The fossil record suggests an evolutionary history that may include both morphologically dog-like wolves and wolf-like dogs. If the earliest dogs followed humans scavenging on carcasses that they left behind, then early selection may have favoured a wolf-like morphology. Perhaps when humans became more sedentary and dogs became closely associated with them was there selection for smaller, phenotypically distinct dogs, even if a reduced body size in dogs may have occurred before agriculture.
When, where, and how many times wolves may have been domesticated remains debated because only a small number of ancient specimens have been found, and both archaeology and genetics continue to provide conflicting evidence. The most widely accepted earliest dog remains are those of the Bonn-Oberkassel dog which date to 15,000 YBP. Earlier remains dating back to 30,000 YBP have been described as Paleolithic dogs but their status as dogs or wolves remains debated.
Subsections (0):

Section: Proposed dual ancestry of the domestic dogs of West Asia, Africa and southern Europe (2):
More recent research analysing the genomes of 72 ancient wolves, specimens from Europe, Siberia and North America spanning the past 100,000 years has confirmed that both early and modern dogs are more similar genetically to ancient wolves from Asia than from Europe. This suggests that domestication occurred in the East. The research also found evidence that dogs have a dual ancestry, meaning that two separate populations of wolves contributed DNA to dogs. 
Early dogs from northeastern Europe, Siberia and the Americas appear to have a single, shared origin from the eastern source. But early dogs from the Middle East, Africa and southern Europe appear to have some ancestry from another source related to wolves in the Middle East, in addition to the eastern source. It is possible that wolves underwent domestication more than once, with different populations then mixing together. Or, that domestication happened once only, and that dual ancestry is related to early dogs then mixing with wild wolves. 
The research also demonstrated how wolf DNA changed during the 30,000 generations that were represented in their 100,000-year timeline. This identified the effects of natural selection as particular genes spread within wolf populations. One gene variant, over a period of around 10,000 years, went from being very rare to being present in every wolf, and it is still present in all wolves and dogs today. The variant affects a gene, IFT88, which is involved in the development of bones in the skull and jaw. It is possible that the spread of this variant could have been driven by a change in the types of prey available during the Ice Age, giving an advantage to wolves with a certain head shape.  
""This is the first time scientists have directly tracked natural selection in a large animal [the wolf] over a time-scale of 100,000 years, seeing evolution play out in real time rather than trying to reconstruct it from DNA today,"" said study senior author Pontus Skoglund.
Subsections (0):
, Section: Dog domestication (1):
... Remove domestication from the human species, and there's probably a couple of million of us on the planet, max. Instead, what do we have? Seven billion people, climate change, travel, innovation and everything. Domestication has influenced the entire earth. And dogs were the first. For most of human history, we're not dissimilar to any other wild primate. We're manipulating our environments, but not on a scale bigger than, say, a herd of African elephants. And then, we go into partnership with this group of wolves. They altered our relationship with the natural world. ...
Animal domestication is a coevolutionary process in which a population responds to selective pressure while adapting to a novel niche that included another species with evolving behaviours.
One of the most important transitions in human history was the domestication of animals, which began with the long-term association between wolves and hunter–gatherers more than 15,000 years ago. Dogs were the first domesticated species, the only animal known to have entered into a domestic relationship with humans during the Pleistocene, and the only large carnivore to have been domesticated. It was not until 11,000 YBP that people living in the Near East entered into relationships with wild populations of aurochs, boar, sheep, and goats. A domestication process then began to develop. The earlier association of dogs with humans may have allowed dogs to have a profound influence on the course of early human history and the development of civilization.
The questions of when and where dogs were first domesticated have taxed geneticists and archaeologists for decades. Genetic studies suggest a domestication process commencing over 25,000 YBP, in one or several wolf populations in either Europe, the high Arctic, or eastern Asia. There is clear evidence that dogs were derived from grey wolves during the initial phases of domestication. The wolf population(s) that were involved are likely to be extinct. Despite numerous genetic studies of both modern dogs and ancient dog remains, there is no firm consensus regarding either the timing or location(s) of domestication, the number of wolf populations that were involved, or the long-term effects domestication has had on the dog's genome.
Around 10,000 YBP agriculture was developed resulting in a sedentary lifestyle, along with phenotype divergence of the dog from its wolf ancestors, including variance in size. Two population bottlenecks have occurred to the dog lineage, one due to the initial domestication and one due to the formation of dog breeds.
Subsections (4):
Section: Socialization (2):
Humans and wolves both exist in complex social groups. How humans and wolves got together remains unknown. One view holds that domestication is a process that is difficult to define. The term was developed by anthropologists with a human-centric view in which humans took wild animals (ungulates) and bred them to be ""domestic"", usually in order to provide improved food or materials for human consumption. That term may not be appropriate for a large carnivore such as the dog. This alternate view regards dogs as being either socialized and able to live among humans, or unsocialized. There exist today dogs that live with their human families but are unsocialized and will threaten strangers defensively and aggressively no differently than a wild wolf. There also exists a number of cases where wild wolves have approached people in remote places, attempting to initiate play and to form companionship. One such notable wolf was Romeo, a gentle black wolf that formed relationships with the people and dogs of Juneau, Alaska. This view holds that before there could have been domestication of the wolf, there had to have been its socialization.
Even today, the wolves on Ellesmere Island do not fear humans, which is thought to be due to them seeing humans so little, and they will approach humans cautiously, curiously and closely.
Subsections (0):

Section: Commensal pathway (2):
The dog is a classic example of a domestic animal that likely traveled a commensal pathway into domestication. The dog was the first domesticant, and was domesticated and widely established across Eurasia before the end of the Pleistocene, well before cultivation or the domestication of other animals. It may have been inevitable that the first domesticated animal came from the order of carnivores as these are less afraid when approaching other species. Within the carnivores, the first domesticated animal would need to exist without an all-meat diet, possess a running and hunting ability to provide its own food, and be of a controllable size to coexist with humans, indicating the family Canidae, and the right temperament with wolves being among the most gregarious and cooperative animals on the planet.
Subsections (3):
Section: Human campfire theory (3):
Ancient DNA supports the hypothesis that dog domestication preceded the emergence of agriculture and was initiated close to the Last Glacial Maximum when hunter-gatherers preyed on megafauna, and when proto-dogs might have taken advantage of carcasses left on site by early hunters, assisted in the capture of prey, or provided defense from large competing predators at kill-sites. Wolves were probably attracted to human campfires by the smell of meat being cooked and discarded refuse in the vicinity, first loosely attaching themselves and then considering these as part of their home territory where their warning growls would alert humans to the approach of outsiders. The wolves most likely drawn to human camps were the less-aggressive, subdominant pack members with lowered flight response, higher stress thresholds and less wary around humans, which was the start of a process known as self-domestication, making them better candidates for further domestication.
Subsections (0):

Section: Migratory wolves theory (3):
On the mammoth steppe the wolf's ability to hunt in packs, to share risk fairly among pack members, and to cooperate moved them to the top of the food chain above lions, hyenas and bears. Some wolves followed the great reindeer herds, eliminating the unfit, the weaklings, the sick and the aged, and therefore improved the herd. These wolves had become the first pastoralists hundreds of thousands of years before humans also took to this role. The wolves' advantage over their competitors was that they were able to keep pace with the herds, move fast and enduringly, and make the most efficient use of their kill by their ability to ""wolf down"" a large part of their quarry before other predators had detected the kill. One study proposed that during the Last Glacial Maximum, some of our ancestors teamed up with those pastoralist wolves and learned their techniques.
Many early humans remained gatherers and scavengers, or specialized as fish-hunters, hunter-gatherers, and hunter-gardeners. However, some adopted the pastoralist wolves' lifestyle as herd followers and herders of reindeer, horses, and other hoofed animals. They harvested the best stock for themselves while the wolves kept the herd strong, and this group of humans was to become the first herders and this group of wolves was to become the first dogs.
The remains of large carcasses left by human hunter-gatherers may have led some wolves into entering a migratory relationship with humans. This could have led to their divergence from those wolves that remained in the one territory. A closer relationship between these wolves – or proto-dogs – and humans may have then developed, such as hunting together and mutual defence from other carnivores and other humans. A maternal mDNA, paternal yDNA, and microsatellite assessment of two wolf populations in North America and combined with satellite telemetry data revealed significant genetic and morphological differences between one population that migrated with and preyed upon caribou, and another territorial ecotype population that remained in a boreal coniferous forest. Though these two populations spend a period of the year in the same place, and though there was evidence of gene flow between them, the difference in prey–habitat specialization has been sufficient to maintain genetic and even colouration divergence. A study has identified the remains of a population of extinct Pleistocene Beringian wolves with unique mDNA signatures. The skull shape, tooth wear, and isotopic signatures suggested these were specialist megafauna hunters and scavengers that became extinct while less specialized wolf ecotypes survived. Analogous to the modern wolf ecotype that has evolved to track and prey upon caribou, a Pleistocene wolf population could have begun following mobile hunter-gatherers, thus slowly acquiring genetic and phenotypic differences that would have allowed them to more successfully adapt to the human habitat.
Subsections (0):

Section: Food partitioning theory (3):
Dogs were the only animal to be domesticated by mobile hunter-gatherers. Humans and wolves were both persistent pack hunters of large prey, were competing in overlapping territory, and are both capable of killing each other. One study proposes how humans may have domesticated such a dangerous competitor. Humans and wolves are members of the large carnivore guild, and when there is abundant game the top members leave carcasses for the other members to scavenge. When game is scarce there is often conflict. Humans are unusual members of this guild because their ancestors were primates, therefore their ability to process meat is limited by the capacity of the liver to metabolize protein, and they can only derive 20% of their energy requirements from protein. High protein consumption in humans can lead to illness.
During the harsh winters of the Last Glacial Maximum plant foods would have not been available, and meat would not be the favoured food but fat and grease would be, as is prized by some high-latitude dwelling peoples in modern times. Game meat would have been devoid of fat, but the limbs and crania contain fat deposits, and limb bones contain fatty oils. There is evidence of such processing during this period. Wolves are typical carnivores and can survive on a protein-based diet for months. Calculations of the lipid content of arctic and subarctic game available across the cold steppe environment at this time and today shows that in order to gain the necessary quantity of fat and oils, there would have been enough excess animal calories to feed either proto-dogs or wolves with no need for competition. Hunting together and protection from other predators would have been advantageous to both species, leading to domestication.
Subsections (0):

Section: Genetic changes (2):

Subsections (4):
Section: The Yellow Dog Study (3):
Domestic dogs exhibit diverse coat colours and patterns. In many mammals, different colour patterns are the result of the regulation of the Agouti gene, which can cause hair follicles to switch from making black or brown pigments to yellow or nearly white pigments. The most common coat pattern found in modern wolves is agouti, in which the upperside of the body has banded hairs and the underside exhibits lighter shading. The colour yellow is dominant to the colour black and is found in dogs across much of the world and the dingo in Australia.
In 2021, a study of whole genome sequences taken from dogs and wolves focused on the genetic relationships between them based on coat colour. The study found that most dog colour haplotypes were similar to most wolf haplotypes, however dominant yellow in dogs was closely related to white in arctic wolves from North America. This result suggests a common origin for dominant yellow in dogs and white in wolves but without recent gene flow, because this light colour clade was found to be basal to the golden jackal and genetically distinct from all other canids. The most recent common ancestor of the golden jackal and the wolf lineage dates back to 2 million YBP. The study proposes that 35,000 YBP there was genetic introgression into the Late Pleistocene grey wolf from a ghost population of an extinct canid which had diverged from the grey wolf lineage over 2 million YBP. This colour diversity could be found 35,000 YBP in wolves and 9,500 YBP in dogs. A closely related haplotype exists among those wolves of Tibet which possess yellow shading in their coats. The study explains the colour relationships between modern dogs and wolves, white wolves from North America, yellow dogs, and yellowish wolves from Tibet. The study concludes that during the Late Pleistocene, natural selection laid the genetic foundation for modern coat colour diversity in dogs and wolves.
Subsections (0):

Section: Dietary adaptation (3):
Selection appears to have acted on the dog's metabolic functions to cope with changes in dietary fat, followed later with a dietary increase in starch associated with a more commensal lifestyle.
The dog genome compared to the wolf genome shows signs of having undergone positive selection, these include genes relating to brain function and behaviour, and to lipid metabolism. This ability to process lipids indicates a dietary target of selection that was important when proto-dogs hunted and fed alongside hunter-gatherers. The evolution of the dietary metabolism genes may have helped process the increased lipid content of early dog diets as they scavenged on the remains of carcasses left by hunter-gatherers. Prey capture rates may have increased in comparison to wolves and with it the amount of lipid consumed by the assisting proto-dogs. A unique dietary selection pressure may have evolved both from the amount consumed, and the shifting composition of, tissues that were available to proto-dogs once humans had removed the most desirable parts of the carcass for themselves. A study of the mammal biomass during modern human expansion into the northern Mammoth steppe found that it had occurred under conditions of unlimited resources, and that many of the animals were killed with only a small part consumed or were left unused.

See further: Dietary phenotypic plasticity
Subsections (0):

Section: Behaviour (3):
The key phase in domestication appears to have been changes in social behaviour and its corresponding oxytocin receptor genes and neural-related genes. Behaviour differences between dogs and wolves may be contributed by structural variation in the genes that are associated with human Williams-Beuren syndrome. This syndrome causes increased hyper-sociability, which may have been important during domestication.
In 2014, a whole genome study of the DNA differences between wolves and dogs found that the dogs' tameness was not a reduced fear response but did show greater synaptic plasticity. Synaptic plasticity is widely believed to be the cellular correlate of learning and memory. The study proposes that the improved learning and memory abilities of dogs also helped to lower their level of fear around humans.
Unlike other domestic species which were primarily selected for production-related traits, dogs were initially selected for their behaviours. In 2016, a study found that there were only 11 fixed genes that showed variation between wolves and dogs. These gene variations were unlikely to have been the result of natural evolution, and indicate selection on both morphology and behaviour during dog domestication. There was evidence of selection during dog domestication of genes that affect the adrenaline and noradrenaline biosynthesis pathway. These genes are involved in the synthesis, transport and degradation of a variety of neurotransmitters, particularly the catecholamines, which include dopamine and noradrenaline. Recurrent selection on this pathway and its role in emotional processing and the fight-or-flight response suggests that the behavioural changes we see in dogs compared to wolves may be due to changes in this pathway, leading to tameness and an emotional processing ability. Dogs generally show reduced fear and aggression compared to wolves. Some of these genes have been associated with aggression in some dog breeds, indicating their importance in both the initial domestication and then later in breed formation.
Subsections (0):

Section: Role of epigenetics (3):
Differences in hormonal expression that are associated with domestication syndrome may be linked to epigenetic modifications. A recent study that compared the methylation patterns of dogs with those of wolves found 68 significantly different methylated sites. These included sites which are linked to two neurotransmitter genes associated with cognition. There is a direct association between the dog's social behaviour and OXTR, which is a receptor for the neurotransmitter oxytocin, and this has been caused through the epigenetic methylation of the OXTR gene. DNA methylation differences have been found between wolves and dogs, and between different dog breeds. This implies that epigenetic factors may have been important for both dog domestication and the divergence of dog breeds.
Similar to humans, wolves show strong social and emotional bonds within their groupings, and this relationship might have been the foundation for the evolution of dog-human bonding. In 2019, a literature review led to a new theory named Active Social Domestication, in which the social environment of the dog ancestor induced neuro-physiological changes that caused an epigenetic cascade, which led to the rapid development of domestication syndrome.
Subsections (0):

Section: Dog and human coevolution (2):

Subsections (3):
Section: Parallel evolution (3):
Being the first domesticated species by humans has created a strong bond between dogs and humans and entwined their histories. Dogs accompanied humans when they first migrated into new environments and show similar adaptations – such as to high altitude, low oxygen conditions.
There is an extensive list of genes showing signatures of parallel evolution in dogs and humans. This has led to the study of the coevolution of gene function. 311 genes under positive selection in dogs are related to a large number of overlapping loci which show the same patterns in humans. These genes are involved in traits ranging from digestion and neurological processes to some cancers. For example, it has been inferred from genes which act on the serotonergic system in the brain that coevolution has led to less aggressive behaviour when living in crowded environments.
Dogs also suffer from many of the same common diseases as humans – including cancer, diabetes, heart disease, and neurological disorders. The underlying disease pathologies are similar to those in humans, as are their responses to treatment and resultant outcomes.
Subsections (0):

Section: Behavioural evidence (3):
Convergent evolution is when distantly related species independently evolve similar solutions to the same problem. For example, fish, penguins and dolphins have each separately evolved flippers as a solution to the problem of moving through the water. What has been found between dogs and humans is something less frequently demonstrated: psychological convergence. Dogs have independently evolved to be cognitively more similar to humans than we are to our closest genetic relatives. Dogs have evolved specialized skills for reading human social and communicative behaviour. These skills seem more flexible – and possibly more human-like – than those of other animals more closely related to humans phylogenetically, such as chimpanzees, bonobos and other great apes. This raises the possibility that convergent evolution has occurred: both Canis familiaris and Homo sapiens might have evolved some similar (although obviously not identical) social-communicative skills – in both cases adapted for certain kinds of social and communicative interactions with human beings.
Studies support coevolution in that dogs can follow the human pointing gesture, discriminate the emotional expressions of human faces, and that most people can tell from a bark whether a dog is alone, being approached by a stranger, playing, or being aggressive, and can tell from a growl how big the dog is.
In 2015, a study found that when dogs and their owners interact, extended eye contact (mutual gaze) increases oxytocin levels in both the dog and its owner. As oxytocin is known for its role in maternal bonding, it is considered likely that this effect has supported the coevolution of human–dog bonding.

The dog could have arisen only from animals predisposed to human society by lack of fear, attentiveness, curiosity, necessity, and recognition of advantage gained through collaboration....the humans and wolves involved in the conversion were sentient, observant beings constantly making decisions about how they lived and what they did, based on the perceived ability to obtain at a given time and place what they needed to survive and thrive. They were social animals willing, even eager, to join forces with another animal to merge their sense of group with the others' sense and create an expanded super-group that was beneficial to both in multiple ways. They were individual animals and people involved, from our perspective, in a biological and cultural process that involved linking not only their lives but the evolutionary fate of their heirs in ways, we must assume, they could never have imagined. Powerful emotions were in play that many observers today refer to as love – boundless, unquestioning love.
Subsections (0):

Section: Human adoption of some wolf behaviours (3):
... Isn't it strange that, our being such an intelligent primate, we didn't domesticate chimpanzees as companions instead? Why did we choose wolves even though they are strong enough to maim or kill us? ...
In 2002, a study proposed that immediate human ancestors and wolves may have domesticated each other through a strategic alliance that would change both respectively into humans and dogs. The effects of human psychology, hunting practices, territoriality and social behaviour would have been profound.
Early humans moved from scavenging and small-game hunting to big-game hunting by living in larger, socially more-complex groups, learning to hunt in packs, and developing powers of cooperation and negotiation in complex situations. As these are characteristics of wolves, dogs and humans, it can be argued that these behaviours were enhanced once wolves and humans began to cohabit. Communal hunting led to communal defense. Wolves actively patrol and defend their scent-marked territory, and perhaps humans had their sense of territoriality enhanced by living with wolves. One of the keys to recent human survival has been the forming of partnerships. Strong bonds exist between same-sex wolves, dogs and humans, and these bonds are stronger than exist between other same-sex animal pairs. Today, the most widespread form of inter-species bonding occurs between humans and dogs. The concept of friendship has ancient origins, but it may have been enhanced through the inter-species relationship to give a survival advantage.
In 2003, a study compared the behaviour and ethics of chimpanzees, wolves and humans. Cooperation among humans' closest genetic relative is limited to occasional hunting episodes or the persecution of a competitor for personal advantage, which had to be tempered if humans were to become domesticated. One might therefore argue that the closest approximation to human morality that can be found in nature is that of the grey wolf. Wolves are among the most gregarious and cooperative of animals on the planet, and their ability to cooperate in well-coordinated drives to hunt prey, carry items too heavy for an individual, provisioning not only their own young but also the other pack members, babysitting etc. are rivaled only by that of human societies. Similar forms of cooperation are observed in two closely related canids, the African wild dog and the Asian dhole, therefore it is reasonable to assume that canid sociality and cooperation are old traits that in terms of evolution predate human sociality and cooperation. Today's wolves may even be less social than their ancestors, as they have lost access to large herds of ungulates and now tend more toward a lifestyle similar to coyotes, jackals, and even foxes. Social sharing within families may be a trait that early humans learned from wolves, and, with wolves digging dens long before humans constructed huts, it is not clear who domesticated whom.
Subsections (0):
, Section: First dogs (1):

Subsections (10):
Section: Dogs domesticated in East Asia (2):
Savolainen looking at mitochondrial DNA shows that an initial phase of dog domestication began in China or Southeast Asia 33,000 years ago, and a second phase 18,000 years later in which the dog migrated out of Southeast Asia towards Africa and the Middle East. Arriving in Europe, around 10,000 years ago, giving rise to modern dog breeds.
Savolainen pointed out that many studies that contradicted the origin of dog domestication from China or elsewhere in Southeast Asia, did not include wolf or dog samples from China or Southeast Asia.
Subsections (0):

Section: Dogs domesticated in Siberia 23,000 years ago (2):
Locating the origin of dogs is made difficult by the lack of data on extinct Pleistocene wolves, the small morphological changes that occurred between wild and domestic populations during the first phases of domestication, and the lack of an accompanying human material culture at this time.
In 2016, a genetic study found that ancient and modern dogs fall into an Eastern Eurasian clade and a Western Eurasian clade. In 2017, another genetic study found evidence of a single dog-wolf divergence occurring between 36,900 and 41,500 YBP, followed by a divergence between Eastern Eurasian and Western Eurasian dogs 17,500–23,900 YBP and this indicates a single dog domestication event occurring between 20,000 and 40,000 YBP.
In 2021, a review of the current evidence infers from the timings provided by DNA studies that the dog was domesticated in Siberia 23,000 years ago by ancient North Siberians. The dog later dispersed from Siberia with the migration of peoples eastwards into the Americas and westwards across Eurasia. The ancient North Siberians were once a people whose ancestors archaeological remains have been found at the Paleolithic Yana RHS (Rhinoceros Horn Site) on the Yana River delta in arctic northern Siberia that is dated 31,600 YBP, and at the Mal'ta site near Lake Baikal in southern Siberia just north of Mongolia that is dated 24,000 YBP. Ancient dog remains dating to this time and place have yet to be discovered to support this hypothesis.
The review theorizes that the harsh climate of the Last Glacial Maximum may have brought humans and wolves closer together while they were isolated inside refuge areas. Both species hunt the same prey, and their increased interactions may have resulted in the shared scavenging of kills, wolves drawn to human campsites, a shift in their relationship, and eventually domestication.
Mitochondrial DNA indicates that almost all modern dogs fall into one of four monophyletic haplogroups which are named haplogroups A, B, C, and D. The majority of dogs fall within haplogroup A. The mDNA ""molecular clock"" indicates that 22,800 YBP the first genetic divergence (split) occurred in haplogroup A, resulting in the lineages A1b and A2. This timing is the oldest known between any two dog mDNA lineages. As humans migrated across Siberia, through Beringia, and down through the Americas, archaeological remains indicate that their mDNA lineages diverged several times. Based on these timings, and the timings of several dog divergences found from early dog remains across these regions, it was discovered that there was a correlation between human and dog migrations and population divergences. This correlation suggests that where people went, their dogs also went. Tracing back through these human and dog lineages and timings led to the inference that the dog was first domesticated in Siberia nearly 23,000 YBP by North Siberians.
Another study undertook an analysis of the complete mitogenome sequences of 555 modern and ancient dogs. The sequences showed an increase in the population size approximately 23,500 YBP, which broadly coincides with the proposed genetic divergence of the ancestors of dogs from modern wolves. A ten-fold increase in the population size occurred after 15,000 YBP, which is consistent with the demographic dependence of dogs on the human population.
Earlier in 2018, a study proposes that the Yana site showed evidence of wolf pre-domestication. There are remains of medium-sized canids found there that could not be referred to as dogs, however they showed indications of living with people. These included worn and partially-missing teeth, and the skull of an almost-adult showing juvenile features. The morphologic and morphometric anomalies in the specimens indicate commensalism and the earliest stage of domestication.
Subsections (0):

Section: Admixture (2):
Studies indicate admixture between the dog-wolf ancestor and golden jackals. However, since domestication, there was almost negligible gene flow from wolves into dogs but substantial gene flow from dogs into wolves. There were some wolves that were related to all ancient and modern dogs. A very small amount of gene flow was detected between coyotes and ancient American dogs, and between the African wolf and African dogs but in which direction could not be determined. The short divergence time between dogs and wolves followed by their continuous admixture has led to 20% of the genome of East Asian wolves and 7–25% of the genome of European and Middle Eastern wolves showing contributions from dogs. The β-defensin gene responsible for the black coat of North American wolves was the result of a single introgression from early Native American dogs in the Yukon between 1,600 and 7,200 YBP. Dogs and wolves living in the Himalayas and on the Tibetan plateau carry the EPAS1 allele that is associated with high-altitude oxygen adaptation, which has been contributed by a ghost population of an unknown wolf-like canid. This ghost population is deeply-diverged from modern Holarctic wolves and dogs, and has contributed 39% to the Himalayan wolf's nuclear genome. Limited gene flow has likely occurred in arctic dogs.
Subsections (0):

Section: Bonn-Oberkassel dog (2):
The earliest generally accepted dog remains were discovered in Bonn-Oberkassel, Germany. Contextual, isotopic, genetic, and morphological evidence shows that this dog was clearly not a local wolf. The dog was dated to 14,223 YBP.
In 1914, on the eve of the First World War, two human skeletons were discovered during basalt quarrying at Oberkassel, Bonn in Germany. With them were found a right mandible of a ""wolf"" and other animal bones. After the end of the First World War, in 1919 a full study was made of these remains. The mandible was recorded as ""Canis lupus, the wolf"" and some of the other animal bones were assigned to it. The remains were then stored and forgotten for fifty years. In the late 1970s there was renewed interest in the Oberkassel remains and the mandible was re-examined and reclassified as belonging to a domesticated dog. The mitochondrial DNA sequence of the mandible was matched to Canis familiaris – a dog and falls within mDNA haplogroup C of dogs. The bodies were dated to 14,223 YBP. This implies that in Western Europe there were morphologically and genetically ""modern"" dogs in existence around 14,500 YBP.
Later studies assigned more of the other animal bones to the dog until most of a skeleton could be assembled. The humans were a man aged 40 years and a woman aged 25 years. All three skeletal remains were found sprayed with red hematite powder and covered with large 20 cm thick basalt blocks. The consensus is that a dog was buried along with two humans. A tooth belonging to a smaller and older dog was also identified but it had not been sprayed with red powder. The cause of the death of the two humans is not known. A pathology study of the dog remains suggests that it had died young after suffering from canine distemper between ages 19 and 23 weeks. The dog could not have survived during this period without intensive human care. During this period the dog was of no utilitarian use to humans, and suggests the existence of emotional or symbolic ties between these humans and this dog. In conclusion, near the end of the Late Pleistocene at least some humans regarded dogs not just materialistically, but had developed emotional and caring bonds for their dogs.
Subsections (0):

Section: Ice Age dogs (2):
In 2020, the sequencing of ancient dog genomes indicates that dogs share a common ancestry and descended from an ancient, now-extinct wolf population – or closely related wolf populations – which was distinct from the modern wolf lineage. By the close of the last Ice Age (11,700 YBP), five ancestral lineages had diversified from each other and were expressed in dog samples taken from the Neolithic era Levant (7,000 YBP), Mesolithic era Karelia (10,900 YBP), Mesolithic era Baikal (7,000 YBP), ancient America (4,000 YBP), and the New Guinea singing dog (present day).
The world's ancient and modern dog population structure can be classified into Arctic/Americas, East Asian, and West Eurasian. The Arctic/Americas lineage includes modern arctic breeds, a 9,500 YBP dog from Zhokhov Island, ancient pre-European contact American dogs, mid-Holocene dogs from Lake Baikal, historical dogs from across Siberia, and dogs from the Yamalo-Nenets Autonomous Okrug region in northwestern Siberia. The East Asian lineage includes modern dogs from China, Vietnam, Island South East Asia, and the dingo and the New Guinea singing dog that represent unadmixed East Asian ancestry. The West Eurasian lineage includes ancient Levantine and ancient Near Eastern dogs, ancient and modern European dogs, modern African dogs, and Bronze Age dogs from the Eurasian Steppe.
Ancient and modern European dogs have a closer relationship with arctic dogs than do Near Eastern dogs, indicating a major admixture event in Europe. Analyses of a recently sequenced genome from the Mesolithic site of Veretye, Karelia (~10,000 YBP) in Northeast Europe recapitulate findings that show these dogs possessed ancestry related to both Arctic (~70%) and Western Eurasian (~30%) lineages. This suggests that other modern and ancient (post-Mesolithic) European dogs sequenced to date, Mesolithic dogs in Europe already possessed both Arctic and Western Eurasian ancestry. The fact that the ancient Siberian dog from Zhokhov Island, dated ~1,000 years after the Veretye, Karelia dogs, possesses no Western Eurasian ancestry, indicates that Western dog ancestry had not yet reached the Siberian Arctic by 9,500 YBP. The 9,500 YBP Zhokhov dog is more closely related to a 6,000 YBP dog from Lake Baikal than related to the ancient dogs found in North America, which supports that a genetic split had occurred between the early Arctic and North American dogs and that their common ancestor dates much older than the 9,500 YBP Zhokhov dog The earliest Neolithic European dog dated 7,000 YBP was found to be a mixture of the Karelian and the Levantine lineages. The lineage of a Neolithic dog dated 5,000 YBP found in southwestern Sweden was the ancestor of 90-100% of modern European dogs. This implies that in Europe a population of half-Karelian and half-Levantine dogs similar to this one – but not necessarily originating in Sweden – replaced all of the other dog populations. These findings together support a dual ancestry for modern European dogs, which possess 54% Karelian and 46% Levantine ancestries.
Siberian dogs were genetically similar 9,500–7,000 YBP showing Arctic ancestry, however the introduction of dogs from the Eurasian Steppe and Europe led to substantial genetic admixture, with ancient and historical Siberian dogs exhibiting varying levels of Arctic and Near East ancestry. Dogs from the Bronze Age Eurasian Steppe exhibited 40% ancient arctic and 60% ancient Near East ancestry until the Middle Ages. This implies that dogs migrated as part of the Neolithic expansion of farming from the Near East into the steppes. In the Yamalo-Nenets Autonomous Okrug region in northwestern Siberia, dogs from 2,000 YBP were less related to the dogs of the Eurasian Steppe and Europe than dogs 1,000 YBP. The archaeological presence of glass beads and metal items indicate that this region was connected to a large trade network which included the Near East, the Black Sea region, and the Eurasian Steppe which led to the acquiring of dogs from these regions. The acquisition of dogs from the Near East adapted to farming, and the Eurasian Steppe adapted to pastoralism, may have provided behavioural and morphological characteristics when admixed with Arctic dogs, leading to their adaptation from foraging to reindeer pastoralism. Two dog specimens that are nearly 100 years old and obtained from the Nenets people on the Yamal Peninsula found that these are related to two specimens dated 2,000 years old and 850 years old, which suggests continuity of the lineage in this region. The two 100 year old dogs were closely related with the Samoyed breed. Siberian Huskies show a genetic affinity with historical East Siberian dogs and ancient Lake Baikal dogs. Together, this indicates that the ancient arctic lineage lives on in some modern Siberian breeds.
Ancient dog genomes were compared with ancient human genomes across time, space, and cultural context to reveal that these generally matched each other. These generally share similar features but they differ across time. There were some large differences: the same dogs could be found in both the Neolithic Levant and later in Chalcolithic Iran (5,800 YBP) although the human populations of each were different; in Neolithic Ireland (4,800 YBP) and Germany (7,000 YBP) the dogs are more associated with northern European hunter-gatherers while the humans were more associated with people from the Levant; and on the Bronze Age Pontic–Caspian steppe (3,800 YBP) and in Corded Ware culture Germany (4,700 YBP) the human population had shifted away from the Neolithic European populations but the dogs had not. European dogs have a stronger genetic relationship to Siberian and ancient American dogs than to the New Guinea singing dog, which has an East Asian origin, reflecting an early polar relationship between humans in the Americas and Europe. People living in the Lake Baikal region 18,000–24,000 YBP were genetically related to western Eurasians and contributed to the ancestry of Native Americans, however these were then replaced by other populations. Ten thousand years later, around 7,000 YBP, the dogs in the Lake Baikal region still exhibited a relationship with Europe and the Americas. This implies that there was a shared population structure for both dogs and humans across circumpolar northern Eurasia.
Ancient human genomes show a major ancestry transformation which coincided with the expansion of Neolithic farmers from the Near East into Europe. Ancient dog mitochondria suggests these were accompanied by dogs, which led to an associated ancestry transformation for dogs in Europe. The expansions of steppe pastoralists associated with the Corded Ware culture and the Yamnaya culture into Late Neolithic and Bronze Age Europe transformed the ancestry of human populations but their accompanying dogs had no major impact on European dog populations. The steppe pastoralists also expanded eastwards but had little impact on the ancestry of East Asian people. However, many Chinese dogs appear to be a product of admixture between the lineage of a 3,800 YBP western Eurasian Srubnaya culture dog and the ancestor of the dingo and New Guinea singing dog. Populations of modern Siberian dogs also show ancestry from 7,000 YBP Lake Baikal dogs but little or no New Guinea singing dog ancestry, indicating no East Asian ancestry.
The AMY2B gene codes a protein which assists with the first step in the digestion of dietary starch and glycogen. An expansion of this gene would enable early dogs to exploit a starch-rich diet. At the beginning of agriculture, only some dogs possessed this adaptation which became widespread several thousand years later.
Dogs migrated alongside humans but the movement of the two did not always align, indicating that in some cases humans migrated without dogs or that dogs moved between human groups, possibly as a cultural or trade item. Dogs appear to have been dispersed across Eurasia and into the Americas without any major human population movement being involved, which remains a mystery. Past studies have suggested the dog's place of origin but these studies were based upon today's patterns of genomic diversity or possible links to modern wolf populations. The dog's history was obscured to these studies because of recent gene flow and population dynamics – the geographical origin of the dog remains unknown.
Subsections (0):

Section: First dogs as a hunting technology (2):
During the Upper Paleolithic (50,000–10,000 YBP), the increase in human population density, advances in blade and hunting technology, and climate change may have altered prey densities and made scavenging crucial to the survival of some wolf populations. Adaptations to scavenging such as tameness, small body size, and a decreased age of reproduction would reduce their hunting efficiency further, eventually leading to obligated scavenging. Whether these earliest dogs were simply human-commensal scavengers or they played some role as companions or hunters that hastened their spread is unknown.
Researchers have proposed that in the past a hunting partnership existed between humans and dogs that was the basis for dog domestication.
Petroglyph rock art dating to 8,000 YBP at the sites of Shuwaymis and Jubbah, in northwestern Saudi Arabia, depict large numbers of dogs participating in hunting scenes with some being controlled on a leash. The transition from the Late Pleistocene into the early Holocene was marked by climatic change from cold and dry to warmer, wetter conditions and rapid shifts in flora and fauna, with much of the open habitat of large herbivores being replaced by forests. In the early Holocene, it is proposed that along with changes in arrow-head technology that hunting dogs were used by hunters to track and retrieve wounded game in thick forests. The dog's ability to chase, track, sniff out and hold prey can significantly increase the success of hunters in forests, where human senses and location skills are not as sharp as in more open habitats. Dogs are still used for hunting in forests today.
Subsections (0):

Section: Arctic breeds (2):

Subsections (3):
Section: First dog breeds developed in arctic northeastern Siberia (3):
The domestic dog was present 9,500 YBP on what is now Zhokhov Island, arctic northeastern Siberia. The archaeological discoveries at the Zhokhov site includes the remains of dog harness straps similar to those used by the modern Inuit, the bone remains of polar bears and reindeer which suggests a wide hunting range and the transport of large body parts back to the site, and tools made from obsidian transported from 1,500 kilometres away. These findings suggest long-distance transport through the use of sled dogs.
A study of dog remains indicates that these were selectively bred to be either as sled dogs or as hunting dogs, which implies that a sled dog standard and a hunting dog standard existed at that time. The optimal maximum size for a sled dog is 20–25 kg based on thermo-regulation, and the ancient sled dogs were between 16 and 25 kg. The same standard has been found in the remains of sled dogs from this region 2,000 YBP and in the modern Siberian husky breed standard. Other dogs were more massive at 30 kg and appear to be dogs that had been crossed with wolves and used for polar bear hunting. At death, the heads of the dogs had been carefully separated from their bodies by humans, probably for ceremonial reasons.
The study proposes that after having diverged from the common ancestor shared with the grey wolf, the evolution of the dog proceeded in three stages. The first was natural selection based on feeding behaviour within the ecological niche that had been formed through human activity. The second was artificial selection based on tamability. The third was directed selection based on forming breeds that possessed qualities to help with specific tasks within the human economy. The process commenced 30,000–40,000 YBP with its speed increasing in each stage until domestication became complete.
The Zhokhov dogs are the oldest known dogs to exhibit colour patterns. These possessed black colour patterns on their backs, which helped to distinguish them from white arctic wolves.
Subsections (0):

Section: Dogs enter North America from northeastern Siberia (3):
Material culture provides evidence for dog harnessing in the Arctic 9,000 YBP. Ancient DNA from the remains of these dogs indicates that they belong to the same genetic lineage as modern Arctic dogs, and that this lineage gave rise to the earliest native American dogs. Since the earliest native American dogs, multiple, genetically different lineages of dogs were introduced by the Thule people and European settlers. The European dogs replaced the dog lineages that were introduced more than 10,000 years ago.
In North America, the earliest dog remains were found in Lawyer's Cave on the Alaskan mainland east of Wrangell Island in the Alexander Archipelago of southeast Alaska, radiocarbon dating indicates 10,150 YBP. A genetic-based estimate indicates that this dog's lineage had split from the Siberian Zhokhov Island dog lineage 16,700 YBP. This timing coincides with the suggested opening of the North Pacific coastal route into North America. Stable isotope analysis can be used to identify some chemical elements, allowing researchers to make inferences about the diet of a species. An isotope analysis of bone collagen indicates a marine diet. The next earliest dogs were found in Illinois and radiocarbon dating indicates 9,900 YBP. These include three isolated burials at the Koster Site near the lower Illinois River in Greene County, and one burial 35 km away at the Stilwell II site in Pike County. These dogs were medium-sized adults around 50 cm (20 in) in height and around 17 kilograms (37 lb) in weight, with very active lifestyles and varied morphologies. Stable isotope analysis indicates a diet consisting largely of freshwater fish. Similar dog burials across Eurasia are thought to be due to the dog's importance in hunting to people who were trying to adapt to the changing environments and prey species during the Pleistocene-Holocene transition. In these places, the dog had gained an elevated social status.
In 2018, a study compared sequences of North American dog fossils with Siberian dog fossils and modern dogs. The nearest relative to the North American fossils was a 9,000 YBP fossil discovered on Zhokhov Island, arctic north-eastern Siberia, which was connected to the mainland at that time. The study inferred from mDNA that all of the North American dogs shared a common ancestor dated 14,600 YBP, and this ancestor had diverged along with the ancestor of the Zhokhov dog from their common ancestor 15,600 YBP. The timing of the Koster dogs shows that dogs entered North America from Siberia 4,500 years after humans did, were isolated for the next 9,000 years, and after contact with Europeans these no longer exist because they were replaced by Eurasian dogs. The (earlier wave of, prior to the Thule/Inuit introduction) pre-contact dogs exhibit a unique genetic signature that is now gone, with nDNA indicating that their nearest genetic relatives today are the arctic breed dogs: Alaskan malamutes, Greenland dogs, and Alaskan huskies and Siberian huskies.
In 2019, a study found that those dogs brought initially into the North American Arctic from northeastern Siberia were later replaced by dogs accompanying the Inuit during their expansion beginning 2,000 years ago. These Inuit dogs were more genetically diverse and more morphologically divergent when compared with the earlier dogs. Today, Arctic sledge dogs are among the last descendants in the Americas of this pre-European dog lineage. In 2020, the sequencing of ancient dog genomes indicates that in two Mexican breeds the Chihuahua retains 4% and the Xoloitzcuintli 3% pre-colonial ancestry.
Subsections (0):

Section: Late Pleistocene wolf admixture (3):
In 2015, a study mapped the first genome of a 35,000 YBP Pleistocene wolf fossil found in the Taimyr Peninsula, arctic northern Siberia and compared it with those of modern dogs and grey wolves. The Taimyr wolf was identified through mDNA as Canis lupus but from a population which had diverged from the dog–grey wolf lineage immediately before the dog and grey wolf diverged from each other, which implies that the majority of grey wolf populations today stems from an ancestral population that lived less than 35,000 years ago but before the inundation of the Bering Land Bridge with the subsequent isolation of Eurasian and North American wolves.
The Taimyr wolf was equally related to both dogs and modern wolves, but shared more alleles (i.e. gene expressions) with those breeds that are associated with high latitudes and arctic human populations: the Siberian husky and Greenland dog, and to a lesser extent the Shar Pei and Finnish spitz. The Greenland dog shows 3.5% Taimyr wolf ancestry, which indicates admixture between the Taimyr wolf population and the ancestral dog population of these four high-latitude breeds. These results can be explained either by a very early presence of dogs in northern Eurasia or by the genetic legacy of the Taimyr wolf being preserved in northern wolf populations until the arrival of dogs into high latitudes. This introgression could have provided early dogs living in high latitudes with adaptations to the new and challenging environment. It also indicates that the ancestry of present-day dog breeds descends from more than one region.: 3–4  An attempt to explore admixture between the Taimyr wolf and grey wolves produced unreliable results.: 23 
As the Taimyr wolf had contributed to the genetic makeup of the Arctic breeds, this indicates that the descendants of the Taimyr wolf survived until dogs were domesticated in Europe and arrived at high latitudes where they mixed with local wolves, and these both contributed to the modern Arctic breeds. Based on the most widely accepted oldest zooarchaeological dog remains, domestic dogs most likely arrived at high latitudes within the last 15,000 years.
The nuclear genome sequence was generated for a dog specimen that was found in the Late Neolithic passage grave at Newgrange, Ireland and radiocarbon dated at 4,800 YBP. A genetic analysis of the Newgrange dog showed that it was male, did not possess genetic variants associated with modern coat length or colour, was not as able to process starch as efficiently as modern dogs but more efficiently than wolves, and showed ancestry from a population of wolves that could not be found in other dogs or wolves today. The mutation rates calibrated from both the Taimyr wolf and the Newgrange dog genomes suggest that the modern wolf and dog populations diverged from a common ancestor between 20,000 and 60,000 YBP. This indicates that either dogs were domesticated much earlier than their first appearance in the archaeological record, or they arrived in the Arctic early, or both. Another view is that because northern breeds can trace at least some of their ancestry back to the Taimyr wolf, this indicates the possibility of more than one domestication event.
In 2020, the nuclear genome was generated of a 33,000 YBP Pleistocene wolf from an archaeological site on the Yana River, arctic northeastern Siberia. The Yana wolf sequence was more closely related to the 35,000 YBP Taimyr wolf than it was to modern wolves. There was evidence of gene flow between the Yana-Taimyr wolves and the Pre-Columbian, Zhokhov, and modern sled dogs. This suggests that genetic admixture has occurred between the Pleistocene wolves and the ancestor of these dogs. There was no evidence of admixture between sled dogs and the modern grey wolf for the past 9,500 years. Greenland sled dogs have been kept isolated from other breeds since their arrival in Greenland with the Inuit 850 years ago. Their lineage traces more genomic history to the Zhokhov dogs than any other arctic breed. Sled dogs do not show an adaptation to a starch-rich diet when compared with other dogs but do show an adaptation to a high intake of fat and fatty acids, which was not found in the Zhokhov dogs. The same adaptation has been found in Inuit and other arctic peoples. This suggests that the sled dogs adapted to the low starch and high fat diet of the people they coexisted with.
In 2021, a study of another four Late Pleistocene northeast Siberian wolf sequences showed that they are genetically similar to the Taimyr and Yana wolves. These six extinct wolves sequentially branched off from the lineage that leads to the modern wolf and dog. The 50,000 YBP Tirekhtyakh River, 48,000 YBP Bunge-Toll site, and 32,000 YBP Yana RHS specimens were separate lineages not related to each other. The 16,800 YBP Ulakhan Sular and the 14,100 YBP Tumat specimens both cluster with a modern wolf from Ellesmere Island, indicating that these two specimens derive from the same lineage as the North American wolves. All six Late Pleistocene wolves share alleles with Arctic dogs: Greenland dogs, Siberian and Alaskan huskies, Alaskan malamutes, the extinct Zhokhov dog and the extinct pre-European contact dogs of North America. It is possible that another population of extinct wolves, that were related to all six specimens, may have contributed to the ancestry of the Arctic dogs. There was evidence that four of the extinct Siberian wolves had contributed to the ancestry of modern wolf populations in Shanxi, western China, and possibly Chukotka and Inner Mongolia.
Subsections (0):

Section: Dogs enter Japan (2):
The oldest fossil of a dog that has been found in Japan dates to 9,500 YBP. With the beginning of the Holocene and its warmer weather, temperate deciduous forests rapidly spread onto the main island of Honshu and caused an adaption away from hunting megafauna (Naumann's elephant and Yabe's giant deer) to hunting the quicker sika deer and wild boar in dense forest. With this came a change in hunting technology, including a shift to smaller, triangular points for arrows. A study of the Jōmon people that lived on the Pacific coast of Honshu during the early Holocene shows that they were conducting individual dog burials and were probably using dogs as tools for hunting sika deer and wild boar, as hunters in Japan still do today.
Hunting dogs make major contributions to forager societies and the ethnographic record shows them being given proper names, treated as family members, and considered separate to other types of dogs. This special treatment includes separate burials with markers and grave-goods, with those that were exceptional hunters or that were killed on the hunt often venerated. A dog's value as a hunting partner gives them status as a living weapon and the most skilled elevated to taking on a ""personhood"", with their social position in life and in death similar to that of the skilled hunters.
Intentional dog burials together with ungulate hunting is also found in other early Holocene deciduous forest forager societies in Europe and North America, indicating that across the Holarctic temperate zone hunting dogs were a widespread adaptation to forest ungulate hunting.
Subsections (0):

Section: Dogs from the Near East enter Africa (2):
In 2020, the sequencing of ancient dog genomes indicates that the lineage of modern dogs in sub-Sahara Africa shares a single origin from the Levant, where an ancestral specimen was dated to 7,000 YBP. This finding mirrors the gene flow of humans from the Levant into Africa during the Neolithic, along with cattle. Since then, there has been limited gene flow into African dogs until the past few hundred years. The descendants of a dog from Iran dated 5,800 YBP and dogs from Europe completely replaced the Levant dog lineage 2,300 YBP. This was associated with human migration from Iran and some minor migration from Europe. Today all Near Eastern dogs show 81% ancient Iranian and 19% Neolithic European ancestry.
The oldest dog remains to be found in Africa date 5,900 YBP and were discovered at the Merimde Beni-Salame Neolithic site in the Nile Delta, Egypt. The next oldest remains date 5,500 YBP and were found at Esh Shareinab on the Nile in Sudan. This suggests that the dog arrived from Asia at the same time as domestic sheep and goats. The dog then spread north to south down Africa beside livestock herders, with remains found in archaeological sites dated 925–1,055 YBP at Ntusi in Uganda, dated 950–1,000 YBP at Kalomo in Zambia, and then at sites south of the Limpopo River and into southern Africa. In 2020, the sequencing of ancient dog genomes indicates that the southern African Rhodesian Ridgeback retains 4% pre-colonial ancestry.
Subsections (0):

Section: Dogs enter South East Asia and Oceania from southern China (2):
In 2020, an mDNA study of ancient dog fossils from the Yellow River and Yangtze River basins of southern China showed that most of the ancient dogs fell within haplogroup A1b, as do the Australian dingoes and the pre-colonial dogs of the Pacific, but in low frequency in China today. The specimen from the Tianluoshan archaeological site, Zhejiang province dates to 7,000 YBP and is basal to the entire lineage. The dogs belonging to this haplogroup were once widely distributed in southern China, then dispersed through Southeast Asia into New Guinea and Oceania, but were replaced in China 2,000 YBP by dogs of other lineages.
Subsections (0):
, Section: See also (1):
Dog breed
Dog type
Domesticated silver fox, a rare domesticated canine derived from a melanistic population of the red fox (Vulpes vulpes)
Fuegian dog, an extinct domesticated canine derived from the culpeo (Lycalopex culpaeus)
Hare Indian Dog, an extinct domesticated canine hypothesized to be a domesticated form of the coyote (Canis latrans)
Dusicyon, an extinct genus of canine hypothesized to have been domesticated
Subsections (0):
, Section: References (1):

Subsections (0):
, Section: Bibliography (1):
Derr, Mark (2011). How the Dog Became the Dog: From Wolves to Our Best Friends. Penguin Group. ISBN 978-1-4683-0269-1.
Pierotti, R.; Fogg, B. (2017). The First Domestication: How Wolves and Humans Coevolved. Yale University Press. ISBN 978-0-300-22616-4.
Shipman, P. (2015). The Invaders:How humans and their dogs drove Neanderthals to extinction. Harvard University Press. ISBN 978-0-674-73676-4.
Subsections (0):
]"
5,"Category:Origins (id: 29739395, ns: 14)",0,List of domesticated animals,"This page gives a list of domesticated animals, also including a list of animals which are or may be currently undergoing the process of domestication and animals that have an extensive relationship with humans beyond simple predation. This includes species which are semi-domesticated, undomesticated but captive-bred on a commercial scale, or commonly wild-caught, at least occasionally captive-bred, and tameable. In order to be considered fully domesticated, most species have undergone significant genetic, behavioural and morphological changes from their wild ancestors, while others have changed very little from their wild ancestors despite hundreds or thousands of years of potential selective breeding. A number of factors determine how quickly any changes may occur in a species, but there is not always a desire to improve a species from its wild form. Domestication is a gradual process, so there is no precise moment in the history of a given species when it can be considered to have become fully domesticated.
Zooarchaeology has identified three classes of animal domesticates:

Pets (dogs, cats, ferrets, hamsters, etc.)
Livestock (cattle, sheep, pigs, goats, etc.)
Beasts of burden (horses, camels, donkeys, etc.)","[Section: Domesticated animals (1):

Subsections (0):
, Section: Tame, partially domesticated, and widely captive-bred animals (1):
Due to the somewhat unclear outlines of what precisely constitutes domestication, there are some species that may or may not be fully domesticated. There are also some species that are extensively commercially used by humans, but are not significantly altered from wild-type animals. Many animals on this second table are at least somewhat altered from wild-type animals due to their extensive interactions with humans, albeit not to the point that they are regarded as distinct forms (therefore, no separate wild ancestors are noted) or would be unable to survive if reintroduced to the wild.
Subsections (0):
, Section: Taxonomical groupings (1):
The categories used in the Taxon group column are: 

1a: Artiodactyla except Bovidae, 1b: Bovidae, 1c: Carnivora, 1d: Rodentia, 1e: Other mammals
2a: Anseriformes, 2b: Galliformes, 2c: Columbiformes, 2d: Passeriformes, 2e: Psittaciformes, 2f: Palaeognathae , 2g: Other birds
3a: Serpentes, 3b: Lacertilia, 3c:  Testudines, 3d: Other reptiles
4a: Anura, 4b: Other amphibians
5a: Cyprinidae, 5b: Other fish
6a: Hymenoptera, 6b: Other insects, 6c: Other arthropods
7a: Mollusca, 7b: Annelida, 7c: Other animals
Subsections (0):
, Section: See also (1):
List of domesticated plants
List of domesticated fungi and microorganisms


== References ==
Subsections (0):
]"
6,"Category:Origins (id: 29739395, ns: 14)",0,Etiology,"Etiology (; alternatively spelled aetiology or ætiology) is the study of causation or origination. The word is derived from the Greek word αἰτιολογία (aitiología), meaning ""giving a reason for"" (from  αἰτία (aitía) 'cause', and  -λογία (-logía) 'study of'). More completely, etiology is the study of the causes, origins, or reasons behind the way that things are, or the way they function, or it can refer to the causes themselves. The word is commonly used in medicine (pertaining to causes of disease) and in philosophy, but also in physics, biology, psychology, government, geography, spatial analysis and theology in reference to the causes or origins of various phenomena.
In the past, when many physical phenomena were not well understood or when histories were not recorded, myths often arose to provide etiologies. Thus, an etiological myth, or origin myth, is a myth that has arisen, been told over time or written to explain the origins of various social or natural phenomena. For example, Virgil's Aeneid is a national myth written to explain and glorify the origins of the Roman Empire. In theology, many religions have creation myths explaining the origins of the world or its relationship to believers.","[Section: Medicine (1):
In medicine, the etiology of an illness or condition refers to the frequent studies to determine one or more  factors that come together to cause the illness. Relatedly, when disease is widespread, epidemiological studies investigate what associated factors, such as location, sex, exposure to chemicals, and many others, make a population more or less likely to have an illness, condition, or disease, thus helping determine its etiology. Sometimes determining etiology is an imprecise process. In the past, the etiology of a common sailor's disease, scurvy, was long unknown. When large, ocean-going ships were built, sailors began to put to sea for long periods of time, and often lacked fresh fruit and vegetables. Without knowing the precise cause, Captain James Cook suspected scurvy was caused by the lack of vegetables in the diet.  Based on his suspicion, he forced his crew to eat sauerkraut, a cabbage preparation, every day, and based upon the positive outcomes, he inferred that it prevented scurvy, even though he did not know precisely why. It took about another two hundred years to discover the precise etiology; the lack of vitamin C in a sailor's diet.
The following are examples of intrinsic factors:

Inherited conditions, or conditions that are passed down to you from your parents. An example of this is hemophilia, a disorder that leads to excessive bleeding.
Metabolic and endocrine, or hormone, disorders. These are abnormalities in the chemical signaling and interaction in the body. For example, Diabetes mellitus is an endocrine disease that causes high blood sugar.
Neoplastic disorders or cancer where the cells of the body grow out of control.
Problems with immunity, such as allergies, which are an overreaction of the immune system.
Subsections (0):
, Section: Mythology (1):
An etiological myth, or origin myth, is a myth intended to explain the origins of cult practices, natural phenomena, proper names and the like. For example, the name Delphi and its associated deity, Apollon Delphinios, are explained in the Homeric Hymn which tells of how Apollo, in the shape of a dolphin (delphis),  propelled Cretans over the seas to make them his priests. While Delphi is actually related to the word delphus (""womb""), many etiological myths are similarly based on folk etymology (the term ""Amazon"", for example). In the Aeneid (published c. 17 BC), Virgil claims the descent of Augustus Caesar's Julian clan from the hero Aeneas through his son Ascanius, also called Iulus. The story of Prometheus' sacrifice trick at Mecone in Hesiod's Theogony relates how Prometheus tricked Zeus into choosing the bones and fat of the first sacrificial animal rather than the meat to justify why, after a sacrifice, the Greeks offered the bones wrapped in fat to the gods while keeping the meat for themselves. In Ovid's Pyramus and Thisbe, the origin of the color of mulberries is explained, as the white berries become stained red from the blood gushing forth from their double suicide.
Subsections (0):
, Section: See also (1):
Backstory
Bradford Hill criteria
Correlation does not imply causation
Creation myth
Just-so story
Just So Stories
Pathology
Pourquoi story
Problem of causation
Involution (esoterism)
Subsections (0):
, Section: References (1):

Subsections (0):
, Section: External links (1):
 The dictionary definition of etiology at Wiktionary
Subsections (0):
]"
7,"Category:Origins (id: 29739395, ns: 14)",0,Origins of Judaism,"The origins of Judaism lie in Bronze Age polytheistic Canaanite religion. Judaism also  syncretized elements of other Semitic religions such as Babylonian religion, which is reflected in the early prophetic books of the Hebrew Bible.
During the Iron Age I period (12th to 11th centuries BCE),
the religion of the Israelites branched out of the Canaanite religion and took the form of Yahwism. Yahwism was the  national religion of the Kingdom of Israel and of the Kingdom of Judah.
As distinct from other Canaanite religious traditions, Yahwism was monolatristic and focused on the exclusive worship of Yahweh, whom his worshippers conflated with El. Yahwists started to deny the existence of other gods, whether Canaanite or foreign, as Yahwism became more strictly monotheistic over time.
During the Babylonian captivity of the 6th and 5th centuries BCE (Iron Age II), certain circles within exiled Judahites in Babylon refined pre-existing ideas about Yahwism, such as the nature of  divine election,  law and covenants. Their ideas came to dominate the Jewish community in the following centuries.
From the 5th century BCE until 70 CE, Yahwism evolved into the various theological schools of Second Temple Judaism, besides Hellenistic Judaism in the diaspora. Second Temple Jewish eschatology has similarities with Zoroastrianism. The text of the Hebrew Bible was redacted into its extant form in this period and possibly also  canonized as well. Archaeological and textual evidence pointing to widespread observance of the laws of the Torah among rank-and-file Jews first appears around the middle of the 2nd century BCE, during the Hasmonean period. 
Rabbinic Judaism developed in Late Antiquity, during the 3rd to 6th centuries CE; the Masoretic Text of the Hebrew Bible and the Talmud were compiled in this period. The oldest manuscripts of the Masoretic tradition come from the 10th and 11th centuries CE, in the form of the Aleppo Codex (of the later portions of the 10th century CE) and of the Leningrad Codex (dated to 1008–1009 CE). Due largely to censoring and the burning of manuscripts in medieval Europe, the oldest existing manuscripts of various  rabbinical works are quite late. The oldest surviving complete manuscript copy of the Babylonian Talmud dates from 1342 CE.","[Section: Iron Age Yahwism (1):
Judaism has three essential and related elements: study of the written Torah; the recognition of Israel as the chosen people and the recipients of the law at Mount Sinai; and the requirement that Israel and their descendants live according to the laws outlined in the Torah. These three elements have their origins in Iron Age Yahwism and in Second Temple Judaism.
Iron Age Yahwism was formalized in the 9th century BCE, around the same time that the Iron Age kingdoms of Israel (or Samaria) and Judah became consolidated in Canaan. Yahweh was the national god of both kingdoms.
Other neighbouring Canaanite kingdoms also each had their own national god originating from the Canaanite pantheon of gods: Chemosh was the god of Moab, Milcom the god of the Ammonites, Qaus the god of the Edomites, and so on. In each kingdom, the king was his national god's viceroy on Earth.
The various national gods were more or less equal, reflecting the fact that the kingdoms in Canaan themselves were more or less equal, and within each kingdom a divine couple, made up of the national god and his consort – in the case of Israel and Judah: Yahweh and the goddess Asherah – headed a pantheon of lesser gods.
By the late 8th century, both Judah and Israel had become vassals of the Assyrian Empire, bound by treaties of loyalty on one side and protection on the other.  Israel rebelled and was destroyed c. 722 BCE, and refugees from the former kingdom fled to Judah, bringing with them the tradition that Yahweh, already known in Judah, was not merely the most important of the gods, but the only god who should be served.
Various  prophets traditionally played significant roles in promoting Yahwism at the expense of its rival religions, both in the North and in the South.
The Yahwist-centred outlook was taken up by the Judahite landowning élite, who became extremely powerful in court circles in the next century when they placed the eight-year-old Josiah (reigned 641–609 BC) on the throne. During Josiah's reign, Assyrian power suddenly collapsed (after 631 BC), and a pro-independence movement took power in Jerusalem, promoting both the independence of Judah from foreign overlords and loyalty to Yahweh as the sole god of Israel. With Josiah's support, the ""Yahweh-alone"" movement launched a full-scale reform of worship, including a covenant (i.e., treaty) between Judah and Yahweh, replacing that between Judah and Assyria.
By the time this occurred, Yahweh had already been absorbing or superseding the positive characteristics of the other gods and goddesses of the pantheon, a process of appropriation that was an essential step in the subsequent emergence of one of Judaism's most notable features: its uncompromising monotheism. Philip R. Davies holds that the people of ancient Israel and Judah were not followers of Judaism; they were practitioners of a polytheistic culture worshiping multiple gods, concerned with fertility and local shrines and legends. They probably lacked a written Torah, elaborate laws governing ritual purity, and the sense of a covenant with an exclusive national god.
Subsections (0):
, Section: Second Temple Judaism (1):
In 586 BCE, Jerusalem was destroyed by the Babylonians, and the Judean elite – the royal family, the priests, the scribes, and other members of the elite – were taken to Babylon in captivity. They represented only a minority of the population, and Judah, after recovering from the immediate impact of war, continued to have a life not much different from what had gone before. In 539 BCE, Babylon fell to the Persians; the Babylonian exile ended and a number of the exiles, but by no means all and probably a minority, returned to Jerusalem. They were the descendants of the original exiles, and had never lived in Judah; nevertheless, in the view of the authors of the Biblical literature, they, and not those who had remained in the land, were ""Israel"". Judah, now called Yehud, was a Persian province, and the returnees, with their Persian connections in Babylon, were in control of it. They represented also the descendants of the old ""Yahweh-alone"" movement, but the religion they instituted was significantly different from both monarchic Yahwism and modern Judaism. These differences include new concepts of priesthood, a new focus on written law and thus on scripture, and a concern with preserving purity by prohibiting intermarriage outside the community of this new ""Israel"".
The Yahweh-alone party returned to Jerusalem after the Persian conquest of Babylon and became the ruling elite of Yehud. Much of the Hebrew Bible was assembled, revised and edited by them in the 5th century BCE, including the Torah (the books of Genesis, Exodus, Leviticus, Numbers, and Deuteronomy), the historical works, and much of the prophetic and Wisdom literature. The Bible narrates the discovery of a legal book in the Temple in the seventh century BCE, which the majority of scholars see as some form of Deuteronomy and regard as pivotal to the development of the scripture. The growing collection of scriptures was translated into Greek in the Hellenistic period by the Jews of the Egyptian diaspora, while the Babylonian Jews produced the court tales of the Book of Daniel (chapters 1–6 of Daniel – chapters 7–12 were a later addition), and the books of Tobit and Esther.
Afterwards, Yahwism split into Second Temple Judaism and Samaritanism. These religions initially had friendly relations but after John Hyrcanus's destruction of the Mount Gerizim temple in 120 BC, they became rival competitors. The latter is infamously recorded in the Christian New Testament.
Subsections (0):
, Section: Widespread adoption of Torah law (1):
In his seminal Prolegomena zur Geschichte Israels (Prologue to the History of Israel) of 1878, Julius Wellhausen argued that Judaism as a religion based on widespread observance of Torah law first emerged in 444 BCE when, according to the biblical account provided in the Book of Nehemiah (chapter 8), a priestly scribe named Ezra read a copy of the Mosaic Torah before the populace of Judea assembled in a central Jerusalem square. Wellhausen believed that this narrative should be accepted as historical because it sounds plausible, noting: ""The credibility of the narrative appears on the face of it."" Following Wellhausen, most scholars throughout the 20th and early 21st centuries have accepted that widespread Torah observance began sometime around the middle of the 5th century BCE.
More recently, Yonatan Adler has argued that in fact there is no surviving evidence to support the notion that the Torah was widely known, regarded as authoritative, and put into practice, any time prior to the middle of the 2nd century BCE. Adler explored the likelihood that Judaism, as the widespread practice of Torah law by Jewish society at large, first emerged in Judea during the reign of the Hasmonean dynasty, centuries after the putative time of Ezra.
Subsections (0):
, Section: Development of Rabbinic Judaism (1):
For centuries, the traditional understanding has been that the split of early Christianity and Judaism some time after the destruction of the Second Temple in 70 CE was the first major theological schism in Jewish tradition. Starting in the latter half of the 20th century, some scholars have begun to argue that the historical picture is quite a bit more complicated than that.
By the 1st century, Second Temple Judaism was divided into competing theological factions, notably the Pharisees and the Sadducees, besides numerous smaller sects such as the Essenes, messianic movements such as Early Christianity, and closely related traditions such as Samaritanism (which gives us the Samaritan Pentateuch, an important witness of the text of the Torah independent of the Masoretic Text). The sect of Israelite worship that eventually became Rabbinic Judaism and the sect which developed into Early Christianity were but two of these separate Israelite religious traditions. Thus, some scholars have begun to propose a model which envisions a twin birth of Christianity and Rabbinic Judaism, rather than an evolution and separation of Christianity from Rabbinic Judaism. It is increasingly accepted among scholars that ""at the end of the 1st century CE there were not yet two separate religions called 'Judaism' and 'Christianity'"". Daniel Boyarin (2002) proposes a revised understanding of the interactions between nascent Christianity and nascent Rabbinic Judaism in Late Antiquity which views the two religions as intensely and complexly intertwined throughout this period.
The Amoraim were the Jewish scholars of Late Antiquity who codified and commented upon the law and the biblical texts. The final phase of redaction of the Talmud into its final form took place during the 6th century CE, by the scholars known as the Savoraim. This phase concludes the Chazal era foundational to Rabbinical Judaism.
Subsections (0):
, Section: See also (1):
Atenism, the two-decade duration ancient Egyptian monotheistic religion of the 14th century BCE
Hellenistic religion
Historicity of the Bible
Jewish history
Jewish studies
Maccabees
Old Testament theology
Religions of the ancient Near East
Subsections (0):
, Section: References (1):

Subsections (2):
Section: Citations (2):

Subsections (0):

Section: Bibliography (2):

Subsections (0):
, Section: External links (1):
Adler, Yonatan (16 February 2023). ""When Did Jews Start Observing Torah? – TheTorah.com"". thetorah.com. Retrieved 23 February 2023.
Amzallag, Nissim (August 2018). ""Metallurgy, the Forgotten Dimension of Ancient Yahwism"". The Bible and Interpretation. University of Arizona. Archived from the original on 26 July 2020. Retrieved 28 July 2021.
Brown, William, ed. (October 2017). ""Early Judaism"". World History Encyclopedia. Retrieved 28 July 2021.
Gaster, Theodor H. (26 November 2020). ""Biblical Judaism (20th–4th century BCE)"". Encyclopædia Britannica. Edinburgh: Encyclopædia Britannica, Inc. Retrieved 28 July 2021.
Subsections (0):
]"
8,"Category:Origins (id: 29739395, ns: 14)",0,K-U ratio,"The K/U Ratio is  the ratio of a slightly volatile element, potassium (K), to a highly refractory element, uranium (U). It is a useful way to measure the presence of volatile elements on planetary surfaces.  The K/U ratio helps explain the evolution of the planetary system and the origin of Earth's moon.","[Section: Volatile and refractory elements (1):
In planetary science, volatiles are the group of chemical elements and chemical compounds with low boiling points that are associated with a planet's or a moon's crust or atmosphere.
Very low boiling temperature examples include nitrogen, water, carbon dioxide, ammonia, hydrogen, methane and sulfur dioxide.
In contrast with volatiles, elements and compounds with high boiling points are known as refractory substances.
On the basis of available data, which is sparse for Mars and very uncertain for Venus, the three inner planets then become progressively more depleted in K passing from Mars to Earth to Venus.
Subsections (0):
, Section: Planetary gamma-ray spectrometers (1):
Some elements like potassium, uranium, and thorium are naturally radioactive and give off gamma rays as they decay. Electromagnetic radiation from these isotopes can be detected by a Gamma-Ray Spectrometer (GRS) dropped toward the planetary surface or observed from orbit. An orbiting instrument can map the surface distribution of many elements for an entire planet.
Uncrewed spacecraft programs such as Venera and the Vega program have flown to Venus and sent back data allowing estimates of the K/U ratio of the surface rocks.
The Lunar Prospector mission used a GRS to map the Earth's Moon.
To determine the elemental makeup of the Martian surface, the Mars Odyssey used a GRS and two neutron detectors.
These GRS readings can be compared to direct elemental measurements of chondrites meteorites, Earth, and Moon samples brought back from Apollo program missions, as well as to meteorites that are believed to have come from Mars.
Subsections (0):
, Section: Ratios of solar system bodies (1):
K and U move together during geochemical processes and have long-lived radioisotopes that emit gamma rays. It is calculated as a ratio of one to the other on an equal mass basis which is often 
  
    
      
        μ
        g
        r
        a
        m
        [
        e
        l
        e
        m
        e
        n
        t
        ]
        
          /
        
        g
        r
        a
        m
      
    
    {\displaystyle \mu gram[element]/gram}
  
.
This creates a compelling explanation for the evolution of the solar system.

This result is consistent with an increasing temperature toward the sun during its early protoplanetary nebula phase.
The temperature at the early stage of solar system formation was in excess of 1,000K at the distance of Earth from the sun, and as low as 200–100K at the distances of Jupiter and Saturn.
Subsections (0):
, Section: Earth (1):
At the high temperatures for Earth, no volatiles would be in the solid state, and the dust would be made up of silicate and metal.
The continental crust and lower mantle have average K/U values of about 12,000.  mid-ocean ridge basalt (MORB) or upper mantle have more volatiles and have a K/U ratio of about 19,000.
Volatile depletion explains why Earth's sodium (volatile) content is about 10% of its calcium (refractory) content, despite the similar abundance in chondrites.
Subsections (0):
, Section: Earth's Moon's origin (1):
The Moon stands out as being very depleted in volatiles.
The Moon not only lacks water and atmospheric gases, but also lacks moderately volatile elements such as K, Na, and Cl. The Earth's K/U ratio is 12,000, while the Moon has a K/U ratio of only 2,000. This difference suggests that the material that formed the Moon was subjected to temperatures considerably higher than the Earth.
The prevailing theory is that the Moon formed out of the debris left over from a collision between Earth and an astronomical body the size of Mars, approximately 4.5 billion years ago, about 20 to 100 million years after the Solar System coalesced.  This is called the Giant-impact hypothesis.
It is hypothesized that most of the outer silicates of the colliding body would be vaporized, whereas a metallic core would not. Hence, most of the collisional material sent into orbit would consist of silicates, leaving the coalescing Moon deficient in iron. The more volatile materials that were emitted during the collision probably would escape the Solar System, whereas silicates would tend to coalesce.
The ratios of the Moon's volatile elements are not explained by the giant-impact hypothesis. If the giant-impact hypothesis is correct, they must be due to some other cause.
Subsections (0):
, Section: Meteorites (1):
Farther from the sun, the temperature was low enough that volatile elements would precipitate as ices. The two are separated by a snow line controlled by the temperature distribution around the Sun.
Formed farthest from the sun, the carbonaceous chondrites have the highest K/U ratios. Ordinary chondrites which form closer in are only about 10% depleted in K relative to U.
The fine-grained matrix which fills spaces between the chondrules, however, appears to have formed at rather different temperatures in the various classes of chondrites. For this reason the volatile abundances of different classes of chondrites can vary. One particularly important class is the carbonaceous chondrites because of their high carbon content. In these meteorites, chondrules coexist with minerals that are only stable below 100 °C, so they contain materials that formed in both high- and low-temperature environments and were only later collected together. Further evidence for the primordial attributes of carbonaceous chondrites comes from the fact that they have compositions very similar to the nonvolatile element composition of the sun.
Subsections (0):
, Section: Controversy of Mercury (1):
Mercury was surveyed by the MESSENGER mission with its Gamma-Ray Spectrometer.  The K/U ratios for Mercury could range between 8,000 and 17,000 which would imply a volatile rich planet. However, metal/silicate partitioning data for K and U still needs additional experiments at the conditions of Mercury's core formation to understand this unusual high ratio.


== References ==
Subsections (0):
]"
9,"Category:Origins (id: 29739395, ns: 14)",0,Origin of the Moon,"The origin of the Moon is usually explained by a Mars-sized body striking the Earth, creating a debris ring that eventually collected into a single natural satellite, the Moon, but there are a number of variations on this giant-impact hypothesis, as well as alternative explanations, and research continues into how the Moon came to be formed. Other proposed scenarios include captured body, fission, formed together (condensation theory, synestia), planetesimal collisions (formed from asteroid-like bodies), and collision theories.
The standard giant-impact hypothesis suggests that a Mars-sized body, called Theia, impacted the proto-Earth, creating a large debris ring around Earth, which then accreted to form the Moon. This collision also resulted in the 23.5° tilted axis of the Earth, thus causing the seasons. The Moon's oxygen isotopic ratios seem to be essentially identical to Earth's. Oxygen isotopic ratios, which may be measured very precisely, yield a unique and distinct signature for each Solar System body. If Theia had been a separate protoplanet, it probably would have had a different oxygen isotopic signature than proto-Earth, as would the ejected mixed material. Also, the Moon's titanium isotope ratio (50Ti/47Ti) appears so close to the Earth's (within 4 parts per million) that little if any of the colliding body's mass could likely have been part of the Moon.","[Section: Formation (1):
Some theories have been stated that presume the proto-Earth had no large moons early in the formation of the Solar System, 4.425 billion years ago, Earth being basically rock and lava. Theia, an early protoplanet the size of Mars, hit Earth in such a way that it ejected a considerable amount of material away from Earth. Some proportion of these ejecta escaped into space, but the rest consolidated into a single spherical body in orbit about Earth, creating the Moon.
The hypothesis requires a collision between a proto-Earth about 90% of the diameter of present Earth, and another body the diameter of Mars (half of the terrestrial diameter and a tenth of its mass). The latter has sometimes been referred to as Theia, the name of the mother of Selene, the Moon goddess in Greek mythology. This size ratio is needed in order for the resulting system to have sufficient angular momentum to match the current orbital configuration. Such an impact would have put enough material into orbit around Earth to have eventually accumulated to form the Moon.
Computer simulations show a need for a glancing blow, which causes a portion of the collider to form a long arm of material that then shears off. The asymmetrical shape of the Earth following the collision then causes this material to settle into an orbit around the main mass. The energy involved in this collision is impressive: possibly trillions of tonnes of material would have been vaporized and melted. In parts of the Earth, the temperature would have risen to 10,000 °C (18,000 °F).
The Moon's relatively small iron core (compared to other rocky planets and moons in the Solar System) is explained by Theia's core mostly merging into that of Earth. The lack of volatiles in the lunar samples is also explained in part by the energy of the collision. The energy liberated during the reaccretion of material in orbit around Earth would have been sufficient to melt a large portion of the Moon, leading to the generation of a magma ocean.
The newly formed Moon orbited at about one-tenth the distance that it does today, and spiraled outward because of tidal friction transferring angular momentum from the rotations of both bodies to the Moon's orbital motion. Along the way, the Moon's rotation became tidally locked to Earth, so that one side of the Moon continually faces toward Earth. Also, the Moon would have collided with and incorporated any small preexisting satellites of Earth, which would have shared the Earth's composition, including isotopic abundances. The geology of the Moon has since been more independent of the Earth.
A 2012 study on the depletion of zinc isotopes on the Moon found evidence for volatile depletion consistent with the giant-impact origin for Earth and the Moon. In 2013, a study was released that indicated that water in lunar magma is indistinguishable from that in carbonaceous chondrites and nearly the same as that of Earth in isotopic composition.
Subsections (0):
, Section: Derivatives of the hypothesis (1):
Although the giant-impact hypothesis explains many aspects of the Earth–Moon system, there are still a few unresolved problems, such as the Moon's volatile elements not being as depleted as expected from such an energetic impact.
Another issue is lunar and Earth isotope comparisons. In 2001, the most precise measurement yet of the isotopic signatures of Moon rocks was published. Surprisingly, the Apollo lunar samples carried an isotopic signature identical to Earth rocks, but different from other Solar System bodies. Because most of the material that went into orbit to form the Moon was thought to come from Theia, this observation was unexpected. In 2007, researchers from Caltech showed that the likelihood of Theia having an identical isotopic signature as the Earth is very small (less than 1 percent chance). Published in 2012, an analysis of titanium isotopes in Apollo lunar samples showed that the Moon has the same composition as Earth, which conflicts with the Moon forming far from Earth's orbit.
Subsections (4):
Section: Merger of two planets (2):
To help resolve these problems, a theory published in 2012 posits that two bodies—each five times the size of Mars—collided, then recollided, forming a large disc of mixed debris that eventually formed Earth and the Moon.
Subsections (0):

Section: Immediate origin of the Moon as a post-impact satellite (2):
The Moon is traditionally thought to have coalesced from the debris ejected by a giant impact onto the early Earth. However, such models struggle to explain the similar isotopic compositions of Earth and lunar rocks at the same time as the system's angular momentum, and the details of potential impact scenarios are hotly debated. Above a high resolution threshold for simulations, a study published in 2022 finds that giant impacts can immediately place a satellite with similar mass and iron content to the Moon into orbit far outside Earth's Roche limit. Even satellites that initially pass within the Roche limit can reliably and predictably survive, by being partially stripped and then torqued onto wider, stable orbits. Furthermore, the outer layers of these directly formed satellites are molten over cooler interiors and are composed of around 60% proto-Earth material. This could alleviate the tension between the Moon's Earth-like isotopic composition and the different signature expected for the impactor. Immediate formation opens up new options for the Moon's early orbit and evolution, including the possibility of a highly tilted orbit to explain the lunar inclination, and offers a simpler, single-stage scenario for the origin of the Moon.
Subsections (0):

Section: Multiple impacts (2):
In 2004, Russian astrophysicist Nikolai Gorkavyi proposed a novel model titled the multiple large asteroid impacts model, which found support from a notable group of Russian astronomers in 2013 and later, in 2017, by planetary researchers at Weizmann Institute of Science in Rehovot, Israel. In general terms, the main idea of the model suggests that the Moon was formed as a result of a violent rain of large asteroids (1–100 km) that repeatedly hammered the fledgling Earth over millions of years. Such a series of smaller impacts, which were likely more common in the early Solar System, could blast enough rocky Earth debris into orbit to form a protosatellite disk which later forms into a small moonlet. As repeated impacts created more balls of debris, the moonlets could merge over time into one large moon.
Subsections (0):

Section: Synestia hypothesis (2):
In 2018 researchers at Harvard and the UC Davis developed computer models demonstrating that one possible outcome of a planetary collision is that it creates a synestia, a mass of vaporized rock and metal which forms a biconcave disc extending beyond the lunar orbit. The synestia will eventually shrink and cool to accrete the satellite and reform the impacted planet.
Subsections (0):
, Section: Other hypotheses (1):

Subsections (4):
Section: Capture (2):
This hypothesis states that the Moon was captured by the Earth. This model was popular until the 1980s, and some points in its favor are the Moon's size, orbit, and tidal locking.
One problem is understanding the capture mechanism. A close encounter of two planetary bodies typically results in either collision or altered trajectories. For this hypothesis to work, there might have been a large atmosphere around the primitive Earth, which would slow the movement of the Moon by aerobraking before it could escape. That hypothesis may also explain the irregular satellite orbits of Jupiter and Saturn. However, this hypothesis does not adequately explain the essentially identical oxygen isotope ratios of the two bodies.
Subsections (0):

Section: Fission (2):
This is the now discredited hypothesis that an ancient, rapidly spinning Earth expelled a piece of its mass. This was first proposed by George Darwin (son of the famous biologist Charles Darwin) in 1879 and retained some popularity until Apollo. The Austrian geologist Otto Ampferer in 1925 also suggested the emerging of the Moon as cause for continental drift.
It was proposed that the Pacific Ocean represented the scar of this event. Today it is known that the oceanic crust that makes up this ocean basin is relatively young, about 200 million years old or less, whereas the Moon is much older. The Moon does not consist of oceanic crust but of mantle material, which originated inside the proto-Earth in the Precambrian.
Subsections (0):

Section: Accretion (2):
The hypothesis of accretion suggests that the Earth and the Moon formed together as a double system from the primordial accretion disk of the Solar System or even a black hole.
The problem with this hypothesis is that it does not explain the angular momentum of the Earth-Moon system or why the Moon has a relatively small iron core compared to the Earth (25% of its radius compared to 50% for the Earth).
Subsections (0):

Section: Nuclear explosion (2):
Dutch scientists Rob de Meijer and Wim van Westrenen suggested in 2010 that the Moon may have formed from a nuclear explosion caused by the centrifugal force of an earlier, spinning proto-Earth. The centrifugal force would have concentrated heavy elements such as thorium and uranium on the equatorial plane and at the boundary between the Earth's outer core and mantle. If the concentrations of these radioactive elements were high enough, this could have led to a nuclear chain reaction that became supercritical, causing a nuclear explosion ejecting the Moon into orbit. This natural nuclear fission reactor has been observed on Earth at a much smaller scale.
Subsections (0):
, Section: Additional theories and studies (1):

Subsections (5):
Section: 2011 (2):
In 2011, it was theorized that a second moon existed 4.5 billion years ago, and later had an impact with the Moon, as a part of the accretion process in the formation of the Moon.
Subsections (0):

Section: 2013 (2):
One hypothesis, presented only as a possibility, was that the Earth captured the Moon from Venus.
Subsections (0):

Section: 2017 (2):
Uranium–lead dating of Apollo 14 zircon fragments shows the age of the Moon to be about 4.51 billion years.
Subsections (0):

Section: 2020 (2):
A team of researchers of the Miniature Radio Frequency (Mini-RF) instrument on NASA's Lunar Reconnaissance Orbiter (LRO) spacecraft concluded that the Moon's subsurface may be richer in metals, like iron and titanium, more than scientists had believed.
In July 2020 scientists report that the Moon formed 4.425 ±0.025 bya, about 85 million years later than thought, and that it hosted an ocean of magma for substantially longer than previously thought (for ~200 million years).
Subsections (0):

Section: 2023 (2):
On 1 November 2023, scientists reported that, according to computer simulations, remnants of a protoplanet, named Theia, could be inside the Earth, left over from a collision with the Earth in ancient times, and afterwards becoming the Moon.
Subsections (0):
, Section: See also (1):
Geology of the Moon – Structure and composition of the Moon
Late Heavy Bombardment – Hypothesized astronomical event
Lunar theory – theoretical description of motion of Earth's moonPages displaying wikidata descriptions as a fallback
Claimed moons of Earth – Claims that Earth may have other natural satellites
Lunar Reconnaissance Orbiter – NASA robotic spacecraft orbiting the Moon
MoonRise – proposed NASA mission to the MoonPages displaying wikidata descriptions as a fallback (Lunar lander proposal)
Spaceship Moon, a non-scientific hypothesis of the Moon's origin
Phaeton, another non-scientific hypothesis of the Moon's origin
Magma Ocean, general description of magma oceans and their formation
Subsections (0):
, Section: References (1):

Subsections (0):
, Section: External links (1):
Lunar formation Case Western Reserve University
The Once and Future Moon (September 28, 2012) Archived January 7, 2013, at the Wayback Machine
Nature - Moon-forming impact theory rescued
Subsections (0):
]"
10,"Category:Origins (id: 29739395, ns: 14)",0,Origin of COVID-19,"Since the beginning of the COVID-19 pandemic, there have been efforts by scientists, governments, and others to determine the origin of the SARS-CoV-2 virus. Similar to other outbreaks, the virus was derived from a bat-borne virus and most likely was transmitted to humans via another animal in nature, or during wildlife trade such as that in food markets. While other explanations, such as speculations that SARS-CoV-2 was accidentally released from a laboratory have been proposed, such explanations are not supported by evidence. Conspiracy theories about the virus's origin have also proliferated.
SARS-CoV-2 has close genetic similarity to multiple previously identified bat coronaviruses, suggesting it crossed over into humans from bats. Research is ongoing as to whether SARS-CoV-2 came directly from bats or indirectly through an intermediate host, such as pangolins, civets, or raccoon dogs. Genomic sequence evidence indicates the spillover event introducing SARS-CoV-2 to humans likely occurred in late 2019. As with the 2002–2004 SARS-CoV-1 outbreak, efforts to trace the specific geographic and taxonomic origins of SARS-CoV-2 could take years, and results may be inconclusive.
In July 2022, two papers published in Science described novel epidemiological and genetic evidence that suggested the pandemic likely began at the Huanan Seafood Wholesale Market and did not come from a laboratory.","[Section: Zoonosis (1):
While there are multiple proposed explanations for how SARS-CoV-2 was introduced into and evolved adaptations suited to human populations, there is significant evidence and agreement that the most likely original viral reservoir for SARS-CoV-2 is horseshoe bats. The closest known viral relatives of SARS-CoV-2 are RaTG13 and BANAL-52, sampled from horseshoe bat droppings in Yunnan province in China and Feuang, Laos, respectively. The evolutionary distance between SARS-CoV-2 and RaTG13 is estimated to be about 50 years (between 38 and 72 years).
Bats are a significant reservoir species for a diverse range of coronaviruses, and humans have been found with antibodies for them suggesting that direct infection by bats is common. The zoonotic transmission of SARS-CoV-2 virus to humans took place in the context of exacerbating factors that could make such spillovers more likely. Human contact with bats has increased as human population centers encroach on bat habitats.  Several social and environmental factors including climate change, natural ecosystem destruction and wildlife trade have also increased the likelihood for the emergences of zoonosis. One study made with the support of the European Union found climate change increased the likelihood of the pandemic by influencing distribution of bat species.
The earliest human cases of SARS-CoV-2 were identified in Wuhan, but the index case remains unknown. RaTG13 was sampled from bats in a mine in Mojiang County, Yunnan, located roughly 1,500 km (930 mi) away from Wuhan, and there are relatively few bat coronaviruses from Hubei province, where Wuhan is located.
Subsections (1):
Section: Intermediate host (2):
In addition to direct spillover, another pathway, considered highly likely by scientists, is that of transmission through an intermediate host. Specifically, this implies that a cross species transmission occurred prior to the human outbreak and that it had pathogenic results on the animal. This pathway has the potential to allow for greater adaptation to human transmission via animals with more similar protein shapes to humans, though this is not required for the scenario to occur. The evolutionary separation from bat viruses is explained in this case by the virus's presence in an unknown species with less viral surveillance than bats. The virus's ability to easily infect and adapt to additional species (including mink) provides evidence that such a route of transmission is possible.
Subsections (0):
, Section: Unlikely scenarios (1):
While the scientific consensus is that SARS-CoV-2 derived from viruses hosted in bats, the precise means by which this occurred has been sometimes subject to speculation. Below are some judged to be unlikely scenarios.
Subsections (2):
Section: Cold/food chain (2):
Another proposed introduction to humans is through fresh or frozen food products, referred to as the cold/food chain. Scientists do not consider this to be a likely origin of SARS-CoV-2 in humans. This scenario's source animal could be either a direct or intermediary species as described above. Many investigations centered around the Huanan Seafood Wholesale Market in Wuhan, which had an early cluster of cases. While there have been food-borne outbreaks of human viruses in the past, and evidence of re-introduction of SARS-CoV-2 into China through imported frozen foods, investigations found no conclusive evidence of viral contamination in products at the Huanan Market.
Subsections (0):

Section: Lab leak theory (2):

Subsections (0):
, Section: Investigations (1):

Subsections (6):
Section: Chinese government (2):
The first investigation conducted in China was by the Wuhan Municipal Health Commission, responding to hospitals reporting cases of pneumonia of unknown etiology, resulting in the closure of the Huanan Seafood Wholesale Market on 1 January 2020 for sanitation and disinfection. The Chinese Center for Disease Control and Prevention (CCDC) entered the market the same day and took samples; as the animals had been removed before public-health authorities came in, no animals were sampled, although that would have been more conclusive.
In April 2020, China imposed restrictions on publishing academic research on the novel coronavirus. Investigations into the origin of the virus would receive extra scrutiny and must be approved by Central Government officials. The restrictions do not ban research or publication, including with non-Chinese researchers; Ian Lipkin, a US scientist, has been working with a team of Chinese researchers under the auspices of the Chinese Center for Disease Control and Prevention, a Chinese government agency, to investigate the origin of the virus. Lipkin has long-standing relationships with Chinese officials, including premier Li Keqiang, because of his contributions to rapid testing for SARS in 2003.
The Huanan live-animal market was suspected of being the source of the virus, as there was a major, early cluster of cases there. On 31 January 2021, a team of scientists led by the World Health Organization visited the market to investigate the origins of COVID-19. Based on the existing evidence, the WHO concluded that the origin of the virus was still unknown, and the Chinese government insisted that the market was not the origin. The Chinese government has long insisted that the virus originated outside China, and until June 2021 denied that live animals were traded at the Huanan market.
Some Chinese researchers had published a preprint analysis of the Huanan swab samples in February 2022, concluding that the coronavirus in the samples had likely been brought in by humans, not the animals on sale, but omissions in the analysis had raised questions, and the raw sample data had not yet been released.
On March 4, 2023, the data from the swab samples of the Huanan live-animal market were released, or possibly leaked; a preliminary analysis of this data was reviewed by the international research community, which said that it made an animal origin much more likely. Although the samples do not definitively prove that the raccoon dog is the ""missing"" intermediate animal host in the bat-to-human transmission chain, it does show that common raccoon dogs were present in the Huanan market at the time of the initial SARS-CoV-2 outbreak, in areas that were also positive for SARS-CoV-2 RNA, and substantially strengthens this hypothesis as the proximal origin of the pandemic.
An attempt by these researchers to collaborate with the Chinese researchers was not answered, but the raw data was removed from the online database. On March 14, an international group of researchers presented a preliminary analysis at a meeting of the World Health Organization's Scientific Advisory Group for Origins of Novel Pathogens, at which Chinese COVID-19 researchers were also present. On the sixteenth, George Gao, the former head of the CCDC and lead author on the February 2022 preprint, told Science that there was ""nothing new"" in the raw data, and refused to answer questions about why his research team had removed it from the database.
On March 17, the WHO director-general said that the data should have been shared three years earlier, and called on China to be more transparent in its data-sharing. There exists further data from further samples which has not yet been made public. Maria Van Kerkhove, the WHO's COVID-19 technical lead, called for it to be made public immediately (see Huanan live-animal market#Swabs).
Subsections (0):

Section: United States government (2):

Subsections (2):
Section: Trump administration (3):
On 6 February 2020, the director of the White House's Office of Science and Technology Policy requested the National Academies of Sciences, Engineering, and Medicine to convene a meeting of ""experts, world class geneticists, coronavirus experts, and evolutionary biologists"", to ""assess what data, information and samples are needed to address the unknowns, in order to understand the evolutionary origins of COVID-19 and more effectively respond to both the outbreak and any resulting information"".
In April 2020, it was reported that the US intelligence community was investigating whether the virus came from an accidental leak from a Chinese lab. The hypothesis was one of several possibilities being pursued by the investigators. US Secretary of Defense Mark Esper said the results of the investigation were ""inconclusive"". By the end of April 2020, the Office of the Director of National Intelligence said the US intelligence community believed the coronavirus was not man-made or genetically modified.
US officials criticised the ""terms of reference"" allowing Chinese scientists to do the first phase of preliminary research. On 15 January 2021, US Secretary of State Mike Pompeo said that to assist the WHO investigative team's work and ensure a transparent, thorough investigation of COVID-19's origin, the US was sharing new information and urging the WHO to press the Chinese government to address three specific issues, including the illnesses of several researchers inside the WIV in autumn 2019 ""with symptoms consistent with both COVID-19 and common seasonal illnesses"", the WIV's research on ""RaTG13"" and ""gain of function"", and the WIV's links to the People's Liberation Army. On 18 January, the US called on China to allow the WHO's expert team to interview ""care givers, former patients and lab workers"" in the city of Wuhan, drawing a rebuke from the Chinese government. Australia also called for the WHO team to have access to ""relevant data, information and key locations"".
A classified report from May 2020 by the Lawrence Livermore National Laboratory, a US government national laboratory, concluded that the hypothesis that the virus leaked from the WIV ""is plausible and deserves further investigation"", although the report also notes that the virus could have developed naturally, echoing the consensus of the American intelligence community, and provides no ""smoking gun"" towards either hypothesis.
Subsections (0):

Section: Biden administration (3):
On 13 February 2021, the White House said it had ""deep concerns"" about both the way the WHO's findings were communicated and the process used to reach them. Mirroring concerns raised by the Trump administration, National Security Adviser Jake Sullivan stated that it was essential that the WHO-convened report be independent and ""free from alteration by the Chinese government"". On 14 April 2021, the Director of National Intelligence Avril Haines, along with other Biden administration officials, said that they had not ruled out the possibility of a laboratory accident as the origin of the COVID-19 virus.
On 26 May 2021, President Joe Biden directed the U.S. intelligence community to produce a report within 90 days on whether the COVID-19 virus originated from a human contact with an infected animal or from an accidental lab leak, stating his national security staff said there is insufficient evidence to determine either hypothesis to be more likely. On 26 August 2021, the Office of the Director of National Intelligence released an unclassified summary of their findings, with the main point being that the report remained inconclusive as to the origin of the virus, with intelligence agencies divided on the question. The report also concluded that the virus was most likely not genetically engineered, and that China had no foreknowledge of the virus prior to the outbreak. The report concluded that a final determination of the origin was unlikely without cooperation from the Chinese government, saying their prior lack of transparency ""reflect[ed] in part China's government's own uncertainty about where an investigation could lead, as well as its frustration that the international community is using the issue to exert political pressure on China."" Chinese foreign ministry spokesman Wang Wenbin said that the US intelligence report was ""unscientific and has no credibility"".
On 23 May 2021, The Wall Street Journal reported that a previously undisclosed US intelligence report stated that three researchers from the Wuhan Institute of Virology became ill enough in November 2019 to seek hospital care. The report did not specify what the illness was. Officials familiar with the intelligence differed as to the strength to which it corroborates the hypothesis that the virus responsible for COVID-19 was leaked from the WIV. The WSJ report notes that it is not unusual for people in China to go to the hospital with uncomplicated influenza or common cold symptoms.
Yuan Zhiming, director of the WIV's Wuhan National Biosafety Laboratory, responded in the Global Times, a Chinese state media outlet, that the ""claims are groundless"". Marion Koopmans, a member of the WHO study team, described the number of flu-like illnesses at the WIV in 2019 as ""completely normal"". Workers at the WIV must provide yearly serum samples. WIV virologist Shi Zhengli said in 2020 that, based on an evaluation of those serum samples, all staff tested negative for COVID-19 antibodies.
The House Foreign Affairs Committee has investigated the origins of the pandemic, and heard classified briefings. The Republican minority issued a report in August 2021 that they believed the origin of the pandemic was an accidental lab escape.
The resurgence of the theory of a laboratory accident was fueled in part by the publication, in May 2021, of early emails between Anthony Fauci and scientists discussing the issue, before deliberate manipulation was ruled out as of March 2020.
On 14 July 2021, the House Committee on Science, Space and Technology held the first congressional hearing on the origins of the virus. Bill Foster, an Illinois Democrat who chaired the hearing, said the Chinese government's lack of transparency is not in itself evidence of a lab leak and cautioned that answers may not be known even after the administration produces its intelligence report. Expert witnesses Stanley Perlman and David Relman presented to the congressman different proposed explanations for the origins of the virus and how to conduct further investigations.
On 16 July 2021, CNN reported that Biden administration officials considered the lab leak theory ""as credible"" as the natural origins theory. In October 2022, an interim report of a Republican member of a US Senate committee concluded that a lab origin was most likely, but offered ""little new evidence"", according to The New York Times.
In February 2023, the United States Energy Department updated its assessment on the origins of the virus, shifting from ""undecided"" to ""low confidence"" in favor of a laboratory leak. White House National Security Advisor Jake Sullivan responded to the report saying there was still ""no definitive answer"" to the pandemic origins' question.
On 28 February 2023, the head of the Federal Bureau of Investigation Christopher Wray said the FBI believes Covid-19 most likely originated in the lab.
On 20 March 2023, the COVID-19 Origin Act of 2023 was signed into law. On June 23, 2023, the Biden administration released its report, as required by the Act.
Subsections (0):

Section: World Health Organization (2):
The World Health Organization has declared that finding where SARS-CoV-2 came from is a priority and that it is ""essential for understanding how the pandemic started."" In May 2020, the World Health Assembly, which governs the World Health Organization (WHO), passed a motion calling for a ""comprehensive, independent and impartial"" study into the COVID-19 pandemic. A record 137 countries, including China, co-sponsored the motion, giving overwhelming international endorsement to the study. In mid 2020, the World Health Organization (WHO) began negotiations with the government of China on conducting an official study into the origins of COVID-19.
In November 2020, the WHO published a two-phase study plan. The purpose of the first phase was to better understand how the virus ""might have started circulating in Wuhan"", and a second phase involves longer-term studies based on the findings of the first phase. WHO director-general Tedros Adhanom said ""We need to know the origin of this virus because it can help us to prevent future outbreaks,"" adding, ""There is nothing to hide. We want to know the origin, and that's it."" He also urged countries not to politicise the origin tracing process, saying that would only create barriers to learning the truth.
In 2021, the World Health Assembly (on behalf of the WHO) commissioned a study conducted jointly between WHO experts and Chinese scientists. Echoing the assessment of most virologists, the study concluded that the virus most likely had a zoonotic origin in bats, possibly via an intermediate host. It also stated that a laboratory origin for the virus was ""extremely unlikely"". WHO director-general Tedros Adhanom Ghebreyesus, in concert with various governments including the US and the EU, responded to the 2021 study report saying the matter still ""requires further investigation"". In July 2021, Zeng Yixin, Vice Health Minister of the Chinese National Health Commission, said that China would not participate in a second phase of investigation, denouncing the decision to proceed as ""shocking"" and ""arrogant"". In June 2022, a second round of investigations concluded that more investigations in the various possible pathways of emergence were necessary. In response to the WHO's June 2022 report, Chinese Foreign Ministry spokesperson Zhao Lijian called the lab leak theory ""a lie concocted by anti-China forces for political purposes, which has nothing to do with science"".
Subsections (2):
Section: Phase 1 (3):
For the first phase, the WHO formed a team of ten researchers with expertise in virology, public health and animals to conduct a thorough study. One of the team's tasks was to retrospectively ascertain what wildlife was being sold in local wet markets in Wuhan. The WHO's phase one team arrived and quarantined in Wuhan, Hubei, China in January 2021.
Members of the team included Thea Fisher, John Watson, Marion Koopmans, Dominic Dwyer, Vladimir Dedkov, Hung Nguyen-Viet, Fabian Leendertz, Peter Daszak, Farag El Moubasher, and Ken Maeda. The team also included five WHO experts led by Peter Ben Embarek, two Food and Agriculture Organization representatives, and two representatives from the World Organisation for Animal Health.
The inclusion of Peter Daszak in the team stirred controversy. Daszak is the head of EcoHealth Alliance, a nonprofit that studies spillover events, and has been a longtime collaborator of over 15 years with Shi Zhengli, Wuhan Institute of Virology's director of the Center for Emerging Infectious Diseases. While Daszak is highly knowledgeable about Chinese laboratories and the emergence of diseases in the area, his close connection with the WIV was seen by some as a conflict of interest in the WHO's study. When a BBC News journalist asked about his relationship with the WIV, Daszak said, ""We file our papers, it's all there for everyone to see.""
The team was denied access to raw data, including the list of early patients, swabs, and blood samples. It was allowed only a few hours of supervised access to the Wuhan Institute of Virology.
Subsections (2):
Section: Findings (4):
In February 2021, after conducting part of their study, the WHO stated that the likely origin of COVID-19 was a zoonotic event from a virus circulating in bats, likely through another animal carrier, and that the time of transmission to humans was likely towards the end of 2019.
The Chinese and the international experts who jointly carried out the WHO-convened study consider it ""extremely unlikely"" that COVID-19 leaked from a lab. No evidence of a lab leak from the Wuhan Institute of Virology was found by the WHO team, with team leader Peter Ben Embarek stating that it was ""very unlikely"" due to the safety protocols in place. During a 60 Minutes interview with Lesley Stahl, Peter Daszak, another member of the WHO team, described the investigation process to be a series of questions and answers between the WHO team and the Wuhan lab staff. Stahl made the comment that the team was ""just taking their word for it"", to which Daszak replied, ""Well, what else can we do? There's a limit to what you can do and we went right up to that limit. We asked them tough questions. They weren't vetted in advance. And the answers they gave, we found to be believable—correct and convincing.""
The investigation also stated that transfer from animals to humans was unlikely to have occurred at the Huanan Seafood Market, since infections without a known epidemiological link were confirmed before the outbreak around the market. In an announcement that surprised some foreign experts, the joint investigation concluded that early transmission via the cold chain of frozen products was ""possible"".
In March 2021, the WHO published a written report with the results of the study. The joint team stated that there are four scenarios for introduction:

direct zoonotic transmission to humans (spillover), assessed as ""possible to likely""
introduction through an intermediate host followed by a spillover, assessed as ""likely to very likely""
introduction through the (cold) food chain, assessed as ""possible""
introduction through a laboratory incident, assessed as ""extremely unlikely""
The report mentions that direct zoonotic transmission to humans has a precedent, as most current human coronaviruses originated in animals. Zoonotic transmission is also supported by the fact that RaTG13 binds to hACE2, although the fit is not optimal.
The investigative team noted the requirement for further studies, noting that these would ""potentially increase knowledge and understanding globally."": 9
Subsections (0):

Section: Reactions (4):
WHO director-general Tedros Adhanom, who was not directly involved with the investigation, said he was ready to dispatch additional missions involving specialist experts and that further research was required. He said in a statement, ""Some explanations may be more probable than others, but for now all possibilities remain on the table."" He also said, ""We have not yet found the source of the virus, and we must continue to follow the science and leave no stone unturned as we do."" Tedros called on China to provide ""more timely and comprehensive data sharing"" as part of future investigations.
News outlets noted that, though it was unrealistic to expect quick and huge results from the report, it ""offered few clear-cut conclusions regarding the start of the pandemic"", ""failed to audit the Chinese official position at some parts of the report"", and was ""biased according to critics"". Other scientists praised how the report details the pathways that can shed light on the origin, if explored later.
After the publication of the report, politicians, talk show hosts, journalists, and some scientists advanced unsupported claims that SARS-CoV-2 may have come from the WIV. In the United States, calls to investigate a laboratory leak reached ""fever pitch"", fueling aggressive rhetoric resulting in antipathy towards people of Asian ancestry, and the bullying of scientists. The European Union, United States, and 13 other countries criticised the WHO-convened study, calling for transparency from China and access to the raw data and original samples. Chinese officials described these criticisms as an attempt to politicise the study. Scientists involved in the WHO report, including Liang Wannian, John Watson, and Peter Daszak, objected to the criticism, and said that the report was an example of the collaboration and dialogue required to successfully continue investigations into the matter.
In a letter published in Science, a number of scientists, including Ralph Baric, argued that the accidental laboratory leak hypothesis had not been sufficiently investigated and remained possible, calling for greater clarity and additional data. Their letter was criticized by some virologists and public health experts, who said that a ""hostile"" and ""divisive"" focus on the WIV was unsupported by evidence, and would cause Chinese scientists and authorities to share less, rather than more data.
Subsections (0):

Section: Phase 2 (3):
On 27 May 2021, Danish epidemiologist Tina Fischer spoke on the This Week in Virology podcast, advocating for a second phase of the study to audit blood samples for COVID-19 antibodies in China. WHO-convened study team member Marion Koopmans, on that same broadcast, advocated for WHO member states to make a decision on the second phase of the study, though she also cautioned that an investigatory audit of the laboratory itself may be inconclusive. In early July 2021, WHO emergency chief Michael Ryan said the final details of phase 2 were being worked out in negotiations between WHO and its member states, as the WHO works ""by persuasion"" and cannot compel any member state (including China) to cooperate.
In July 2021 China rejected WHO requests for greater transparency, cooperation, and access to data as part of Phase 2. On 16 July 2021, Foreign Ministry spokesperson Zhao Lijian declared that China's position was that future investigations should be conducted elsewhere and should focus on cold chain transmission and the US military's labs. On 22 July 2021, the Chinese government held a press conference in which Zeng Yixin, Vice Health Minister of the National Health Commission (NHC), said that China would not participate in a second phase of the WHO's investigation, denouncing it as ""shocking"" and ""arrogant"". He elaborated ""In some aspects, the WHO's plan for next phase of investigation of the coronavirus origin doesn't respect common sense, and it's against science. It's impossible for us to accept such a plan.""
On 9 June 2022, the SAGO group, in development of its function of advisor to the WHO, published its first preliminary report. This report summarised existing findings and recommended that further studies be undertaken into possibly pathways of emergence.
Subsections (0):

Section: The Lancet COVID-19 Commission task force (2):
In November 2020, Richard Horton, editor of The Lancet, appointed economist Jeffrey Sachs as chair of its COVID-19 Commission, with wide-ranging goals relating to the virus and pandemic. Sachs set up a number of task forces, including one on the origins of the virus. Sachs appointed Peter Daszak, a colleague of Sachs' at Columbia, to head this task force, two weeks after the Trump administration prematurely ended an federal grant supporting a project led by Daszak, EcoHealth Alliance, which worked with the Wuhan Institute of Virology. This appointment was criticised as creating a conflict of interest, for instance by Richard Ebright, chemical biologist at Rutgers University, who called the commission an ""entirely Potemkin commission"" in the National Review.
Daszak stated that the task force was formed to ""conduct a thorough and rigorous investigation into the origins and early spread of SARS-CoV-2"". The task force has twelve members with backgrounds in One Health, outbreak investigation, virology, lab biosecurity and disease ecology. The task force planned to analyse scientific findings and did not plan to visit China. However, as Sachs became increasingly drawn to the lab leak theory, he came into conflict with Daszak and his task force. In June 2021, The Lancet announced that Daszak had recused himself from the commission. On 25 September 2021, the task force work was folded after procedural concerns and a need to broaden its scope to examine transparency and government regulation of risky laboratory research. However, it continued to conduct its work independently.
In September 2022, the Lancet commission published a wide-ranging report on the pandemic, including commentary on the virus origin overseen by the group's chairman, economist Jeffrey Sachs. The report suggested that the virus may have originated from an American laboratory, a notion promoted by Sachs since late 2020, including in 2022 on the podcast of anti-vaxx conspiracy theorist Robert F. Kennedy Jr. Reacting to the Commission report, virologist Angela Rasmussen commented that this may have been ""one of The Lancet's most shameful moments regarding its role as a steward and leader in communicating crucial findings about science and medicine"". Virologist David Robertson said the invocation of US laboratory involvement was ""wild speculation"" and that ""it's really disappointing to see such a potentially influential report contributing to further misinformation on such an important topic"".
The task force published their own report in October 2022, saying they concluded there was ""overwhelming"" evidence of a natural spillover, but they also accepted the possibility of a lab leak.
Subsections (0):

Section: Independent investigations (2):
In June 2021, the NIH announced that a set of sequence data had been removed from the Sequence Read Archive (SRA) in June 2020. The removal was performed according to standard practice at the request of the investigators who owned the rights to the sequences, with the investigators' rationale that the sequences would be submitted to another database. The investigators subsequently published a paper in an academic journal the same month they were removed from the NIH database which described the sequences in detail and discussed their evolutionary relationship to other sequences, but did not include the raw data. Virologist David Robertson said that it was difficult to conclude it was a cover-up rather than the more likely explanation: a mundane deletion of data without malfeasance. The missing genetic sequence data was restored in a correction published 29 July 2021 after it was stated to be a copy-edit error.
In March 2023, an international team of virus experts from University of Arizona, Scripps Research Institute, and University of Sydney found genetic evidence that COVID-19 may have originated from the illegal trade of infected raccoon dogs in Wuhan, China, supporting the zoonotic transmission scenario. Swabs taken from the Huanan Seafood Wholesale Market in January 2020, which tested positive for coronavirus, contained large amounts of genetic material from raccoon dogs.
Subsections (0):

Section: International calls for investigations (2):
In April 2020, Australian foreign minister Marise Payne and Australian prime minister Scott Morrison called for an independent international inquiry into the origins of the coronavirus pandemic. A few days later, German chancellor Angela Merkel also pressed China for transparency about the origin of the coronavirus, following similar concerns raised by the French president Emmanuel Macron. The UK also expressed support for an investigation, although both France and UK said the priority at the time was to first fight the virus. Some public health experts have also called for an independent examination of COVID-19's origins, ""arguing WHO does not have the political clout to conduct such a forensic analysis"".
In May 2021, Prime Minister Justin Trudeau told reporters Canada would ""support the call by the United States and others to better understand the origins of COVID-19."" In June 2021, at the G7 summit in Cornwall, the attending leaders issued a joint statement calling for a new investigation, citing China's refusal to cooperate with certain aspects of the original WHO-convened study. This resistance to international pressure was one of the key findings of a Wall Street Journal investigation into the pandemic origin.
The divisive nature of the debate has led scientists to call for less political pressure on the topic. Public health analysts have remarked that the debate over the origins of SARS-CoV-2 is fueling unnecessary confrontation, resulting in bullying and harassment of scientists, and is deepening existing geopolitical tensions and hindering collaboration at a time where such mutual cooperation is required, both to deal with the current pandemic and in preparation for future such outbreaks. This comes in the face of scientists having predicted such events for decades: according to Katie Woolaston, researcher at the Queensland University of Technology, ""The environmental drivers of pandemics are not being widely discussed"". The debate comes at a moment of difficult global relations with Chinese authorities. Researchers have noted that the politicisation of the debate is making the process more difficult, and that words are often twisted to become ""fodder for conspiracy theories"".
A letter published in The Lancet in July 2021 remarked that the atmosphere of speculation surrounding the issue was of no help in making an objective assessment of the situation. In response to this letter, in a communication published in the same journal, a small group of researchers opposed the idea that scientists should promote unity and called for openness to alternative hypotheses. Despite the unlikelihood of the event, and although definitive answers are likely to take years of research, biosecurity experts have called for a review of global biosecurity policies, citing known gaps in international standards for biosafety. The situation has also reignited a debate over gain-of-function research, although the intense political rhetoric surrounding the issue has threatened to sideline serious inquiry over policy in this domain.
Subsections (0):
, Section: See also (1):
Assessment on COVID-19 Origins
Proximal Origin
Scientific Advisory Group for Origins of Novel Pathogens
World Health Organization's response to the COVID-19 pandemic
Subsections (0):
, Section: References (1):

Subsections (0):
, Section: Further reading (1):
Quammen, David, ""The Sobbing Pangolin: How a threatened animal may be linked to the [Covid-19] pandemic's beginnings"", The New Yorker, 31 August 2020, pp. 26–31. ""More field research is needed [...]. More sampling of wild animals. More scrutiny of genomes. More cognizance of the fact that animal infections can become human infections because humans are animals. We live in a world of viruses, and we have scarcely begun to understand this one [ COVID-19 ]. (p. 31.)
Subsections (0):
]"
11,"Category:Origins (id: 29739395, ns: 14)",0,Origin of language,"The origin of language, its relationship with human evolution, and its consequences have been subjects of study for centuries. Scholars wishing to study the origins of language must draw inferences from evidence such as the fossil record, archaeological evidence, contemporary language diversity, studies of language acquisition, and comparisons between human language and systems of animal communication (particularly other primates). Many argue that the origins of language probably relate closely to the origins of modern human behavior, but there is little agreement about the facts and implications of this connection.
The shortage of direct, empirical evidence has caused many scholars to regard the entire topic as unsuitable for serious study; in 1866, the Linguistic Society of Paris banned any existing or future debates on the subject, a prohibition which remained influential across much of the Western world until late in the twentieth century. Various hypotheses have been developed about how, why, when, and where language might have emerged. Still, little more has been universally agreed upon by 1996  than over a century and a half ago, when Charles Darwin's theory of evolution by natural selection had provoked a surge of speculation on the topic. Since the early 1990s, however, a number of linguists, archaeologists, psychologists, anthropologists, and others have attempted to address this issue with new, modern methods.","[Section: Approaches (1):
Attempts to explain the origin of language take a variety of forms:

""Continuity theories"" build on the idea that language exhibits so much complexity that one cannot imagine it simply appearing from nothing in its final form; therefore it must have evolved from earlier pre-linguistic systems among humans' primate ancestors.
""Discontinuity theories"" take the opposite approach—that language, as a unique trait which cannot be compared to anything found among non-humans, must have appeared fairly suddenly during the course of human evolution.
Some theories consider language mostly as an innate faculty—largely genetically encoded.
Other theories regard language as a mainly cultural system—learned through social interaction.
A majority of linguistic scholars as of 2024 favour continuity-based theories, but they vary in how they hypothesize language development. Among those who consider language as mostly innate, some avoid speculating about specific precursors in nonhuman primates, stressing simply that the language faculty must have evolved in the usual gradual way. Others in this intellectual camp—notably Ib Ulbæk—hold that language evolved not from primate communication but from primate cognition, which is significantly more complex.
Those who consider language as learned socially, such as Michael Tomasello, consider it developing from the cognitively controlled aspects of primate communication, these being mostly gestural as opposed to vocal. Where vocal precursors are concerned, many continuity theorists envisage language evolving from early human capacities for song.
Noam Chomsky, a proponent of discontinuity theory, argues that a single change occurred in humans before we left Africa, coincident with the Great Leap approximately 100,000 years ago, in which a common language faculty developed in a group of humans and their descendants.   Chomsky bases his argument on the observation that any human baby of any culture can be raised in a different culture and will completely assimilate the language and behavior of the new culture that they were raised in.   This implies that no major change to the human language faculty have occurred since we left Africa.
Transcending the continuity-versus-discontinuity divide, some scholars view the emergence of language as the consequence of some kind of social transformation that, by generating unprecedented levels of public trust, liberated a genetic potential for linguistic creativity that had previously lain dormant. ""Ritual/speech coevolution theory"" exemplifies this approach. Scholars in this intellectual camp point to the fact that even chimpanzees and bonobos have latent symbolic capacities that they rarely—if ever—use in the wild. Objecting to the sudden mutation idea, these authors argue that even if a chance mutation were to install a language organ in an evolving bipedal primate, it would be adaptively useless under all known primate social conditions. A very specific social structure—one capable of upholding unusually high levels of public accountability and trust—must have evolved before or concurrently with language to make reliance on ""cheap signals"" (words) an evolutionarily stable strategy.
Since the emergence of language lies so far back in human prehistory, the relevant developments have left no direct historical traces; neither can comparable processes be observed today. Despite this, the emergence of new sign languages in modern times—Nicaraguan Sign Language, for example—may potentially offer insights into the developmental stages and creative processes necessarily involved. Another approach inspects early human fossils, looking for traces of physical adaptation to language use. In some cases, when the DNA of extinct humans can be recovered, the presence or absence of genes considered to be language-relevant—FOXP2, for example—may prove informative. Another approach, this time archaeological, involves invoking symbolic behavior (such as repeated ritual activity) that may leave an archaeological trace—such as mining and modifying ochre pigments for body-painting—while developing theoretical arguments to justify inferences from symbolism in general to language in particular.
The time range for the evolution of language or its anatomical prerequisites extends, at least in principle, from the phylogenetic divergence of Homo (2.3 to 2.4 million years ago) from Pan (5 to 6 million years ago) to the emergence of full behavioral modernity some 50,000–150,000 years ago. Few dispute that Australopithecus probably lacked vocal communication significantly more sophisticated than that of great apes in general, but scholarly opinions vary as to the developments since the appearance of Homo some 2.5 million years ago. Some scholars assume the development of primitive language-like systems (proto-language) as early as Homo habilis, while others place the development of symbolic communication only with Homo erectus (1.8 million years ago) or with Homo heidelbergensis (0.6 million years ago) and the development of language proper with Homo sapiens, currently estimated at less than 200,000 years ago.
Using statistical methods to estimate the time required to achieve the current spread and diversity in modern languages, Johanna Nichols—a linguist at the University of California, Berkeley—argued in 1998 that vocal languages must have begun diversifying in the human species at least 100,000 years ago. Estimates of this kind are not universally accepted, but jointly considering genetic, archaeological, palaeontological, and much other evidence indicates that language probably emerged somewhere in sub-Saharan Africa during the Middle Stone Age, roughly contemporaneous with the speciation of Homo sapiens.
Subsections (0):
, Section: Language origin hypotheses (1):

Subsections (14):
Section: Early speculations (2):
I cannot doubt that language owes its origin to the imitation and modification, aided by signs and gestures, of various natural sounds, the voices of other animals, and man's own instinctive cries. In 1861, historical linguist Max Müller published a list of speculative theories concerning the origins of spoken language:
Bow-wow. The bow-wow or cuckoo theory, which Müller attributed to the German philosopher Johann Gottfried Herder, saw early words as imitations of the cries of beasts and birds.
Pooh-pooh. The pooh-pooh theory saw the first words as emotional interjections and exclamations triggered by pain, pleasure, surprise, etc.
Ding-dong. Müller suggested what he called the ding-dong theory, which states that all things have a vibrating natural resonance, echoed somehow by man in his earliest words.
Yo-he-ho. The yo-he-ho theory claims language emerged from collective rhythmic labor, the attempt to synchronize muscular effort resulting in sounds such as heave alternating with sounds such as ho.
Ta-ta. This did not feature in Max Müller's list, having been proposed in 1930 by Sir Richard Paget. According to the ta-ta theory, humans made the earliest words by tongue movements that mimicked manual gestures, rendering them audible.
Most scholars today consider all such theories not so much wrong—they occasionally offer peripheral insights—as naïve and irrelevant. The problem with these theories is that they rest on the assumption that once early humans had discovered a workable mechanism for linking sounds with meanings, language would automatically have evolved.
Much earlier, Medieval Muslim scholars developed theories on the origin of language. Their theories were of five general types:

Naturalist: There is a natural relation between expressions and the things they signify. Language thus emerged from a natural human inclination to imitate the sounds of nature.
Conventionalist: Language is a social convention. The names of things are arbitrary inventions of humans.
Revelationist: Language was gifted to humans by God, and it was thus God—and not humans—who named everything.
Revelationist-Conventionalist: God revealed to humans a core base of language—enabling humans to communicate with each other—and then humans invented the rest of language.
Non-Committal: The view that conventionalist and revelationist theories are equally plausible.
Subsections (0):

Section: Problems of reliability and deception (2):
From the perspective of signalling theory, the main obstacle to the evolution of language-like communication in nature is not a mechanistic one. Rather, it is the fact that symbols—arbitrary associations of sounds or other perceptible forms with corresponding meanings—are unreliable and may well be false. As the saying goes, ""words are cheap"". The problem of reliability was not recognized at all by Darwin, Müller or the other early evolutionary theorists.
Animal vocal signals are, for the most part, intrinsically reliable. When a cat purrs, the signal constitutes direct evidence of the animal's contented state. The signal is trusted, not because the cat is inclined to be honest, but because it just cannot fake that sound. Primate vocal calls may be slightly more manipulable, but they remain reliable for the same reason—because they are hard to fake. Primate social intelligence is ""Machiavellian""—self-serving and unconstrained by moral scruples. Monkeys, apes and humans often attempt to deceive each other, while at the same time remaining constantly on guard against falling victim to deception themselves. Paradoxically, it is theorized that primates' resistance to deception is what blocks the evolution of their signalling systems along language-like lines. Language is ruled out because the best way to guard against being deceived is to ignore all signals except those that are instantly verifiable. Words automatically fail this test.
Words are easy to fake. Should they turn out to be lies, listeners will adapt by ignoring them in favor of hard-to-fake indices or cues. For language to work, then, listeners must be confident that those with whom they are on speaking terms are generally likely to be honest. A peculiar feature of language is ""displaced reference"", which means reference to topics outside the currently perceptible situation. This property prevents utterances from being corroborated in the immediate ""here"" and ""now"". For this reason, language presupposes relatively high levels of mutual trust in order to become established over time as an evolutionarily stable strategy. This stability is born of a longstanding mutual trust and is what grants language its authority. A theory of the origins of language must therefore explain why humans could begin trusting cheap signals in ways that other animals apparently cannot (see signalling theory).
Subsections (4):
Section: The ""mother tongues"" hypothesis (3):
The ""mother tongues"" hypothesis was proposed in 2004 as a possible solution to this problem. W. Tecumseh Fitch suggested that the Darwinian principle of ""kin selection""—the convergence of genetic interests between relatives—might be part of the answer. Fitch suggests that languages were originally ""mother tongues"". If language evolved initially for communication between mothers and their own biological offspring, extending later to include adult relatives as well, the interests of speakers and listeners would have tended to coincide. Fitch argues that shared genetic interests would have led to sufficient trust and cooperation for intrinsically unreliable signals—words—to become accepted as trustworthy and so begin evolving for the first time.
Critics of this theory point out that kin selection is not unique to humans. So even if one accepts Fitch's initial premises, the extension of the posited ""mother tongue"" networks from close relatives to more distant relatives remains unexplained. Fitch argues, however, that the extended period of physical immaturity of human infants and the postnatal growth of the human brain give the human-infant relationship a different and more extended period of intergenerational dependency than that found in any other species.
Subsections (0):

Section: The ""obligatory reciprocal altruism"" hypothesis (3):
Ib Ulbæk invokes another standard Darwinian principle—""reciprocal altruism""—to explain the unusually high levels of intentional honesty necessary for language to evolve. ""Reciprocal altruism"" can be expressed as the principle that if you scratch my back, I'll scratch yours. In linguistic terms, it would mean that if you speak truthfully to me, I'll speak truthfully to you. Ordinary Darwinian reciprocal altruism, Ulbæk points out, is a relationship established between frequently interacting individuals. For language to prevail across an entire community, however, the necessary reciprocity would have needed to be enforced universally instead of being left to individual choice. Ulbæk concludes that for language to evolve, society as a whole must have been subject to moral regulation.
Critics point out that this theory fails to explain when, how, why or by whom ""obligatory reciprocal altruism"" could possibly have been enforced. Various proposals have been offered to remedy this defect. A further criticism is that language does not work on the basis of reciprocal altruism anyway. Humans in conversational groups do not withhold information to all except listeners likely to offer valuable information in return. On the contrary, they seem to want to advertise to the world their access to socially relevant information, broadcasting that information without expectation of reciprocity to anyone who will listen.
Subsections (0):

Section: The gossip and grooming hypothesis (3):
Gossip, according to Robin Dunbar in his book Grooming, Gossip and the Evolution of Language, language does for group-living humans what manual grooming does for other primates—it allows individuals to service their relationships and so maintain their alliances on the basis of the principle: if you scratch my back, I'll scratch yours. Dunbar argues that as humans began living in increasingly larger social groups, the task of manually grooming all one's friends and acquaintances became so time-consuming as to be unaffordable. In response to this problem, humans developed ""a cheap and ultra-efficient form of grooming""—vocal grooming. To keep allies happy, one now needs only to ""groom"" them with low-cost vocal sounds, servicing multiple allies simultaneously while keeping both hands free for other tasks. Vocal grooming then evolved gradually into vocal language—initially in the form of ""gossip"". Dunbar's hypothesis seems to be supported by adaptations, in the structure of language, to the function of narration in general.
Critics of this theory point out that the very efficiency of ""vocal grooming""—the fact that words are so cheap—would have undermined its capacity to signal commitment of the kind conveyed by time-consuming and costly manual grooming. A further criticism is that the theory does nothing to explain the crucial transition from vocal grooming—the production of pleasing but meaningless sounds—to the cognitive complexities of syntactical speech.
Subsections (0):

Section: Ritual/speech coevolution (3):
The ritual/speech coevolution theory was originally proposed by social anthropologist Roy Rappaport before being elaborated by anthropologists such as Chris Knight, Jerome Lewis, Nick Enfield, Camilla Power and Ian Watts. Cognitive scientist and robotics engineer Luc Steels is another prominent supporter of this general approach, as is biological anthropologist and neuroscientist Terrence Deacon. A more recent champion of the approach is the Chomskyan specialist in linguistic syntax, Cedric Boeckx.
These scholars argue that there can be no such thing as a ""theory of the origins of language"". This is because language is not a separate adaptation but an internal aspect of something much wider—namely, the entire domain known to anthropologists as human symbolic culture. Attempts to explain language independently of this wider context have failed, say these scientists, because they are addressing a problem with no solution. Language would not work outside its necessary environment of confidence-building social mechanisms and institutions. For example, it would not work for a nonhuman ape communicating with others of its kind in the wild. Not even the cleverest nonhuman ape could make language work under such conditions.

Lie and alternative, inherent in language ... pose problems to any society whose structure is founded on language, which is to say all human societies. I have therefore argued that if there are to be words at all it is necessary to establish The Word, and that The Word is established by the invariance of liturgy.
Advocates of this school of thought point out that words are cheap. Should an especially clever nonhuman ape, or even a group of articulate nonhuman apes, try to use words in the wild, they would carry no conviction. The primate vocalizations that do carry conviction—those they actually use—are unlike words, in that they are emotionally expressive, intrinsically meaningful, and reliable because they are relatively costly and hard to fake.
Oral and gestural languages consist of pattern-making whose cost is essentially zero. As pure social conventions, signals of this kind cannot evolve in a Darwinian social world—they are a theoretical impossibility. Being intrinsically unreliable, language works only if one can build up a reputation for trustworthiness within a certain kind of society—namely, one where symbolic cultural facts (sometimes called ""institutional facts"") can be established and maintained through collective social endorsement. In any hunter-gatherer society, the basic mechanism for establishing trust in symbolic cultural facts is collective ritual. Therefore, the task facing researchers into the origins of language is more multidisciplinary than is usually supposed. It involves addressing the evolutionary emergence of human ritual, kinship, religion and symbolic culture taken as a whole, with language an important but subsidiary component.
An authoritative current proponent of the 'ritual/speech co-evolution' approach is Cedric Boeckx, a specialist in syntax known for his work in explicating Chomsky's 'Minimalist' program. In a 2023 article, Boeckx endorses the Rappaport/Searle/Knight way of capturing the ""special"" nature of human words. Words are symbols. This means that, from a standpoint in Darwinian signal evolution theory, they are ""patently false signals."" Words are facts, but ""facts whose existence depends entirely on subjective belief"". In philosophical terms, they are ""institutional facts"": fictions that are granted factual status within human social institutions From this standpoint, according to Boeckx, linguistic utterances are symbolic to the extent that they are patent falsehoods serving as guides to communicative intentions. ""They are communicatively useful untruths, as it were."" The reason why words can survive among humans despite being false is largely down to a matter of trust. The corresponding origins theory is that language can only have begun to evolve from the moment humans started reciprocally faking in communicatively helpful ways, i.e., when they became capable of upholding the levels of trust necessary for linguistic communication to work. 
The point here is that an ape or other nonhuman must always carry at least some of the burden of generating the trust necessary for communication to work. That is, in order to be taken seriously, each signal it emits must be a patently reliable one, trusted because it is rooted in some way in the real world. But now imagine what might happen under social conditions where trust could be taken for granted. The signaller could stop worrying about reliability and concentrate instead on perceptual discriminability. Carried to its conclusion, this should permit digital signaling—the cheapest and most efficient kind of communication. 
From this philosophical standpoint, animal communication cannot be digital because it does not have the luxury of being patently false. Costly signals of any kind can only be evaluated on an analog scale. Put differently, truly symbolic, digital signals become socially acceptable only under highly unusual conditions—such as those internal to a ritually bonded community whose members are not tempted to lie. 
Critics of the speech/ritual co-evolution idea theory include Noam Chomsky, who terms it the ""non-existence"" hypothesis—a denial of the very existence of language as an object of study for natural science. Chomsky's own theory is that language emerged in an instant and in perfect form, prompting his critics in turn, to retort that only something that does not exist—a theoretical construct or convenient scientific fiction—could possibly emerge in such a miraculous way. The controversy remains unresolved.
Subsections (0):

Section: Tool resiliency, grammar and language production (2):
Acheulean tool use began during the Lower Paleolithic approximately 1.75 million years ago. Studies focusing on the lateralization of Acheulean tool production and language production have noted similar areas of blood flow when engaging in these activities separately; this theory suggests that the brain functions needed for the production of tools across generations is consistent with the brain systems required for producing language. Researchers used functional transcranial Doppler ultrasonography (fTDC) and had participants perform activities related to the creation of tools using the same methods during the Lower Paleolithic as well as a task designed specifically for word generation. The purpose of this test was to focus on the planning aspect of Acheulean tool making and cued word generation in language (an example of cued word generation would be trying to list all words beginning with a given letter). Theories of language developing alongside tool use has been theorized by multiple individuals, however until recently there has been little empirical data to support these hypotheses. Focusing on the results of the study performed by Uomini et al. evidence for the usage of the same brain areas has been found when looking at cued word generation and Achuelean tool use. The relationship between tool use and language production is found in working and planning memory respectively and was found to be similar across a variety of participants, furthering evidence that these areas of the brain are shared. This evidence lends credibility to the theory that language developed alongside tool use in the Lower Paleolithic.
Subsections (0):

Section: Humanistic theory (2):
The humanistic tradition considers language as a human invention. Renaissance philosopher Antoine Arnauld gave a detailed description of his idea of the origin of language in Port-Royal Grammar. According to Arnauld, people are social and rational by nature, and this urged them to create language as a means to communicate their ideas to others. Language construction would have occurred through a slow and gradual process. In later theory, especially in functional linguistics, the primacy of communication is emphasised over psychological needs.
The exact way language evolved is however not considered as vital to the study of languages. Structural linguist Ferdinand de Saussure abandoned evolutionary linguistics after having come to the firm conclusion that it would not be able to provide any further revolutionary insight after the completion of the major works in historical linguistics by the end of the 19th century. Saussure was particularly sceptical of the attempts of August Schleicher and other Darwinian linguists to access prehistorical languages through series of reconstructions of proto-languages.
Saussure's solution to the problem of language evolution involves dividing theoretical linguistics in two. Evolutionary and historical linguistics are renamed as diachronic linguistics. It is the study of language change, but it has only limited explanatory power due to the inadequacy of all of the reliable research material that could ever be made available. Synchronic linguistics, in contrast, aims to widen scientists' understanding of language through a study of a given contemporary or historical language stage as a system in its own right.
Although Saussure paid much focus to diachronic linguistics, later structuralists who equated structuralism with the synchronic analysis were sometimes criticised of ahistoricism. According to structural anthropologist Claude Lévi-Strauss, language and meaning—in opposition to ""knowledge, which develops slowly and progressively""—must have appeared in an instant.
Structuralism, as first introduced to sociology by Émile Durkheim, is nonetheless a type of humanistic evolutionary theory which explains diversification as necessitated by growing complexity. There was a shift of focus to functional explanation after Saussure's death. Functional structuralists including the Prague Circle linguists and André Martinet explained the growth and maintenance of structures as being necessitated by their functions. For example, novel technologies make it necessary for people to invent new words, but these may lose their function and be forgotten as the technologies are eventually replaced by more modern ones.
Subsections (0):

Section: Chomsky's single-step theory (2):
According to Noam Chomsky's single-mutation theory, the emergence of language resembled the formation of a crystal; with digital infinity as the seed crystal in a super-saturated primate brain, on the verge of blossoming into the human mind, by physical law, once evolution added a single small but crucial keystone. Thus, in this theory, language appeared rather suddenly within the history of human evolution. Chomsky, writing with computational linguist and computer scientist Robert C. Berwick, suggests that this scenario is completely compatible with modern biology. They note that ""none of the recent accounts of human language evolution seem to have completely grasped the shift from conventional Darwinism to its fully stochastic modern version—specifically, that there are stochastic effects not only due to sampling like directionless drift, but also due to directed stochastic variation in fitness, migration, and heritability—indeed, all the ""forces"" that affect individual or gene frequencies ... All this can affect evolutionary outcomes—outcomes that as far as we can make out are not brought out in recent books on the evolution of language, yet would arise immediately in the case of any new genetic or individual innovation, precisely the kind of scenario likely to be in play when talking about language's emergence.""
Citing evolutionary geneticist Svante Pääbo, they concur that a substantial difference must have occurred to differentiate Homo sapiens from Neanderthals to ""prompt the relentless spread of our species, who had never crossed open water, up and out of Africa and then on across the entire planet in just a few tens of thousands of years. ... What we do not see is any kind of 'gradualism' in new tool technologies or innovations like fire, shelters, or figurative art."" Berwick and Chomsky therefore suggest language emerged approximately between 200,000 years ago and 60,000 years ago (between the appearance of the first anatomically modern humans in southern Africa and the last exodus from Africa respectively). ""That leaves us with about 130,000 years, or approximately 5,000–6,000 generations of time for evolutionary change. This is not 'overnight in one generation' as some have (incorrectly) inferred—but neither is it on the scale of geological eons. It's time enough—within the ballpark for what Nilsson and Pelger (1994) estimated as the time required for the full evolution of a vertebrate eye from a single cell, even without the invocation of any 'evo-devo' effects.""
The single-mutation theory of language evolution has been directly questioned on different grounds. A formal analysis of the probability of such a mutation taking place and going to fixation in the species has concluded that such a scenario is unlikely, with multiple mutations with more moderate fitness effects being more probable. Another criticism has questioned the logic of the argument for single mutation and puts forward that from the formal simplicity of Merge, the capacity Berwick and Chomsky deem the core property of human language that emerged suddenly, one cannot derive the (number of) evolutionary steps that led to it.
Subsections (0):

Section: The Romulus and Remus hypothesis (2):
The Romulus and Remus hypothesis, proposed by neuroscientist Andrey Vyshedskiy, seeks to address the question as to why the modern speech apparatus originated over 500,000 years before the earliest signs of modern human imagination. This hypothesis proposes that there were two phases that led to modern recursive language. The phenomenon of recursion occurs across multiple linguistic domains, arguably most prominently in syntax and morphology. Thus, by nesting a structure such as a sentence or a word within themselves, it enables the generation of potentially (countably) infinite new variations of that structure. For example, the base sentence [Peter likes apples.] can be nested in irrealis clauses to produce [[Mary said [Peter likes apples.]], [Paul believed [Mary said [Peter likes apples.]]] and so forth.
The first phase includes the slow development of non-recursive language with a large vocabulary along with the modern speech apparatus, which includes changes to the hyoid bone, increased voluntary control of the muscles of the diaphragm, the evolution of the FOXP2 gene, as well as other changes by 600,000 years ago. Then, the second phase was a rapid Chomskian single step, consisting of three distinct events that happened in quick succession around 70,000 years ago and allowed the shift from non-recursive to recursive language in early hominins. 

A genetic mutation that slowed down the prefrontal synthesis (PFS) critical period of at least two children that lived together.
This allowed these children to create recursive elements of language such as spatial prepositions.
Then this merged with their parents' non-recursive language to create recursive language.
It is not enough for children to have a modern prefrontal cortex (PFC) to allow the development of PFS; the children must also be mentally stimulated and have recursive elements already in their language to acquire PFS. Since their parents would not have invented these elements yet, the children would have had to do it themselves, which is a common occurrence among young children that live together, in a process called cryptophasia. This means that delayed PFC development would have allowed more time to acquire PFS and develop recursive elements.
Delayed PFC development also comes with negative consequences, such as a longer period of reliance on one's parents to survive and lower survival rates. For modern language to have occurred, PFC delay had to have an immense survival benefit in later life, such as PFS ability. This suggests that the mutation that caused PFC delay and the development of recursive language and PFS occurred simultaneously, which lines up with evidence of a genetic bottleneck around 70,000 years ago. This could have been the result of a few individuals who developed PFS and recursive language which gave them significant competitive advantage over all other humans at the time.
Subsections (0):

Section: Gestural theory (2):
The gestural theory states that human language developed from gestures that were used for simple communication.
Two types of evidence support this theory.

Gestural language and vocal language depend on similar neural systems. The regions on the cortex that are responsible for mouth and hand movements border each other.
Nonhuman primates can use gestures or symbols for at least primitive communication, and some of their gestures resemble those of humans, such as the ""begging posture"", with the hands stretched out, which humans share with chimpanzees.
Research has found strong support for the idea that verbal language and sign language depend on similar neural structures. Patients who used sign language, and who suffered from a left-hemisphere lesion, showed the same disorders with their sign language as vocal patients did with their oral language. Other researchers found that the same left-hemisphere brain regions were active during sign language as during the use of vocal or written language.
Primate gesture is at least partially genetic: different nonhuman apes will perform gestures characteristic of their species, even if they have never seen another ape perform that gesture. For example, gorillas beat their breasts. This shows that gestures are an intrinsic and important part of primate communication, which supports the idea that language evolved from gesture.
Further evidence suggests that gesture and language are linked. In humans, manually gesturing has an effect on concurrent vocalizations, thus creating certain natural vocal associations of manual efforts. Chimpanzees move their mouths when performing fine motor tasks. These mechanisms may have played an evolutionary role in enabling the development of intentional vocal communication as a supplement to gestural communication. Voice modulation could have been prompted by preexisting manual actions.
From infancy, gestures both supplement and predict speech. This addresses the idea that gestures quickly change in humans from a sole means of communication (from a very young age) to a supplemental and predictive behavior that is used despite the ability to communicate verbally. This too serves as a parallel to the idea that gestures developed first and language subsequently built upon it.
Two possible scenarios have been proposed for the development of language, one of which supports the gestural theory:

Language developed from the calls of human ancestors.
Language was derived from gesture.
The first perspective that language evolved from the calls of human ancestors seems logical because both humans and animals make sounds or cries. One evolutionary reason to refute this is that, anatomically, the centre that controls calls in monkeys and other animals is located in a completely different part of the brain than in humans. In monkeys, this centre is located in the depths of the brain related to emotions. In the human system, it is located in an area unrelated to emotion. Humans can communicate simply to communicate—without emotions. So, anatomically, this scenario does not work. This suggests that language was derived from gesture(humans communicated by gesture first and sound was attached later).
The important question for gestural theories is why there was a shift to vocalization. Various explanations have been proposed: 

Human ancestors started to use more and more tools, meaning that their hands were occupied and could no longer be used for gesturing.
Manual gesturing requires that speakers and listeners be visible to one another. In many situations, they might need to communicate, even without visual contact—for example after nightfall or when foliage obstructs visibility.
A composite hypothesis holds that early language took the form of part gestural and part vocal mimesis (imitative 'song-and-dance'), combining modalities because all signals (like those of nonhuman apes and monkeys) still needed to be costly in order to be intrinsically convincing. In that event, each multi-media display would have needed not just to disambiguate an intended meaning but also to inspire confidence in the signal's reliability. The suggestion is that only once community-wide contractual understandings had come into force could trust in communicative intentions be automatically assumed, at last allowing Homo sapiens to shift to a more efficient default format. Since vocal distinctive features (sound contrasts) are ideal for this purpose, it was only at this point—when intrinsically persuasive body-language was no longer required to convey each message—that the decisive shift from manual gesture to the current primary reliance on spoken language occurred.
A comparable hypothesis states that in 'articulate' language, gesture and vocalisation are intrinsically linked, as language evolved from equally intrinsically linked dance and song.
Humans still use manual and facial gestures when they speak, especially when people meet who have no language in common. There are also a great number of sign languages still in existence, commonly associated with Deaf communities. These sign languages are equal in complexity, sophistication, and expressive power, to any oral language. The cognitive functions are similar and the parts of the brain used are similar. The main difference is that the ""phonemes"" are produced on the outside of the body, articulated with hands, body, and facial expression, rather than inside the body articulated with tongue, teeth, lips, and breathing. (Compare the motor theory of speech perception.)
Critics of gestural theory note that it is difficult to name serious reasons why the initial pitch-based vocal communication (which is present in primates) would be abandoned in favor of the much less effective non-vocal, gestural communication. However, Michael Corballis has pointed out that it is supposed that primate vocal communication (such as alarm calls) cannot be controlled consciously, unlike hand movement, and thus it is not credible as precursor to human language; primate vocalization is rather homologous to and continued in involuntary reflexes (connected with basic human emotions) such as screams or laughter (the fact that these can be faked does not disprove the fact that genuine involuntary responses to fear or surprise exist). Also, gesture is not generally less effective, and depending on the situation can even be advantageous, for example in a loud environment or where it is important to be silent, such as on a hunt. Other challenges to the ""gesture-first"" theory have been presented by researchers in psycholinguistics, including David McNeill.
Subsections (0):

Section: Tool-use associated sound in the evolution of language (2):
Proponents of the motor theory of language evolution have primarily focused on the visual domain and communication through observation of movements. The Tool-use sound hypothesis suggests that the production and perception of sound also contributed substantially, particularly incidental sound of locomotion (ISOL) and tool-use sound (TUS). Human bipedalism resulted in rhythmic and more predictable ISOL. That may have stimulated the evolution of musical abilities, auditory working memory, and abilities to produce complex vocalizations, and to mimic natural sounds. Since the human brain proficiently extracts information about objects and events from the sounds they produce, TUS, and mimicry of TUS, might have achieved an iconic function. The prevalence of sound symbolism in many extant languages supports this idea. Self-produced TUS activates multimodal brain processing (motor neurons, hearing, proprioception, touch, vision), and TUS stimulates primate audiovisual mirror neurons, which is likely to stimulate the development of association chains. Tool use and auditory gestures involve motor-processing of the forelimbs, which is associated with the evolution of vertebrate vocal communication. The production, perception, and mimicry of TUS may have resulted in a limited number of vocalizations or protowords that were associated with tool use. A new way to communicate about tools, especially when out of sight, would have had selective advantage. A gradual change in acoustic properties, meaning, or both could have resulted in arbitrariness and an expanded repertoire of words. Humans have been increasingly exposed to TUS over millions of years, coinciding with the period during which spoken language evolved.
Subsections (0):

Section: Mirror neurons and language origins (2):
In humans, functional MRI studies have reported finding areas homologous to the monkey mirror neuron system in the inferior frontal cortex, close to Broca's area, one of the language regions of the brain. This has led to suggestions that human language evolved from a gesture performance/understanding system implemented in mirror neurons. Mirror neurons have been said to have the potential to provide a mechanism for action-understanding, imitation-learning, and the simulation of other people's behavior. This hypothesis is supported by some cytoarchitectonic homologies between monkey premotor area F5 and human Broca's area.
Rates of vocabulary expansion link to the ability of children to vocally mirror non-words and so to acquire the new word pronunciations. Such speech repetition occurs automatically, quickly and separately in the brain to speech perception. Moreover, such vocal imitation can occur without comprehension such as in speech shadowing and echolalia. Further evidence for this link comes from a recent study in which the brain activity of two participants was measured using fMRI while they were gesturing words to each other using hand gestures with a game of charades—a modality that some have suggested might represent the evolutionary precursor of human language. Analysis of the data using Granger Causality revealed that the mirror-neuron system of the observer indeed reflects the pattern of activity of in the motor system of the sender, supporting the idea that the motor concept associated with the words is indeed transmitted from one brain to another using the mirror system.
Not all linguists agree with the above arguments, however. In particular, supporters of Noam Chomsky argue against the possibility that the mirror neuron system can play any role in the hierarchical recursive structures essential to syntax.
Subsections (0):

Section: Putting-down-the-baby theory (2):
According to Dean Falk's ""putting-down-the-baby"" theory, vocal interactions between early hominid mothers and infants began a sequence of events that led, eventually, to human ancestors' earliest words. The basic idea is that evolving human mothers, unlike their counterparts in other primates, could not move around and forage with their infants clinging onto their backs. Loss of fur in the human case left infants with no means of clinging on. Frequently, therefore, mothers had to put their babies down. As a result, these babies needed to be reassured that they were not being abandoned. Mothers responded by developing 'motherese'—an infant-directed communicative system embracing facial expressions, body language, touching, patting, caressing, laughter, tickling, and emotionally expressive contact calls. The argument is that language developed out of this interaction.
In The Mental and Social Life of Babies, psychologist Kenneth Kaye noted that no usable adult language could have evolved without interactive communication between very young children and adults. ""No symbolic system could have survived from one generation to the next if it could not have been easily acquired by young children under their normal conditions of social life.""
Subsections (0):

Section: From-where-to-what theory (2):
The ""from where to what"" model is a language evolution model that is derived primarily from the organization of language processing in the brain into two structures: the auditory dorsal stream and the auditory ventral stream. It hypothesizes seven stages of language evolution (see illustration). Speech originated for the purpose of exchanging contact calls between mothers and their offspring to find one another in the event they became separated (illustration part 1). The contact calls could be modified with intonations in order to express either a higher or lower level of distress (illustration part 2). The use of two types of contact calls enabled the first question-answer conversation. In this scenario, the child would emit a low-level distress call to express a desire to interact with an object, and the mother would respond with either another low-level distress call (to express approval of the interaction) or a high-level distress call (to express disapproval) (illustration part 3). Over time, the improved use of intonations and vocal control led to the invention of unique calls (phonemes) associated with distinct objects (illustration part 4). At first, children learned the calls (phonemes) from their parents by imitating their lip-movements (illustration part 5). Eventually, infants were able to encode into long-term memory all the calls (phonemes). Consequentially, mimicry via lip-reading was limited to infancy and older children learned new calls through mimicry without lip-reading (illustration part 6). Once individuals became capable of producing a sequence of calls, this allowed multi-syllabic words, which increased the size of their vocabulary (illustration part 7). The use of words, composed of sequences of syllables, provided the infra structure for communicating with sequences of words (i.e., sentences).
The theory's name is derived from the two auditory streams, which are both found in the brains of humans and other primates. The auditory ventral stream is responsible for sound recognition, and so it is referred to as the auditory what stream. In primates, the auditory dorsal stream is responsible for sound localization, and thus it is called the auditory where stream. Only in humans (in the left hemisphere), is it also responsible for other processes associated with language use and acquisition, such as speech repetition and production, integration of phonemes with their lip movements, perception and production of intonations, phonological long-term memory (long-term memory storage of the sounds of words), and phonological working memory (the temporary storage of the sounds of words). Some evidence also indicates a role in recognising others by their voices. The emergence of each of these functions in the auditory dorsal stream represents an intermediate stage in the evolution of language.
A contact call origin for human language is consistent with animal studies, as like human language, contact call discrimination in monkeys is lateralised to the left hemisphere. Mice with knock-out to language related genes (such as FOXP2 and SRPX2) also resulted in the pups no longer emitting contact calls when separated from their mothers. Supporting this model is also its ability to explain unique human phenomena, such as the use of intonations when converting words into commands and questions, the tendency of infants to mimic vocalisations during the first year of life (and its disappearance later on) and the protruding and visible human lips, which are not found in other apes. This theory could be considered an elaboration of the putting-down-the-baby theory of language evolution.
Subsections (0):

Section: Grammaticalisation theory (2):
""Grammaticalisation"" is a continuous historical process in which free-standing words develop into grammatical appendages, while these in turn become ever more specialised and grammatical. An initially ""incorrect"" usage, in becoming accepted, leads to unforeseen consequences, triggering knock-on effects and extended sequences of change. Paradoxically, grammar evolves because, in the final analysis, humans care less about grammatical niceties than about making themselves understood. If this is how grammar evolves today, according to this school of thought, similar principles at work can be legitimately inferred among distant human ancestors, when grammar itself was first being established.
In order to reconstruct the evolutionary transition from early language to languages with complex grammars, it is necessary to know which hypothetical sequences are plausible and which are not. In order to convey abstract ideas, the first recourse of speakers is to fall back on immediately recognizable concrete imagery, very often deploying metaphors rooted in shared bodily experience. A familiar example is the use of concrete terms such as ""belly"" or ""back"" to convey abstract meanings such as ""inside"" or ""behind"". Equally metaphorical is the strategy of representing temporal patterns on the model of spatial ones. For example, English speakers might say ""It is going to rain"", modelled on ""I am going to London."" This can be abbreviated colloquially to ""It's gonna rain."" Even when in a hurry, English speakers do not say ""I'm gonna London""—the contraction is restricted to the job of specifying tense. From such examples it can be seen why grammaticalisation is consistently unidirectional—from concrete to abstract meaning, not the other way around.
Grammaticalisation theorists picture early language as simple, perhaps consisting only of nouns.p. 111 Even under that extreme theoretical assumption, however, it is difficult to imagine what would realistically have prevented people from using, say, ""spear"" as if it were a verb (""Spear that pig!""). People might have used their nouns as verbs or their verbs as nouns as occasion demanded. In short, while a noun-only language might seem theoretically possible, grammaticalisation theory indicates that it cannot have remained fixed in that state for any length of time.
Creativity drives grammatical change. This presupposes a certain attitude on the part of listeners. Instead of punishing deviations from accepted usage, listeners must prioritise imaginative mind-reading. Imaginative creativity—emitting a leopard alarm when no leopard was present, for example—is not the kind of behaviour which, say, vervet monkeys would appreciate or reward. Creativity and reliability are incompatible demands; for ""Machiavellian"" primates as for animals generally, the overriding pressure is to demonstrate reliability. If humans escape these constraints, it is because in their case, listeners are primarily interested in mental states.
To focus on mental states is to accept fictions—inhabitants of the imagination—as potentially informative and interesting. An example is metaphor: a metaphor is, literally, a false statement. In Romeo and Juliet, Romeo declares ""Juliet is the sun!"". Juliet is a woman, not a ball of plasma in the sky, but human listeners are not (or not usually) pedants insistent on point-by-point factual accuracy. They want to know what the speaker has in mind. Grammaticalisation is essentially based on metaphor. To outlaw its use would be to stop grammar from evolving and, by the same token, to exclude all possibility of expressing abstract thought.
A criticism of all this is that while grammaticalisation theory might explain language change today, it does not satisfactorily address the really difficult challenge—explaining the initial transition from primate-style communication to language as it is known today. Rather, the theory assumes that language already exists. As Bernd Heine and Tania Kuteva acknowledge: ""Grammaticalisation requires a linguistic system that is used regularly and frequently within a community of speakers and is passed on from one group of speakers to another"". Outside modern humans, such conditions do not prevail.
Subsections (0):

Section: Evolution-progression model (2):
Human language is used for self-expression; however, expression displays different stages. The consciousness of self and feelings represents the stage immediately prior to the external, phonetic expression of feelings in the form of sound, i.e., language. Intelligent animals such as dolphins, Eurasian magpies, and chimpanzees live in communities, wherein they assign themselves roles for group survival and show emotions such as sympathy. When such animals view their reflection (mirror test), they recognise themselves and exhibit self-consciousness. Notably, humans evolved in a quite different environment than that of these animals. Human survival became easier with the development of tools, shelter, and fire, thus facilitating further advancement of social interaction, self-expression, and tool-making, as for hunting and gathering. The increasing brain size allowed advanced provisioning and tools and the technological advances during the Palaeolithic era that built upon the previous evolutionary innovations of bipedalism and hand versatility allowed the development of human language.
Subsections (0):

Section: Self-domesticated ape theory (2):
According to a study investigating the song differences between white-rumped munias and its domesticated counterpart (Bengalese finch), the wild munias use a highly stereotyped song sequence, whereas the domesticated ones sing a highly unconstrained song. In wild finches, song syntax is subject to female preference—sexual selection—and remains relatively fixed. However, in the Bengalese finch, natural selection is replaced by breeding, in this case for colourful plumage, and thus, decoupled from selective pressures, stereotyped song syntax is allowed to drift. It is replaced, supposedly within 1000 generations, by a variable and learned sequence. Wild finches, moreover, are thought incapable of learning song sequences from other finches. In the field of bird vocalisation, brains capable of producing only an innate song have very simple neural pathways: the primary forebrain motor centre, called the robust nucleus of arcopallium, connects to midbrain vocal outputs, which in turn project to brainstem motor nuclei. By contrast, in brains capable of learning songs, the arcopallium receives input from numerous additional forebrain regions, including those involved in learning and social experience. Control over song generation has become less constrained, more distributed, and more flexible.
One way to think about human evolution is that humans are self-domesticated apes. Just as domestication relaxed selection for stereotypic songs in the finches—mate choice was supplanted by choices made by the aesthetic sensibilities of bird breeders and their customers—so might human cultural domestication have relaxed selection on many of their primate behavioural traits, allowing old pathways to degenerate and reconfigure. Given the highly indeterminate way that mammalian brains develop—they basically construct themselves ""bottom up"", with one set of neuronal interactions preparing for the next round of interactions—degraded pathways would tend to seek out and find new opportunities for synaptic hookups. Such inherited de-differentiations of brain pathways might have contributed to the functional complexity that characterises human language. And, as exemplified by the finches, such de-differentiations can occur in very rapid time-frames.
Subsections (0):
, Section: Speech and language for communication (1):
A distinction can be drawn between speech and language. Language is not necessarily spoken: it might alternatively be written or signed. Speech is among a number of different methods of encoding and transmitting linguistic information, albeit arguably the most natural one.
Some scholars, such as Noam Chomsky, view language as an initially cognitive development, its ""externalisation"" to serve communicative purposes occurring later in human evolution. According to one such school of thought, the key feature distinguishing human language is recursion, (in this context, the iterative embedding of phrases within phrases). Other scholars—notably Daniel Everett—deny that recursion is universal, citing certain languages (e.g. Pirahã) which allegedly lack this feature.
The ability to ask questions is considered by some to distinguish language from non-human systems of communication. Some captive primates (notably bonobos and chimpanzees), having learned to use rudimentary signing to communicate with their human trainers, proved able to respond correctly to complex questions and requests. Yet they failed to ask even the simplest questions themselves. Conversely, human children are able to ask their first questions (using only question intonation) at the babbling period of their development, long before they start using syntactic structures. Although babies from different cultures acquire native languages from their social environment, all languages of the world without exception—tonal, non-tonal, intonational and accented—use similar rising ""question intonation"" for yes–no questions. This fact is a strong evidence of the universality of question intonation. In general, according to some authors, sentence intonation/pitch is pivotal in spoken grammar and is the basic information used by children to learn the grammar of whatever language.
Subsections (0):
, Section: Cognitive development and language (1):
Language users have high-level reference (or deixis), the ability to refer to things or states of being that are not in the immediate realm of the speaker. This ability is often related to theory of mind, or an awareness of the other as a being like the self with individual wants and intentions. According to Chomsky, Hauser and Fitch (2002), there are six main aspects of this high-level reference system:

Theory of mind
Capacity to acquire non-linguistic conceptual representations, such as the object/kind distinction
Referential vocal signals
Imitation as a rational, intentional system
Voluntary control over signal production as evidence of intentional communication
Number representation
Subsections (2):
Section: Theory of mind (2):
Simon Baron-Cohen (1999) argues that theory of mind must have preceded language use, based on evidence of use of the following characteristics as much as 40,000 years ago: intentional communication, repairing failed communication, teaching, intentional persuasion, intentional deception, building shared plans and goals, intentional sharing of focus or topic, and pretending. Moreover, Baron-Cohen argues that many primates show some, but not all, of these abilities. Call and Tomasello's research on chimpanzees supports this, in that individual chimps seem to understand that other chimps have awareness, knowledge, and intention, but do not seem to understand false beliefs. Many primates show some tendencies toward a theory of mind, but not a full one as humans have.
Ultimately, there is some consensus within the field that a theory of mind is necessary for language use. Thus, the development of a full theory of mind in humans was a necessary precursor to full language use.
Subsections (0):

Section: Number representation (2):
In one particular study, rats and pigeons were required to press a button a certain number of times to get food. The animals showed very accurate distinction for numbers less than four, but as the numbers increased, the error rate increased. In another, the primatologist Tetsuro Matsuzawa attempted to teach chimpanzees Arabic numerals. The difference between primates and humans in this regard was very large, as it took the chimps thousands of trials to learn 1–9, with each number requiring a similar amount of training time; yet, after learning the meaning of 1, 2 and 3 (and sometimes 4), children (after the age of 5.5 to 6) easily comprehend the value of greater integers by using a successor function (i.e. 2 is 1 greater than 1, 3 is 1 greater than 2, 4 is 1 greater than 3; once 4 is reached it seems most children suddenly understand that the value of any integer n is 1 greater than the previous integer). Put simply, other primates learn the meaning of numbers one by one, similar to their approach to other referential symbols, while children first learn an arbitrary list of symbols (1, 2, 3, 4...) and then later learn their precise meanings. These results can be seen as evidence for the application of the ""open-ended generative property"" of language in human numeral cognition.
Subsections (0):
, Section: Linguistic structures (1):

Subsections (2):
Section: Lexical-phonological principle (2):
Hockett (1966) details a list of features regarded as essential to describing human language. In the domain of the lexical-phonological principle, two features of this list are most important:

Productivity: users can create and understand completely novel messages.
New messages are freely coined by blending, analogizing from, or transforming old ones.
Either new or old elements are freely assigned new semantic loads by circumstances and context. This says that in every language, new idioms constantly come into existence.
Duality (of Patterning): a large number of meaningful elements are made up of a conveniently small number of independently meaningless yet message-differentiating elements.
The sound system of a language is composed of a finite set of simple phonological items. Under the specific phonotactic rules of a given language, these items can be recombined and concatenated, giving rise to morphology and the open-ended lexicon. A key feature of language is that a simple, finite set of phonological items gives rise to an infinite lexical system wherein rules determine the form of each item, and meaning is inextricably linked with form. Phonological syntax, then, is a simple combination of pre-existing phonological units. Related to this is another essential feature of human language: lexical syntax, wherein pre-existing units are combined, giving rise to semantically novel or distinct lexical items.
Certain elements of the lexical-phonological principle are known to exist outside of humans. While all (or nearly all) have been documented in some form in the natural world, very few coexist within the same species. Bird-song, singing nonhuman apes, and the songs of whales all display phonological syntax, combining units of sound into larger structures apparently devoid of enhanced or novel meaning. Certain other primate species do have simple phonological systems with units referring to entities in the world. However, in contrast to human systems, the units in these primates' systems normally occur in isolation, betraying a lack of lexical syntax. There is new evidence to suggest that Campbell's monkeys also display lexical syntax, combining two calls (a predator alarm call with a ""boom"", the combination of which denotes a lessened threat of danger), however it is still unclear whether this is a lexical or a morphological phenomenon.
Subsections (0):

Section: Pidgins and creoles (2):
Pidgins are significantly simplified languages with only rudimentary grammar and a restricted vocabulary. In their early stage, pidgins mainly consist of nouns, verbs, and adjectives with few or no articles, prepositions, conjunctions or auxiliary verbs. Often the grammar has no fixed word order and the words have no inflection.
If contact is maintained between the groups speaking the pidgin for long periods of time, the pidgins may become more complex over many generations. If the children of one generation adopt the pidgin as their native language it develops into a creole language, which becomes fixed and acquires a more complex grammar, with fixed phonology, syntax, morphology, and syntactic embedding. The syntax and morphology of such languages may often have local innovations not obviously derived from any of the parent languages.
Studies of creole languages around the world have suggested that they display remarkable similarities in grammar and are developed uniformly from pidgins in a single generation. These similarities are apparent even when creoles do not have any common language origins. In addition, creoles are similar, despite being developed in isolation from each other. Syntactic similarities include subject–verb–object word order. Even when creoles are derived from languages with a different word order they often develop the SVO word order. Creoles tend to have similar usage patterns for definite and indefinite articles, and similar movement rules for phrase structures even when the parent languages do not.
Subsections (0):
, Section: Evolutionary timeline (1):

Subsections (7):
Section: Primate communication (2):
Field primatologists can give useful insights into great ape communication in the wild. One notable finding is that nonhuman primates, including the other great apes, produce calls that are graded, as opposed to categorically differentiated, with listeners striving to evaluate subtle gradations in signallers' emotional and bodily states. Nonhuman apes seemingly find it extremely difficult to produce vocalisations in the absence of the corresponding emotional states. In captivity, nonhuman apes have been taught rudimentary forms of sign language or have been persuaded to use lexigrams—symbols that do not graphically resemble the corresponding words—on computer keyboards. Some nonhuman apes, such as Kanzi, have been able to learn and use hundreds of lexigrams.
The Broca's and Wernicke's areas in the primate brain are responsible for controlling the muscles of the face, tongue, mouth, and larynx, as well as recognizing sounds. Primates are known to make ""vocal calls"", and these calls are generated by circuits in the brainstem and limbic system.
In the wild, the communication of vervet monkeys has been the most extensively studied. They are known to make up to ten different vocalizations. Many of these are used to warn other members of the group about approaching predators. They include a ""leopard call"", a ""snake call"", and an ""eagle call"". Each call triggers a different defensive strategy in the monkeys who hear the call and scientists were able to elicit predictable responses from the monkeys using loudspeakers and prerecorded sounds. Other vocalisations may be used for identification. If an infant monkey calls, its mother turns toward it, but other vervet mothers turn instead toward that infant's mother to see what she will do.
Similarly, researchers have demonstrated that chimpanzees (in captivity) use different ""words"" in reference to different foods. They recorded vocalisations that chimps made in reference, for example, to grapes, and then other chimps pointed at pictures of grapes when they heard the recorded sound.
Subsections (0):

Section: Ardipithecus ramidus (2):
A study published in HOMO: Journal of Comparative Human Biology in 2017 claims that Ardipithecus ramidus, a hominin dated at approximately 4.5Ma, shows the first evidence of an anatomical shift in the hominin lineage suggestive of increased vocal capability. This study compared the skull of A. ramidus with 29 chimpanzee skulls of different ages and found that in numerous features A. ramidus clustered with the infant and juvenile measures as opposed to the adult measures. Such affinity with the shape dimensions of infant and juvenile chimpanzee skull architecture, it was argued, may have resulted in greater vocal capability. This assertion was based on the notion that the chimpanzee vocal tract ratios that prevent speech are a result of growth factors associated with puberty—growth factors absent in A. ramidus ontogeny. A. ramidus was also found to have a degree of cervical lordosis more conducive to vocal modulation when compared with chimpanzees as well as cranial base architecture suggestive of increased vocal capability.
What was significant in this study, according to the authors, was the observation that the changes in skull architecture that correlate with reduced aggression are the same changes necessary for the evolution of early hominin vocal ability. In integrating data on anatomical correlates of primate mating and social systems with studies of skull and vocal tract architecture that facilitate speech production, the authors argue that paleoanthropologists prior to their study have failed to understand the important relationship between early hominin social evolution and the evolution of our species' capacities for language. 
While the skull of A. ramidus, according to the authors, lacks the anatomical impediments to speech evident in chimpanzees, it is unclear what the vocal capabilities of this early hominin were. While they suggest A. ramidus—based on similar vocal tract ratios—may have had vocal capabilities equivalent to a modern human infant or very young child, they concede this is a debatable and speculative hypothesis. However, they do claim that changes in skull architecture through processes of social selection were a necessary prerequisite for language evolution. As they write:

We propose that as a result of paedomorphic morphogenesis of the cranial base and craniofacial morphology Ar. ramidus would have not been limited in terms of the mechanical components of speech production as chimpanzees and bonobos are. It is possible that Ar. ramidus had vocal capability approximating that of chimpanzees and bonobos, with its idiosyncratic skull morphology not resulting in any significant advances in speech capability. In this sense the anatomical features analysed in this essay would have been exapted in later more voluble species of hominin. However, given the selective advantages of pro-social vocal synchrony, we suggest the species would have developed significantly more complex vocal abilities than chimpanzees and bonobos.
Subsections (0):

Section: Early Homo (2):
Anatomically, some scholars believe that features of bipedalism developed in the australopithecines around 3.5 million years ago. Around this time, these structural developments within the skull led to a more prominently L-shaped vocal tract. In order to generate the sounds modern Homo sapiens are capable of making, such as vowels, it is vital that Early Homo populations must have a specifically shaped voice track and a lower sitting larynx. Opposing research previously suggested that Neanderthals were physically incapable of creating the full range of vocals seen in modern humans due to the differences in larynx placement. Establishing distinct larynx positions through fossil remains of Homo sapiens and Neanderthals would support this theory; however, modern research has revealed that the hyoid bone was indistinguishable in the two populations. Though research has shown a lower sitting larynx is important to producing speech, another theory states it may not be as important as once thought. Cataldo, Migliano, and Vinicius report speech alone appears inadequate for transmiting stone tool-making knowledge, and suggest that speech may have emerged due to an increase in complex social interactions.
Subsections (0):

Section: Archaic Homo sapiens (2):
Steven Mithen proposed the term Hmmmmm for the pre-linguistic system of communication posited to have been used by archaic Homo, beginning with Homo ergaster and reaching the highest sophistication in the Middle Pleistocene with Homo heidelbergensis and Homo neanderthalensis. Hmmmmm is an acronym for holistic (non-compositional), manipulative (utterances are commands or suggestions, not descriptive statements), multi-modal (acoustic as well as gestural and facial), musical, and mimetic.
Subsections (3):
Section: Homo erectus (3):
Evidence for Homo erectus potentially using language comes in the form of Acheulean tool usage. The use of abstract thought in the formation of Acheulean hand axes coincides with the symbol creation necessary for simple language. Recent language theories present recursion as the unique facet of human language and theory of mind. However, breaking down language into its symbolic parts: separating meaning from the requirements of grammar, it becomes possible to see that language does not depend on either recursion or grammar. This can be evidenced by the Pirahã language users in Brazil that have no myth or creation stories, no numbers and no colors within their language. This is to highlight that even though grammar may have been unavailable, use of foresight, planning and symbolic thought can be evidence of language as early as one million years ago with Homo erectus.
Subsections (0):

Section: Homo heidelbergensis (3):
Homo heidelbergensis was a close relative (most probably a migratory descendant) of Homo ergaster. Some researchers believe this species to be the first hominin to make controlled vocalisations, possibly mimicking animal vocalisations, and that as Homo heidelbergensis developed more sophisticated culture, proceeded from this point and possibly developed an early form of symbolic language.
Subsections (0):

Section: Homo neanderthalensis (3):
The discovery in 1989 of the (Neanderthal) Kebara 2 hyoid bone suggests that Neanderthals may have been anatomically capable of producing sounds similar to modern humans. The hypoglossal nerve, which passes through the hypoglossal canal, controls the movements of the tongue, which may have enabled voicing for size exaggeration (see size exaggeration hypothesis below) or may reflect speech abilities.
However, although Neanderthals may have been anatomically able to speak, Richard G. Klein in 2004 doubted that they possessed a fully modern language. He largely bases his doubts on the fossil record of archaic humans and their stone tool kit. Bart de Boer in 2017 acknowledges this ambiguity of a universally accepted Neanderthal vocal tract; however, he notes the similarities in the thoracic vertebral canal, potential air sacs, and hyoid bones between modern humans and Neanderthals to suggest the presence of complex speech. For two million years following the emergence of Homo habilis, the stone tool technology of hominins changed very little. Klein, who has worked extensively on ancient stone tools, describes the crude stone tool kit of archaic humans as impossible to break down into categories based on their function, and reports that Neanderthals seem to have had little concern for the final aesthetic form of their tools. Klein argues that the Neanderthal brain may have not reached the level of complexity required for modern speech, even if the physical apparatus for speech production was well-developed. The issue of the Neanderthal's level of cultural and technological sophistication remains a controversial one.
Based on computer simulations used to evaluate that evolution of language that resulted in showing three stages in the evolution of syntax, Neanderthals are thought to have been in stage 2, showing they had something more evolved than proto-language but not quite as complex as the language of modern humans.
Some researchers, applying auditory bioengineering models to computerised tomography scans of Neanderthal skulls, have asserted that Neanderthals had auditory capacity very similar to that of anatomically modern humans. These researchers claim that this finding implies that ""Neanderthals evolved the auditory capacities to support a vocal communication system as efficient as modern human speech.""
Subsections (0):

Section: Homo sapiens (2):
Anatomically modern humans begin to appear in the fossil record in Ethiopia some 200,000 years ago. Although there is still much debate as to whether behavioural modernity emerged in Africa at around the same time, a growing number of archaeologists nowadays invoke the southern African Middle Stone Age use of red ochre pigments—for example at Blombos Cave—as evidence that modern anatomy and behaviour co-evolved. These archaeologists argue strongly that if modern humans at this early stage were using red ochre pigments for ritual and symbolic purposes, they probably had symbolic language as well.
According to the recent African origins hypothesis, from around 60,000 – 50,000 years ago a group of humans left Africa and began migrating to occupy the rest of the world, carrying language and symbolic culture with them.
Subsections (0):

Section: The descended larynx (2):
The larynx or voice box is an organ in the neck housing the vocal folds, which are responsible for phonation. In humans, the larynx is descended. The human species is not unique in this respect: goats, dogs, pigs and tamarins lower the larynx temporarily, to emit loud calls. Several deer species have a permanently lowered larynx, which may be lowered still further by males during their roaring displays. Lions, jaguars, cheetahs and domestic cats also do this. However, laryngeal descent in nonhumans (according to Philip Lieberman) is not accompanied by descent of the hyoid; hence the tongue remains horizontal in the oral cavity, preventing it from acting as a pharyngeal articulator.

Despite all this, scholars remain divided as to how ""special"" the human vocal tract really is. It has been shown that the larynx does descend to some extent during development in chimpanzees, followed by hyoidal descent. As against this, Philip Lieberman points out that only humans have evolved permanent and substantial laryngeal descent in association with hyoidal descent, resulting in a curved tongue and two-tube vocal tract with 1:1 proportions. He argues that Neanderthals and early anatomically modern humans could not have possessed supralaryngeal vocal tracts capable of producing ""fully human speech"". Uniquely in the human case, simple contact between the epiglottis and velum is no longer possible, disrupting the normal mammalian separation of the respiratory and digestive tracts during swallowing. Since this entails substantial costs—increasing the risk of choking while swallowing food—we are forced to ask what benefits might have outweighed those costs. The obvious benefit—so it is claimed—must have been speech. But this idea has been vigorously contested. One objection is that humans are in fact not seriously at risk of choking on food: medical statistics indicate that accidents of this kind are extremely rare. Another objection is that in the view of most scholars, speech as it is known emerged relatively late in human evolution, roughly contemporaneously with the emergence of Homo sapiens. A development as complex as the reconfiguration of the human vocal tract would have required much more time, implying an early date of origin. This discrepancy in timescales undermines the idea that human vocal flexibility was initially driven by selection pressures for speech, thus not excluding that it was selected for e.g. improved singing ability.
Subsections (1):
Section: The size exaggeration hypothesis (3):
To lower the larynx is to increase the length of the vocal tract, in turn lowering formant frequencies so that the voice sounds ""deeper""—giving an impression of greater size. John Ohala argues that the function of the lowered larynx in humans, especially males, is probably to enhance threat displays rather than speech itself. Ohala points out that if the lowered larynx were an adaptation for speech, adult human males would be expected to be better adapted in this respect than adult females, whose larynx is considerably less low. However, females outperform males in verbal tests, falsifying this whole line of reasoning.
W. Tecumseh Fitch likewise argues that this was the original selective advantage of laryngeal lowering in the human species. Although (according to Fitch) the initial lowering of the larynx in humans had nothing to do with speech, the increased range of possible formant patterns was subsequently co-opted for speech. Size exaggeration remains the sole function of the extreme laryngeal descent observed in male deer. Consistent with the size exaggeration hypothesis, a second descent of the larynx occurs at puberty in humans, although only in males. In response to the objection that the larynx is descended in human females, Fitch suggests that mothers vocalizing to protect their infants would also have benefited from this ability.
Subsections (0):

Section: Phonemic diversity (2):
In 2011, Quentin Atkinson published a survey of phonemes from 500 different languages as well as language families and compared their phonemic diversity by region, number of speakers and distance from Africa. The survey revealed that African languages had the largest number of phonemes, and Oceania and South America had the smallest number. After allowing for the number of speakers, the phonemic diversity was compared to over 2000 possible origin locations. Atkinson's ""best fit"" model is that language originated in western, central, or southern Africa between 80,000 and 160,000 years ago. This predates the hypothesized southern coastal peopling of Arabia, India, southeast Asia, and Australia. It would also mean that the origin of language occurred at the same time as the emergence of symbolic culture.
Numerous linguists have criticized Atkinson's paper as misrepresenting both the phonemic data and processes of linguistic change, as language complexity does not necessarily correspond to age, and of failing to take into account the borrowing of phonemes from neighbouring languages, as some Bantu languages have done with click consonants. Recreations of his method gave possible origins of language in the Caucasus and Turkmenistan, in addition to southern and eastern Africa.
Subsections (0):
, Section: History (1):

Subsections (3):
Section: In religion and mythology (2):
The search for the origin of language has a long history in mythology. Most mythologies do not credit humans with the invention of language but speak of a divine language predating human language. Mystical languages used to communicate with animals or spirits, such as the language of the birds, are also common, and were of particular interest during the Renaissance.
Vāc is the Hindu goddess of speech, or ""speech personified"". As Brahman's ""sacred utterance"", she has a cosmological role as the ""Mother of the Vedas"". The Aztecs' story maintains that only a man, Coxcox, and a woman, Xochiquetzal, survived a flood, having floated on a piece of bark. They found themselves on land and had many children who were at first born unable to speak, but subsequently, upon the arrival of a dove, were endowed with language, although each one was given a different speech such that they could not understand one another.
In the Old Testament, the Book of Genesis (chapter 11) says that God prevented the Tower of Babel from being completed through a miracle that made its construction workers start speaking different languages. After this, they migrated to other regions, grouped together according to which of the newly created languages they spoke, explaining the origins of languages and nations outside of the Fertile Crescent.
Subsections (0):

Section: Historical experiments (2):
History contains a number of anecdotes about people who attempted to discover the origin of language by experiment. The first such tale was told by Herodotus (Histories 2.2). He relates that Pharaoh Psammetichus (probably Psammetichus I, 7th century BC) had two children raised by a shepherd, with the instructions that no one should speak to them, but that the shepherd should feed and care for them while listening to determine their first words. When one of the children cried ""bekos"" with outstretched arms the shepherd concluded that the word was Phrygian, because that was the sound of the Phrygian word for ""bread"". From this, Psammetichus concluded that the first language was Phrygian. King James V of Scotland is said to have tried a similar experiment; his children were supposed to have spoken Hebrew.
Both the medieval monarch Frederick II and Akbar are said to have tried similar experiments; the children involved in these experiments did not speak. The current situation of deaf people also points into this direction.
Subsections (0):

Section: History of research (2):
Modern linguistics did not begin until the late 18th century, and the Romantic or animist theses of Johann Gottfried Herder and Johann Christoph Adelung remained influential well into the 19th century. The question of language origin seemed inaccessible to methodical approaches, and in 1866 the Linguistic Society of Paris famously banned all discussion of the origin of language, deeming it to be an unanswerable problem. An increasingly systematic approach to historical linguistics developed in the course of the 19th century, reaching its culmination in the Neogrammarian school of Karl Brugmann and others.
However, scholarly interest in the question of the origin of language has only gradually been rekindled from the 1950s on (and then controversially) with ideas such as universal grammar, mass comparison and glottochronology.
The ""origin of language"" as a subject in its own right emerged from studies in neurolinguistics, psycholinguistics and human evolution. The Linguistic Bibliography introduced ""Origin of language"" as a separate heading in 1988, as a sub-topic of psycholinguistics. Dedicated research institutes of evolutionary linguistics are a recent phenomenon, emerging only in the 1990s.
Subsections (0):
, Section: See also (1):

Subsections (0):
, Section: References (1):

Subsections (0):
, Section: Further reading (1):

Subsections (0):
, Section: External links (1):

Origin of Language – Givens, David B.
Behavioral and Biological Origins of Modern Humans – Klein, Richard G.
The Origin of Language – Vajda, Edward
First Language Acquisition – Vajda, Edward
Speaking in Tongues: The History of Language Archived 21 February 2014 at the Wayback Machine
Decoding Chomsky: Science and revolutionary politics – Chris Knight
Subsections (0):
]"
12,"Category:Origins (id: 29739395, ns: 14)",0,Refractory (planetary science),"In planetary science, any material that has a relatively high equilibrium condensation temperature is called refractory. The opposite of refractory is volatile.
The refractory group includes elements and compounds like metals and silicates (commonly termed rocks) which make up the bulk of the mass of the terrestrial planets and asteroids in the inner belt. A fraction of the mass of other asteroids, giant planets, their moons and trans-Neptunian objects is also made of refractory materials.","[Section: Classification (1):
The elements can be divided into several categories:

The condensation temperatures are the temperatures at which 50% of the element will be in the form of a solid (rock) under a pressure of 10−4 bar. However, slightly different groups and temperature ranges are used sometimes. Refractory material are also often divided into refractory lithophile elements and refractory siderophile elements.


== References ==
Subsections (0):
]"
13,"Category:Origins (id: 29739395, ns: 14)",0,Origins of society,"The origins of society — the evolutionary emergence of distinctively human social organization — is an important topic within evolutionary biology, anthropology, prehistory and palaeolithic archaeology. While little is known for certain, debates since Hobbes and Rousseau have returned again and again to the philosophical, moral and evolutionary questions posed.","[Section: Social origins in nature (1):

Subsections (2):
Section: Origin of social groups (2):

Subsections (10):
Section: Thomas Hobbes (3):
Arguably the most influential theory of human social origins is that of Thomas Hobbes, who in his Leviathan argued that without strong government, society would collapse into Bellum omnium contra omnes — ""the war of all against all"":

In such condition, there is no place for industry; because the fruit thereof is uncertain: and consequently no culture of the earth; no navigation, nor use of the commodities that may be imported by sea; no commodious building; no instruments of moving, and removing, such things as require much force; no knowledge of the face of the earth; no account of time; no arts; no letters; no society; and which is worst of all, continual fear, and danger of violent death; and the life of man, solitary, poor, nasty, brutish, and short. Hobbes' innovation was to attribute the establishment of society to a founding 'social contract', in which the Crown's subjects surrender some part of their freedom in return for security.
If Hobbes' idea is accepted, it follows that society could not have emerged prior to the state. This school of thought has remained influential to this day. Prominent in this respect is British archaeologist Colin Renfrew (Baron Renfrew of Kaimsthorn), who points out that the state did not emerge until long after the evolution of Homo sapiens. The earliest representatives of our species, according to Renfrew, may well have been anatomically modern, but they were not yet cognitively or behaviourally modern. For example, they lacked political leadership, large-scale cooperation, food production, organised religion, law or symbolic artefacts. Humans were simply hunter-gatherers, who — much like extant apes — ate whatever food they could find in the vicinity. Renfrew controversially suggests that hunter-gatherers to this day think and socialise along lines not radically different from those of their nonhuman primate counterparts. In particular, he says that they do not ""ascribe symbolic meaning to material objects"" and for that reason ""lack fully developed 'mind.'""
However, hunter-gatherer ethnographers emphasise that extant foraging peoples certainly do have social institutions — notably institutionalised rights and duties codified in formal systems of kinship. Elaborate rituals such as initiation ceremonies serve to cement contracts and commitments, quite independently of the state. Other scholars would add that insofar as we can speak of ""human revolutions"" — ""major transitions"" in human evolution — the first was not the Neolithic Revolution but the rise of symbolic culture that occurred toward the end of the Middle Stone Age.
Arguing the exact opposite of Hobbes's position, anarchist anthropologist Pierre Clastres views the state and society as mutually incompatible: genuine society is always struggling to survive against the state.
Subsections (0):

Section: Jean-Jacques Rousseau (3):
Like Hobbes, Jean-Jacques Rousseau argued that society was born in a social contract. In Rousseau's case, however, sovereignty is vested in the entire populace, who enter into the contract directly with one another. ""The problem"", he explained, ""is to find a form of association which will defend and protect with the whole common force the person and goods of each associate, and in which each, while uniting himself with all, may still obey himself alone, and remain as free as before."" This is the fundamental problem of which the Social Contract provides the solution. The contract's clauses, Rousseau continued, may be reduced to one — ""the total alienation of each associate, together with all his rights, to the whole community. Each man, in giving himself to all, gives himself to nobody; and as there is no associate over whom he does not acquire the same right as he yields others over himself, he gains an equivalent for everything he loses, and an increase of force for the preservation of what he has"". In other words: ""Each of us puts his person and all his power in common under the supreme direction of the general will, and, in our corporate capacity, we receive each member as an indivisible part of the whole."" At once, in place of the individual personality of each contracting party, this act of association creates a moral and collective body, composed of as many members as the assembly contains votes, and receiving from this act its unity, its common identity, its life and its will. By this means, each member of the community acquires not only the capacities of the whole but also, for the first time, rational mentality:

The passage from the state of nature to the civil state produces a very remarkable change in man, by substituting justice for instinct in his conduct, and giving his actions the morality they had formerly lacked. Then only, when the voice of duty takes the place of physical impulses and right of appetite, does man, who so far had considered only himself, find that he is forced to act on different principles, and to consult his reason before listening to his inclinations.
Subsections (0):

Section: Sir Henry Sumner Maine (3):
In his influential book, Ancient Law (1861), Maine argued that in early times, the basic unit of human social organisation was the patriarchal family:

The effect of the evidence derived from comparative jurisprudence is to establish the view of the primeval condition of the human race which is known as the Patriarchal Theory.
Hostile to French revolutionary and other radical social ideas, Maine's motives were partly political. He sought to undermine the legacy of Rousseau and other advocates of man's natural rights by asserting that originally, no one had any rights at all – ‘every man, living during the greater part of his life under the patriarchal despotism, was practically controlled in all his actions by a regimen not of law but of caprice’. Not only were the patriarch's children subject to what Maine calls his ‘despotism’: his wife and his slaves were equally affected. The very notion of kinship, according to Maine, was simply a way of categorizing those who were forcibly subjected to the despot's arbitrary rule. Maine later added a Darwinian strand to this argument. In his The Descent of Man, Darwin had cited reports that a wild-living male gorilla would monopolise for itself as large a harem of females as it could violently defend. Maine endorsed Darwin's speculation that ‘primeval man’ probably 'lived in small communities, each with as many wives as he could support and obtain, whom he would have jealously guarded against all other men’. Under pressure to spell out exactly what he meant by the term 'patriarchy', Maine clarified that ‘sexual jealousy, indulged through power, might serve as a definition of the Patriarchal Family’.
Subsections (0):

Section: Lewis Henry Morgan (3):
In his influential book, Ancient Society (1877), its title echoing Maine's Ancient Law, Lewis Henry Morgan proposed a very different theory. Morgan insisted that throughout the earlier periods of human history, neither the state nor the family existed.

 It may be here premised that all forms of government are reducible to two general plans, using the word plan in its scientific sense. In their bases the two are fundamentally distinct. The first, in the order of time, is founded upon persons, and upon relations purely personal, and may be distinguished as a society (societas). The gens is the unit of this organization; giving as the successive stages of integration, in the archaic period, the gens, the phratry, the tribe, and the confederacy of tribes, which constituted a people or nation (populus). At a later period a coalescence of tribes in the same area into a nation took the place of a confederacy of tribes occupying independent areas. Such, through prolonged ages, after the gens appeared, was the substantially universal organization of ancient society; and it remained among the Greeks and Romans after civilization supervened. The second is founded upon territory and upon property, and may be distinguished as a state (civitas). In place of both family and state, according to Morgan, was the gens — nowadays termed the 'clan' — based initially on matrilocal residence and matrilineal descent. This aspect of Morgan's theory, later endorsed by Karl Marx and Frederick Engels, is nowadays widely considered discredited (but for a critical survey of the current consensus, see Knight 2008, 'Early Human Kinship Was Matrilineal').
Subsections (0):

Section: Friedrich Engels (3):
Friedrich Engels built on Morgan's ideas in his 1884 essay, The Origin of the Family, Private Property and the State in the light of the researches of Lewis Henry Morgan. His primary interest was the position of women in early society, and — in particular — Morgan's insistence that the matrilineal clan preceded the family as society's fundamental unit. 'The mother-right gens', wrote Engels in his survey of contemporary historical materialist scholarship, 'has become the pivot around which the entire science turns...' Engels argued that the matrilineal clan represented a principle of self-organization so vibrant and effective that it allowed no room for patriarchal dominance or the territorial state.The first class antagonism which appears in human history coincides with the development of the antagonism between man and woman in monogamian marriage, and the first class oppression with that of the female sex by the male.
Subsections (0):

Section: Emile Durkheim (3):
Emile Durkheim considered that in order to exist, any human social system must counteract the natural tendency for the sexes to promiscuously conjoin. He argued that social order presupposes sexual morality, which is expressed in prohibitions against sex with certain people or during certain periods — in traditional societies particularly during menstruation.

One first fact is certain: that is, that the entire system of prohibitions must strictly conform to the ideas that primitive man had about menstruation and about menstrual blood. For all these taboos start only with the onset of puberty: and it is only when the first signs of blood appear that they reach their maximum rigour.
The incest taboo, wrote Durkheim in 1898, is no more than a particular example of something more basic and universal - the ritualistic setting apart of 'the sacred' from 'the profane'. This begins as the segregation of the sexes, each of which - at least on important occasions - is 'sacred' or 'set apart' from the other. 'The two sexes', as Durkheim explains, 'must avoid each other with the same care as the profane flees from the sacred and the sacred from the profane.' Women as sisters act out the role of 'sacred' beings invested 'with an isolating power of some sort, a power which holds the masculine population at a distance.' Their menstrual blood in particular sets them in a category apart, exercising a 'type of repulsing action which keeps the other sex far from them'. In this way, the earliest ritual structure emerges — establishing morally regulated 'society' for the first time.
Subsections (0):

Section: Sigmund Freud (3):
Charles Darwin pictured early human society as resembling that of apes, with one or more dominant males jealously guarding a harem of females. In his myth of the 'Primal Horde', Sigmund Freud later took all this as his starting point but then postulated an insurrection mounted by the tyrant's own sons:All that we find there is a violent and jealous father who keeps all the females for himself and drives away his sons as they grow up…. One day the brothers who had been driven out came together, killed and devoured their father and so made an end of the patriarchal horde. Following this, the band of brothers were about to take sexual possession of their mothers and sisters when suddenly they were overcome with remorse. In their contradictory emotional state, their dead father now became stronger than the living one had been. In memory of him, the brothers revoked their deed by forbidding the killing and eating of the 'totem' (as their father had now become) and renouncing their claim to the women who had just been set free. In this way, the two fundamental taboos of primitive society – not to eat the totem and not to marry one's sisters – were established for the first time.
Subsections (0):

Section: Marshall Sahlins (3):
A related but less dramatic version of Freud's 'sexual revolution' idea was proposed in 1960 by American social anthropologist Marshall Sahlins. Somehow, he writes, the world of primate brute competition and sexual dominance was turned upside-down: The decisive battle between early culture and human nature must have been waged on the field of primate sexuality….  Among subhuman primates sex had organized society; the customs of hunters and gatherers testify eloquently that now society was to organize sex…. In selective adaptation to the perils of the Stone Age, human society overcame or subordinated such primate propensities as selfishness, indiscriminate sexuality, dominance and brute competition. It substituted kinship and co-operation for conflict, placed solidarity over sex, morality over might. In its earliest days it accomplished the greatest reform in history, the overthrow of human primate nature, and thereby secured the evolutionary future of the species.
Subsections (0):

Section: Christopher Boehm (3):
Once a prehistoric hunting band institutionalized a successful and decisive rebellion, and did away with the alpha-male role permanently... it is easy to see how this institution would have spread.
If we accept Rousseau's line of reasoning, no single dominant individual is needed to embody society, to guarantee security, or to enforce social contracts. The people themselves can do these things, combining to enforce the general will. A modern origins theory along these lines is that of evolutionary anthropologist Christopher Boehm. Boehm argues that ape social organisation tends to be despotic, typically with one or more dominant males monopolising access to the locally available females. But wherever there is dominance, we can also expect resistance. In the human case, resistance to being personally dominated intensified as humans used their social intelligence to form coalitions. Eventually, a point was reached when the costs of attempting to impose dominance became so high that the strategy was no longer evolutionarily stable, whereupon social life tipped over into 'reverse dominance' — defined as a situation in which only the entire community, on guard against primate-style individual dominance, is permitted to use force to suppress deviant behaviour.
Subsections (0):

Section: Ernest Gellner (3):
Human beings, writes social anthropologist Ernest Gellner, are not genetically programmed to be members of this or that social order. You can take a human infant and place it into any kind of social order and it will function acceptably. What makes human society so distinctive is the fabulous range of quite different forms it takes across the world. Yet in any given society, the range of permitted behaviours is quite narrowly constrained. This is not owing to the existence of any externally imposed system of rewards and punishments. The constraints come from within — from certain compulsive moral concepts which members of the social order have internalised. The society installs these concepts in each individual's psyche in the manner first identified by Emile Durkheim, namely, by means of collective rituals such as initiation rites. Therefore, the problem of the origins of society boils down to the problem of the origins of collective ritual.

How is a  society established, and a series of societies diversified, whilst each of them is restrained from chaotically exploiting that wide diversity of possible human behaviour? A theory is available concerning how this may be done and it is one of the basic theories of social anthropology. The way in which you restrain people from doing a wide variety of things, not compatible with the social order of which they are members, is that you subject them to ritual. The process is simple: you make them dance around a totem pole until they are wild with excitement, and become jellies in the hysteria of collective frenzy; you enhance their emotional state by any device, by all the locally available audio-visual aids, drugs, music and so on; and once they are really high, you stamp upon their minds the type of concept or notion to which they subsequently become enslaved.
Subsections (0):

Section: Gender and origins (2):
Feminist scholars — among them palaeoanthropologists Leslie Aiello and Camilla Power — take similar arguments a step further, arguing that any reform or revolution which overthrew male dominance must have been led by women. Evolving human females, Power and Aiello suggest, actively separated themselves from males on a periodic basis, using their own blood (and/or pigments such as red ochre) to mark themselves as fertile and defiant: The sexual division of labor entails differentiation of roles in food procurement, with logistic hunting of large game by males, co-operation and exchange of products. Our hypothesis is that symbolism arose in this context. To minimize energetic costs of travel, coalitions of women began to invest in home bases. To secure this strategy, women would have to use their attractive, collective signal of impending fertility in a wholly new way: by signalling refusal of sexual access except to males who returned ""home"" with provisions. Menstruation — real or artificial — while biologically the wrong time for fertile sex, is psychologically the right moment for focusing men's minds on imminent hunting, since it offers the prospect of fertile sex in the near future. In similar vein, anthropologist Chris Knight argues that Boehm's idea of a 'coalition of everyone' is hard to envisage, unless — along the lines of a modern industrial picket line — it was formed to co-ordinate 'sex-strike' action against badly behaving males: ....male dominance had to be overthrown because the unending prioritising of male short-term sexual interests could lead only to the permanence and institutionalisation of behavioural conflict between the sexes, between the generations and also between rival males. If the symbolic, cultural domain was to emerge, what was needed was a political collectivity — an alliance — capable of transcending such conflicts. ... Only the consistent defence and self-defence of mothers with their offspring could produce a collectivity embodying interests of a sufficiently broad, universalistic kind. In virtually all hunter-gatherer ethnographies, according to Knight, a persistent theme is that 'women like meat', and that they determinedly use their collective bargaining power to motivate men to hunt for them and bring home their kills — on pain of exclusion from sex. Arguments about women's crucial role in domesticating males — motivating them to cooperate — have also been advanced by anthropologists Kristen Hawkes, Sarah Hrdy and Bruce Knauft among others. Meanwhile, other evolutionary scientists continue to envisage uninterrupted male dominance, continuity with primate social systems and the emergence of society on a gradualist basis without revolutionary leaps.
Subsections (0):
, Section: Sociobiological theories (1):

Subsections (2):
Section: Robert Trivers (2):
I consider Trivers one of the great thinkers in the history of Western thought. It would not be too much of an exaggeration to say that he has provided a scientific explanation for the human condition: the intricately complicated and endlessly fascinating relationships that bind us to one another.
In his 1985 book, Social Evolution, Robert Trivers outlines the theoretical framework used today by most evolutionary biologists to understand how and why societies are established. Trivers sets out from the fundamental fact that genes survive beyond the death of the bodies they inhabit, because copies of the same gene may be replicated in multiple different bodies. From this, it follows that a creature should behave altruistically to the extent that those benefiting carry the same genes — 'inclusive fitness', as this source of cooperation in nature is termed. Where animals are unrelated, cooperation should be limited to 'reciprocal altruism' or 'tit-for-tat'.
Where previously, biologists took parent-offspring cooperation for granted, Trivers predicted on theoretical grounds both cooperation and conflict — as when a mother needs to wean an existing baby (even against its will) in order to make way for another. Previously, biologists had interpreted male infanticidal behaviour as aberrant and inexplicable or, alternatively, as a necessary strategy for culling excess population. Trivers was able to show that such behaviour was a logical strategy by males to enhance their own reproductive success at the expense of conspecifics including rival males. Ape or monkey females whose babies are threatened have directly opposed interests, often forming coalitions to defend themselves and their offspring against infanticidal males.

Human society, according to Trivers, is unusual in that it involves the male of the species investing parental care in his own offspring — a rare pattern for a primate. Where such cooperation occurs, it's not enough to take it for granted: in Trivers' view we need to explain it using an overarching theoretical framework applicable to humans and nonhumans alike.Everybody has a social life. All living creatures reproduce and reproduction is a social event, since at its bare minimum it involves the genetic and material construction of one individual by another. In turn, differences between individuals in the number of their surviving offspring (natural selection) is the driving force behind organic evolution. Life is intrinsically social and it evolves through a process of natural selection which is itself social. For these reasons social evolution refers not only to the evolution of social relationships between individuals but also to deeper themes of biological organization stretching from gene to community.
Subsections (0):

Section: Robin Dunbar (2):
Robin Dunbar originally studied gelada baboons in the wild in Ethiopia, and has done much to synthesise modern primatological knowledge with Darwinian theory into a comprehensive overall picture. The components of primate social systems 'are essentially alliances of a political nature aimed at enabling the animals concerned to achieve more effective solutions to particular problems of survival and reproduction'. Primate societies are in essence 'multi-layered sets of coalitions'. Although physical fights are ultimately decisive, the social mobilisation of allies usually decides matters and requires skills that go beyond mere fighting ability. The manipulation and use of coalitions demands sophisticated social — more precisely political — intelligence.
Usually but not always, males exercise dominance over females. Even where male despotism prevails, females typically gang up with one another to pursue agendas of their own. When a male gelada baboon attacks a previously dominant rival so as to take over his harem, the females concerned may insist on their own say in the outcome. At various stages during the fighting, the females may 'vote' among themselves on whether to accept the provisional outcome. Rejection is signalled by refusing to groom the challenger; acceptance is signalled by going up to him and grooming him. According to Dunbar, the ultimate outcome of an inter-male 'sexual fight' always depends on the female 'vote'.

Dunbar points out that in a primate social system, lower-ranking females will typically suffer the most intense harassment. Consequently, they will be the first to form coalitions in self-defence. But maintaining commitment from coalition allies involves much time-consuming manual grooming, putting pressure on time-budgets. In the case of evolving humans, who were living in increasingly large groups, the costs would soon have outweighed the benefits — unless some more efficient way of maintaining relationships could be found. Dunbar argues that 'vocal grooming' — using the voice to signal commitment — was the time-saving solution adopted, and that this led eventually to speech. Dunbar goes on to suggest (citing evolutionary anthropologist Chris Knight) that distinctively human society may have been evolved under pressure from female ritual and 'gossiping' coalitions established to dissuade males from fighting one another and instead cooperate in hunting for the benefit of the whole camp:  If females formed the core of these early groups, and language evolved to bond these groups, it naturally follows that the early human females were the first to speak. This reinforces the suggestion that language was first used to create a sense of emotional solidarity between allies. Chris Knight has argued a passionate case for the idea that language first evolved to allow the females in these early groups to band together to force males to invest in them and their offspring, principally by hunting for meat. This would be consistent with the fact that, among modern humans, women are generally better at verbal skills than men, as well as being more skilful in the social domain.  Dunbar stresses that this is currently a minority theory among specialists in human origins — most still support the 'bison-down-at-the-lake' theory attributing early language and cooperation to the imperatives of men's activities such as hunting. Despite this, he argues that 'female bonding may have been a more powerful force in human evolution than is sometimes supposed'. Although still controversial, the idea that female coalitions may have played a decisive role has subsequently received strong support from a number of anthropologists including Sarah Hrdy, Camilla Power, Ian Watts. and Jerome Lewis. It is also consistent with recent studies by population geneticists (see Verdu et al. 2013  for Central African Pygmies; Schlebusch 2010 for Khoisan) showing a deep-time tendency to matrilocality among African hunter-gatherers.
Subsections (0):
, Section: See also (1):
Behavioral modernity
Generative anthropology
Origin of speech
Origin of language
Sociocultural evolution
Subsections (0):
, Section: References (1):

Subsections (0):
, Section: Further reading (1):
Dunbar, R. I. M., C. Knight and C. Power (eds) 1999. The Evolution of Culture. Edinburgh: Edinburgh University Press.
Dunbar, R., C. Gamble and J. Gowlett, 2010. The social brain and the distributed mind. Proceedings of the British Academy, 158: 3–15.
Gellner, E. 1988. Origins of Society. In A. C. Fabian (ed.), Origins. The Darwin College Lectures. Cambridge: Cambridge University Press.
Knight, C. Early Human Kinship was Matriineal. In N. J. Allen, H. Callan, R. Dunbar and W. James (eds.), Early Human Kinship. Oxford: Blackwell, pp. 61–82.
Lévi Strauss, C. 1969. The Elementary Structures of Kinship. London: Eyre and Spottiswoode.
Maynard Smith, J. and E. Szathmáry 1995. The Major Transitions in Evolution. Oxford: W. H. Freeman.
Steele, J. and S. Shennan (eds), 1996. The Archaeology of Human Ancestry. Power, Sex and Tradition. London: Routledge, pp. 47–66.
Subsections (0):
]"
14,"Category:Origins (id: 29739395, ns: 14)",0,Timeline of maritime migration and exploration,"This timeline is an incomplete list of significant events of human migration and exploration by sea. This timeline does not include migration and exploration over land, including migration across land that has subsequently submerged beneath the sea, such as the initial settlement of Great Britain and Ireland.","[Section: Maritime migration and exploration (1):

Subsections (0):
, Section: See also (1):
Age of Discovery
Ancient maritime history
Chinese exploration
Chronology of European exploration of Asia
Colonization
Columbian exchange
Early human migrations
European exploration of Africa
History of navigation
History of slavery
Human migration
Indian maritime history
Major explorations after the Age of Discovery
Maritime history
Maritime history of Europe
Maritime Silk Road
Maritime timeline
Ming treasure voyages
Naval history of China
Polynesian navigation
Portuguese maritime exploration
Spanish colonization of the Americas
Timeline of European exploration
Timeline of prehistory
Timeline of the Ming treasure voyages
Treaty of Tordesillas
Voyages of Christopher Columbus
Subsections (0):
, Section: References (1):
References are included in the linked articles.


== External links ==
Subsections (0):
]"
15,"Category:Origins (id: 29739395, ns: 14)",0,Volatile (astrogeology),"Volatiles are the group of chemical elements and chemical compounds that can be readily vaporized. In contrast with volatiles, elements and compounds that are not readily vaporized are known as refractory substances.
On planet Earth, the term 'volatiles' often refers to the volatile components of magma. In astrogeology volatiles are investigated in the crust or atmosphere of a planet or moon. Volatiles include nitrogen, carbon dioxide, ammonia, hydrogen, methane, sulfur dioxide, water and others.","[Section: Planetary science (1):
Planetary scientists often classify volatiles with exceptionally low melting points, such as hydrogen and helium, as gases, whereas those volatiles with melting points above about 100 K (–173 °C, –280 °F) are referred to as ices. The terms ""gas"" and ""ice"" in this context can apply to compounds that may be solids, liquids or gases. Thus, Jupiter and Saturn are gas giants, and Uranus and Neptune are ice giants, even though the vast majority of the ""gas"" and ""ice"" in their interiors is a hot, highly dense fluid that gets denser as the center of the planet is approached. Inside of Jupiter's orbit, cometary activity is driven by the sublimation of water ice. Supervolatiles such as CO and CO2 have generated cometary activity as far out as 25.8 AU (3.86 billion km).
Subsections (0):
, Section: Igneous petrology (1):
In igneous petrology the term more specifically refers to the volatile components of magma (mostly water vapor and carbon dioxide) that affect the appearance and explosivity of volcanoes. Volatiles in a magma with a high viscosity, generally felsic with a higher silica (SiO2) content, tend to produce eruptions that are explosive eruption. Volatiles in a magma with a low viscosity, generally mafic with a lower silica content, tend to vent as effusive eruption and can give rise to a lava fountain.
Subsections (3):
Section: Volatiles in magma (2):
Some volcanic eruptions are explosive because of the mixing between water and magma reaching the surface, which releases energy suddenly. However, in some cases, the eruption is caused by volatiles dissolved in the magma itself. Approaching the surface, pressure decreases and the volatiles come out of solution, creating bubbles that circulate in the liquid. The bubbles become connected together, forming a network. This promotes the fragmentation into small drops or spray or coagulate clots in gas.
Generally, 95-99% of magma is liquid rock. However, the small percentage of gas present represents a very large volume when it expands on reaching atmospheric pressure. Gas is thus important in a volcano system because it generates explosive eruptions. Magma in the mantle and lower crust has a high volatile content. Water and carbon dioxide are not the only volatiles that volcanoes release; other volatiles include hydrogen sulfide and sulfur dioxide. Sulfur dioxide is common in basaltic and rhyolite rocks. Volcanoes also release a large amount of hydrogen chloride and hydrogen fluoride as volatiles.
Subsections (0):

Section: Solubility of volatiles (2):
There are three main factors that affect the dispersion of volatiles in magma: confining pressure, composition of magma, temperature of magma. Pressure and composition are the most important parameters. To understand how the magma behaves rising to the surface, the role of solubility within the magma must be known. An empirical law has been used for different magma-volatiles combination. For instance, for water in magma the equation is n=0.1078 P where n is the amount of dissolved gas as weight percentage (wt%), P is the pressure in megapascal (MPa) that acts on the magma. The value changes, for example for water in rhyolite n = 0.4111 P and for the carbon dioxide n = 0.0023 P. These simple equations work if there is only one volatile in a magma. However, in reality, the situation is not so simple because there are often multiple volatiles in a magma. It is a complex chemical interaction between different volatiles.
Simplifying, the solubility of water in rhyolite and basalt is function of pressure and depth below the surface in absence of other volatiles. Both basalt and rhyolite lose water with decreasing pressure as the magma rises to the surface. The solubility of water is higher in rhyolite than in basaltic magma. Knowledge of the solubility allows the determination of the maximum amount of water that might be dissolved in relation with pressure. If the magma contains less water than the maximum possible amount, it is undersaturated in water. Usually insufficient water and carbon dioxide exist in the deep crust and mantle, so magma is often undersaturated in these conditions. Magma becomes saturated when it reaches the maximum amount of water that can be dissolved in it. If the magma continues to rise up to the surface and more water is dissolved, it becomes supersaturated. If more water is dissolved in magma, it can be ejected as bubbles or water vapor. This happens because pressure decreases in the process and velocity increases and the process has to balance also between decrease of solubility and pressure. Making a comparison with the solubility of carbon dioxide in magma, this is considerably less than water and it tends to exsolve at greater depth. In this case water and carbon dioxide are considered independent. What affects the behavior of the magmatic system is the depth at which carbon dioxide and water are released. Low solubility of carbon dioxide means that it starts to release bubbles before reaching the magma chamber. The magma is at this point already supersaturated. The magma enriched in carbon dioxide bubbles, rises up to the roof of the chamber and carbon dioxide tends to leak through cracks into the overlying caldera. Basically, during an eruption the magma loses more carbon dioxide than water, that in the chamber is already supersaturated. Overall, water is the main volatile during an eruption.
Subsections (0):

Section: Nucleation of bubbles (2):
Bubble nucleation happens when the a volatile becomes saturated. Actually the bubbles are composed of molecules that tend to aggregate spontaneously in a process called homogeneous nucleation. The surface tension acts on the bubbles shrinking the surface and forces them back to the liquid. The nucleation process is greater when the space to fit is irregular and the volatile molecules can ease the effect of surface tension. The nucleation can occur thanks to the presence of solid crystals, which are stored in the magma chamber. They are perfect potential nucleation sites for bubbles. If there is no nucleation in the magma the bubbles formation might appear really late and magma becomes significantly supersaturated. The balance between supersaturation pressure and bubble's radii expressed by this equation: ∆P=2σ/r, where ∆P is 100 MPa and σ is the surface tension. If the nucleation starts later when the magma is very supersaturated, the distance between bubbles becomes smaller. Essentially if the magma rises rapidly to the surface, the system will be more out of equilibrium and supersaturated. When the magma rises there is competition between adding new molecules to the existing ones and creating new ones. The distance between molecules characterizes the efficiency of volatiles to aggregate to the new or existing site. Crystals inside magma can determine how bubbles grow and nucleate.
Subsections (0):
, Section: See also (1):
Cryovolcano
Ice
Subsections (0):
, Section: References (1):

Subsections (0):
, Section: External links (1):
Glossary of planetary astronomy terms
Volatiles of Costa Rican volcanoes.
Volatile Planetary Science Research Discoveries
Subsections (0):
]"
16,"Category:Origins (id: 29739395, ns: 14)",0,Origin of water on Earth,"The origin of water on Earth is the subject of a body of research in the fields of planetary science, astronomy, and astrobiology. Earth is unique among the rocky planets in the Solar System in having oceans of liquid water on its surface. Liquid water, which is necessary for all known forms of life, continues to exist on the surface of Earth because the planet is at a far enough distance (known as the habitable zone) from the Sun that it does not lose its water, but not so far that low temperatures cause all water on the planet to freeze.
It was long thought that Earth's water did not originate from the planet's region of the protoplanetary disk. Instead, it was hypothesized water and other volatiles must have been delivered to Earth from the outer Solar System later in its history. Recent research, however, indicates that hydrogen inside the Earth played a role in the formation of the ocean. The two ideas are not mutually exclusive, as there is also evidence that water was delivered to Earth by impacts from icy planetesimals similar in composition to asteroids in the outer edges of the asteroid belt.","[Section: History of water on Earth (1):
One factor in estimating when water appeared on Earth is that water is continually being lost to space. H2O molecules in the atmosphere are broken up by photolysis, and the resulting free hydrogen atoms can sometimes escape Earth's gravitational pull. When the Earth was younger and less massive, water would have been lost to space more easily. Lighter elements like hydrogen and helium are expected to leak from the atmosphere continually, but isotopic ratios of heavier noble gases in the modern atmosphere suggest that even the heavier elements in the early atmosphere were subject to significant losses. In particular, xenon is useful for calculations of water loss over time. Not only is it a noble gas (and therefore is not removed from the atmosphere through chemical reactions with other elements), but comparisons between the abundances of its nine stable isotopes in the modern atmosphere reveal that the Earth lost at least one ocean of water early in its history, between the Hadean and Archean eons.
Any water on Earth during the latter part of its accretion would have been disrupted by the Moon-forming impact (~4.5 billion years ago), which likely vaporized much of Earth's crust and upper mantle and created a rock-vapor atmosphere around the young planet. The rock vapor would have condensed within two thousand years, leaving behind hot volatiles which probably resulted in a majority carbon dioxide atmosphere with hydrogen and water vapor. Afterward, liquid water oceans may have existed despite the surface temperature of 230 °C (446 °F) due to the increased atmospheric pressure of the CO2 atmosphere. As the cooling continued, most CO2 was removed from the atmosphere by subduction and dissolution in ocean water, but levels oscillated wildly as new surface and mantle cycles appeared.

Geological evidence also helps constrain the time frame for liquid water existing on Earth. A sample of pillow basalt (a type of rock formed during an underwater eruption) was recovered from the Isua Greenstone Belt and provides evidence that water existed on Earth 3.8 billion years ago. In the Nuvvuagittuq Greenstone Belt, Quebec, Canada, rocks dated at 3.8 billion years old by one study and 4.28 billion years old by another show evidence of the presence of water at these ages. If oceans existed earlier than this, any geological evidence has yet to be discovered (which may be because such potential evidence has been destroyed by geological processes like crustal recycling). More recently, in August 2020, researchers reported that sufficient water to fill the oceans may have always been on the Earth since the beginning of the planet's formation.
Unlike rocks, minerals called zircons are highly resistant to weathering and geological processes and so are used to understand conditions on the very early Earth. Mineralogical evidence from zircons has shown that liquid water and an atmosphere must have existed 4.404 ± 0.008 billion years ago, very soon after the formation of Earth. This presents somewhat of a paradox, as the cool early Earth hypothesis suggests temperatures were cold enough to freeze water between about 4.4 billion and 4.0 billion years ago. Other studies of zircons found in Australian Hadean rock point to the existence of plate tectonics as early as 4 billion years ago. If true, that implies that rather than a hot, molten surface and an atmosphere full of carbon dioxide, early Earth's surface was much as it is today (in terms of thermal insulation). The action of plate tectonics traps vast amounts of CO2, thereby reducing greenhouse effects, leading to a much cooler surface temperature and the formation of solid rock and liquid water.
Subsections (0):
, Section: Earth's water inventory (1):
While the majority of Earth's surface is covered by oceans, those oceans make up just a small fraction of the mass of the planet. The mass of Earth's oceans is estimated to be 1.37 × 1021 kg, which is 0.023% of the total mass of Earth, 6.0 × 1024 kg. An additional 5.0 × 1020 kg of water is estimated to exist in ice, lakes, rivers, groundwater, and atmospheric water vapor. A significant amount of water is also stored in Earth's crust, mantle, and core. Unlike molecular H2O that is found on the surface, water in the interior exists primarily in hydrated minerals or as trace amounts of hydrogen bonded to oxygen atoms in anhydrous minerals. Hydrated silicates on the surface transport water into the mantle at convergent plate boundaries, where oceanic crust is subducted underneath continental crust. While it is difficult to estimate the total water content of the mantle due to limited samples, approximately three times the mass of the Earth's oceans could be stored there. Similarly, the Earth's core could contain four to five oceans' worth of hydrogen.
Subsections (0):
, Section: Hypotheses for the origins of Earth's water (1):

Subsections (1):
Section: Extraplanetary sources (2):
Water has a much lower condensation temperature than other materials that compose the terrestrial planets in the Solar System, such as iron and silicates. The region of the protoplanetary disk closest to the Sun was very hot early in the history of the Solar System, and it is not feasible that oceans of water condensed with the Earth as it formed. Further from the young Sun where temperatures were lower, water could condense and form icy planetesimals. The boundary of the region where ice could form in the early Solar System is known as the frost line (or snow line), and is located in the modern asteroid belt, between about 2.7 and 3.1 astronomical units (AU) from the Sun. It is therefore necessary that objects forming beyond the frost line–such as comets, trans-Neptunian objects, and water-rich meteoroids (protoplanets)–delivered water to Earth. However, the timing of this delivery is still in question.
One hypothesis claims that Earth accreted (gradually grew by accumulation of) icy planetesimals about 4.5 billion years ago, when it was 60 to 90% of its current size. In this scenario, Earth was able to retain water in some form throughout accretion and major impact events. This hypothesis is supported by similarities in the abundance and the isotope ratios of water between the oldest known carbonaceous chondrite meteorites and meteorites from Vesta, both of which originate from the Solar System's asteroid belt. It is also supported by studies of osmium isotope ratios, which suggest that a sizeable quantity of water was contained in the material that Earth accreted early on. Measurements of the chemical composition of lunar samples collected by the Apollo 15 and 17 missions further support this, and indicate that water was already present on Earth before the Moon was formed.
One problem with this hypothesis is that the noble gas isotope ratios of Earth's atmosphere are different from those of its mantle, which suggests they were formed from different sources. To explain this observation, a so-called ""late veneer"" theory has been proposed in which water was delivered much later in Earth's history, after the Moon-forming impact. However, the current understanding of Earth's formation allows for less than 1% of Earth's material accreting after the Moon formed, implying that the material accreted later must have been very water-rich. Models of early Solar System dynamics have shown that icy asteroids could have been delivered to the inner Solar System (including Earth) during this period if Jupiter migrated closer to the Sun.
Yet a third hypothesis, supported by evidence from molybdenum isotope ratios, suggests that the Earth gained most of its water from the same interplanetary collision that caused the formation of the Moon.
The evidence from 2019 shows that the molybdenum isotopic composition of the Earth's mantle originates from the outer Solar System, likely having brought water to Earth. The explanation is that Theia, the planet said in the giant-impact hypothesis to have collided with Earth 4.5 billion years ago forming the Moon, may have originated in the outer Solar System rather than in the inner Solar System, bringing water and carbon-based materials with it.
Subsections (0):
, Section: Geochemical analysis of water in the Solar System (1):
Isotopic ratios provide a unique ""chemical fingerprint"" that is used to compare Earth's water with reservoirs elsewhere in the Solar System. One such isotopic ratio, that of deuterium to hydrogen (D/H), is particularly useful in the search for the origin of water on Earth. Hydrogen is the most abundant element in the universe, and its heavier isotope deuterium can sometimes take the place of a hydrogen atom in molecules like H2O. Most deuterium was created in the Big Bang or in supernovae, so its uneven distribution throughout the protosolar nebula was effectively ""locked in"" early in the formation of the Solar System. By studying the different isotopic ratios of Earth and of other icy bodies in the Solar System, the likely origins of Earth's water can be researched.
Subsections (3):
Section: Earth (2):
The deuterium to hydrogen ratio for ocean water on Earth is known very precisely to be (1.5576 ± 0.0005) × 10−4. This value represents a mixture of all of the sources that contributed to Earth's reservoirs, and is used to identify the source or sources of Earth's water. The ratio of deuterium to hydrogen has increased over the Earth's lifetime between 2 to 9 times the ratio at the Earth's origin, because the lighter isotope is more likely to leak into space in atmospheric loss processes. Hydrogen beneath the Earth's crust is thought to have a D/H ratio more representative of the original D/H ratio upon formation of the Earth, because it is less affected by those processes. Analysis of subsurface hydrogen contained in recently released lava has been estimated to show that there was a 218‰ higher D/H ratio in the primordial Earth compared to the current ratio. No process is known that can decrease Earth's D/H ratio over time. This loss of the lighter isotope is one explanation for why Venus has such a high D/H ratio, as that planet's water was vaporized during the runaway greenhouse effect and subsequently lost much of its hydrogen to space. Because Earth's D/H ratio has increased significantly over time, the D/H ratio of water originally delivered to the planet was lower than at present. This is consistent with a scenario in which a significant proportion of the water on Earth was already present during the planet's early evolution.
Subsections (0):

Section: Asteroids (2):
Multiple geochemical studies have concluded that asteroids are most likely the primary source of Earth's water. Carbonaceous chondrites–which are a subclass of the oldest meteorites in the Solar System–have isotopic levels most similar to ocean water. The CI and CM subclasses of carbonaceous chondrites specifically have hydrogen and nitrogen isotope levels that closely match Earth's seawater, which suggests water in these meteorites could be the source of Earth's oceans. Two 4.5 billion-year-old meteorites found on Earth that contained liquid water alongside a wide diversity of deuterium-poor organic compounds further support this. Earth's current deuterium to hydrogen ratio also matches ancient eucrite chondrites, which originate from the asteroid Vesta in the outer asteroid belt. CI, CM, and eucrite chondrites are believed to have the same water content and isotope ratios as ancient icy protoplanets from the outer asteroid belt that later delivered water to Earth.
A further asteroid particle study supported the theory that a large source of earth's water has come from hydrogen atoms carried on particles in the solar wind which combine with oxygen on asteroids and then arrive on earth in space dust. Using atom probe tomography the study found hydroxide and water molecules on the surface of a single grain from particles retrieved from the asteroid 25143 Itokawa by the Japanese space probe Hayabusa.
Subsections (0):

Section: Comets (2):
Comets are kilometer-sized bodies made of dust and ice that originate from the Kuiper belt (20-50 AU) and the Oort cloud (>5,000 AU), but have highly elliptical orbits which bring them into the inner solar system. Their icy composition and trajectories which bring them into the inner solar system make them a target for remote and in situ measurements of D/H ratios.
It is implausible that Earth's water originated only from comets, since isotope measurements of the deuterium to hydrogen (D/H) ratio in comets Halley, Hyakutake, Hale–Bopp, 2002T7, and Tuttle, yield values approximately twice that of oceanic water. Using this cometary D/H ratio, models predict that less than 10% of Earth's water was supplied from comets.
Other, shorter period comets (<20 years) called Jupiter family comets likely originate from the Kuiper belt, but have had their orbital paths influenced by gravitational interactions with Jupiter or Neptune. 67P/Churyumov–Gerasimenko is one such comet that was the subject of isotopic measurements by the Rosetta spacecraft, which found the comet has a D/H ratio three times that of Earth's seawater. Another Jupiter family comet, 103P/Hartley 2, has a D/H ratio which is consistent with Earth's seawater, but its nitrogen isotope levels do not match Earth's.
Subsections (0):
, Section: See also (1):
Water on terrestrial planets of the Solar System
Subsections (0):
, Section: Notes (1):

Subsections (0):
, Section: References (1):

Subsections (0):
, Section: External links (1):
Dr. C's Ocean World: ""How the Oceans Formed"" (archived copy)
Nature journal: ""Earth has water older than the Sun""
Subsections (0):
]"
17,"Category:Origins (id: 29739395, ns: 14)",0,Zoonotic origins of COVID-19,"SARS-CoV-2, the causative agent of COVID-19, was first introduced to humans through zoonosis (transmission of a pathogen to a human from an animal), and a zoonotic spillover event is the origin of COVID-19 that is considered most plausible by the scientific community. Human coronaviruses including SARS-CoV-2 are zoonotic diseases that are often acquired through spillover infection from animals.","[Section: Background (1):
Previous emergence of SARS-CoV-1 and MERS-CoV showed that Betacoronaviruses represent a risk for emergence of diseases threatening to humans. Increased awareness due to the 2002–2004 SARS outbreak motivated research into the potential for other coronavirus outbreaks and the animal reservoirs which could lead to them. Bats, in particular, are known to harbor persistent populations of coronaviruses, and under conditions of persistent infection, coronaviruses tend to accumulate mutations that allow their receptor binding domains to interact with cross-species orthologs of the target receptors. Based on serological and molecular studies, Chinese horseshoe bats were identified as the most likely reservoir for SARS-CoV-1. Bats were also a likely reservoir for the related betacoronavirus MERS-CoV, though the evidence for this is less conclusive than the role of camels as a reservoir for MERS. By 2010, in vitro experiments had confirmed that modifications to the spike protein receptor binding domain could enable human infection by several SARS-related coronaviruses. Virologists Rachel Graham and Ralph S. Baric at that time wrote, ""that the question of emergence of another pathogenic human coronavirus from bat reservoirs might be more appropriately expressed as 'when' than as 'if'.""
Subsections (0):
, Section: Origin in bats (1):
The likely origin of SARS-CoV-2 from bats aligns with the origins of other coronaviruses in its genus Betacoronavirus, subgenus Sarbecovirus.  Several bat species have special cellular mechanisms to resist proinflammatory cytokines associated with Betacoronavirus virulence, for example, spike proteins in SARS-related coronaviruses coevolve with bat ACE2 receptors in an evolutionary arms race.

Bats, along with their viruses, have large overlapping geographic ranges in Southeast Asia, and there is a particularly great concentration and diversity of bat-related coronaviruses in Southern and Southwest China. The most similar known viruses to SARS-CoV-2 include bat coronaviruses RpYN06 with 94.5% identity, and RmYN02 with 93% identity RaTG13 was not the direct progenitor of SARS-CoV-2. Temmam et al. found no serological evidence for exposure to BANAL-52 among bat handlers and guano collectors in the area of Laos where it was sampled. Lytras et al. wrote that ""SARS-CoV-2 can be unambiguously traced to horseshoe bats"". They estimated SARS-CoV-2's most recent common ancestors with RmYN02 and RaTG13 to have diverged 40 and 50 years ago, respectively.
Subsections (0):
, Section: Novel features of SARS-CoV-2 (1):
The receptor binding domain of the SARS-CoV-2 spike protein has an insertion of amino acids between its S1 and S2 subunits. Among Sarbecoviruses, only SARS-CoV-2 and RmYN02 have such an insertion, suggesting differences in reservoir species, intermediate hosts, or evolutionary pathway. The receptor binding motif is the portion of SARS-CoV-2 that is most diverged from RaTG13. The SARS-CoV-2 receptor binding domain is more similar to those of pangolin coronaviruses. Viruses including BANAL-52 isolated from bats in Laos showed high similarity to the SARS-CoV-2 receptor binding domain in amino acid residues but less than 76.4% nucleotide identity across the spike protein. The observed binding of N-acetylneuraminic acid by the NTD of the spike protein and loss of that binding through mutation of the corresponding sugar binding pocket in emergent variants of concern has suggested a potential role for transient sugar-binding in the zoonosis of SARS-CoV-2, consistent with prior evolutionary proposals.
Within genus Betacoronavirus, furin cleavage sites are common in subgenera Merbecovirus and Embecovirus. Furin cleavage sites have independently evolved six times in different clades of Betacoronavirus. Furin cleavage sites also evolved in Alphacoronaviruses and Gammacoronaviruses independently of Betacoronavirus.

Furin cleavage contributes strongly to the transmissibility and pathogenicity of SARS-CoV-2 in humans. SARS-CoV-2 variants lacking the furin cleavage site are transmissible between humans, but much less effectively. The furin cleavage site is sometimes described as ""polybasic"" on account of its particular motif of basic amino acids. SARS-CoV-2 shares amino acid identity with a furin cleavage site of human ENaC α subunit. Human ENaC is identical only to that of a few great apes and Pipistrellus kuhli.
SARS-CoV-2 is also distinct among human coronaviruses for having a single intact ORF8 gene rather than ""a"" and ""b"" subunits.
Subsections (0):
, Section: Processes of host adaptation (1):
SARS-CoV-2 has an expanded host range compared to SARS-CoV-1 and MERS-CoV.  SARS-CoV-2 (along with SARS-CoV-1 and MERS-CoV) are generalist viruses, not specifically adapted to humans, meaning they have potential to spill over to many species and establish new natural reservoirs after adaptive evolutionary changes.
Within a single host, a variety of single-nucleotide variations arise through random mutations and genetic drift giving rise to viral quasispecies. SARS-CoV-2 mutates at a slower rate than is typical of RNA viruses. The main host-derived driver of mutation is editing by APOBEC proteins. Negative selection by host immune processes causes convergent evolution towards immune escape. Persistence of infection is correlated with quasispecies diversity, but the direction of causality for this is unknown.
Actual host susceptibility can differ significantly from in silico predictions. The process of host adaptation has been studied in humanized mice as well as by generating mouse-adapted viral strains through serial passage. Wild-type mice are only weakly susceptible to the original SARS-CoV-2 strain.
Subsections (3):
Section: Recombination (2):
Compared to other single-stranded RNA viruses, coronaviruses have increased tendency to undergo genetic recombination, which allows them to exchange genetic material with close relatives co-infecting the same organism. The origin of SARS-CoV-1 is believed to involve multiple recombination events. Recombination between strains of SARS-CoV-1 is common. Inferred phylogenies of SARS2-related coronaviruses might be explained by recombination. Recombination between various SARS-CoV-2 variants of concern has been reported.

Lytras et al. identified the SARS-CoV-2 spike open reading frame as a recombination hotspot. They speculate that the SARS-CoV-2 genome may involve repeated recombination events overprinting regions that were already themselves products of recombination. Temmam et al. wrote that due to the limited diffusion of bat viruses in mammals, co-infection required for recombination in mammals was unlikely. Therefore, they considered it more likely that the furin cleavage site arose in a bat reservoir prior to spillover.
Subsections (0):

Section: Selection (2):
After cross-species transmission of a virus, rapid evolution and positive selection are expected. Several studies found only weak signs of adaptive evolution early in the COVID-19 pandemic. Kang et al. wrote that SARS-CoV-2 had exhibited relatively little genetic variation by 2021. Tai et al. wrote that population expansion rather than positive selection explained the mutation frequency spectrum during the early pandemic. Cagliani et al. wrote that the SARS-CoV-2 genome overall shows evidence of ""strong to moderate"" purifying selection. Accessory open reading frames, especially ORF8, showed weak to neutral selection. The general lack of positive selection during the early outbreak of SARS-CoV-2 contrasted with the evolutionary course of SARS-CoV-1.

Strong evidence of positive selection was found however in the spike protein S1 subunit, which contains the receptor binding domain.
Genome instability in the spike protein is typical of coronaviruses in general, favoring the production of numerous spike protein variants. The receptor binding domain is a significant factor in host tropism, or the variety of species a virus can infect. Coronavirus adaptation to a new host often requires mutations in the receptor binding domain. Kang et al. identified a single nucleotide polymorphism relative to RaTG13 in the spike protein, consistent among all of more than 180,000 SARS-CoV-2 samples, affecting glycosylation of the receptor binding domain. Using a reverse genetics system to generate an ancestral-like mutant, they confirmed that the putative ancestral form of this SNP was much less transmissible in human cells.
Subsections (0):

Section: Host proteases (2):
The majority of sarbecoviruses are not dependent on ACE2 for cell entry. Guo et al. divide the sarbecoviruses into four clades, the first being ACE2-using respiratory viruses including SARS-CoV-1, SARS-CoV-2, and WIV1. Relative to clade 1, clades 3 and 4 have a one residue deletion in the receptor binding domain and diminished ability to use ACE2. Clade 2 has two deletions and does not interact with ACE2. Clades 2 through 4 are more difficult to isolate or propagate in cell culture, and consequently have been less studied. ACE2-independent infection by sarbecoviruses depends on high levels of trypsin, a digestive protein, in the host environment. Trypsin may compensate for other missing or compatible host proteases. The ubiquity of furin compared to tripsin would allow the gain of a furin cleavage site to expand viral tissue tropism. Guo et al. identified clade 1 and 2 sarbecoviruses in Rhinolophus fecal samples, suggesting that both types naturally replicate in the bat digestive tract. Bats with SARS-like infections in the wild showed no viral replication in respiratory droplets. A fecal-oral transmission is an alternative route for some respiratory viruses. No higher incidence of Sarbecoviruses has been reported in workers who come into direct contact with guano. Temmam et al. found that BANAL-236, a SARS-CoV-2-related virus isolated from bats in Laos, acts as an enteric virus in macaques.
Subsections (0):
, Section: Timing of spillover (1):
In contrast to SARS-CoV-1, the initial outbreak of SARS-CoV-2 was reported in only one city. Chinese epidemiological surveillance did not report any other pneumonia outbreaks in autumn 2019. Graham and Baric wrote that in the case of SARS-CoV-1, virus populations circulated and adapted to civets and humans over the course of two years before the recognized outbreak.
Subsections (0):
, Section: Reverse zoonosis (1):
Transmission of SARS-CoV-2 from humans to animals, known as reverse zoonosis or anthroponosis, is possible. Reverse zoonotic or experimental infection with SARS-CoV-2 has been reported in 31 animal species. It is not believed that wildlife plays a significant role in the ongoing circulation of SARS-CoV-2 among humans.

SARS-CoV-2 variants adapted to mink were found co-circulating among humans and farmed mink. Mink are the only animal in Europe or North America to experience widespread SARS-CoV-2 outbreaks. Transmission from human to mink has occurred multiple times, in most cases not resulting in a sustained mink outbreak. Strong evidence was seen of positive selection in mink after spillover, concentrated in the receptor binding motif.
Transmission back to humans has been documented for mink, hamsters, and cats. Transmission to humans from deer is suspected. Transmission of SARS-CoV-2 among domestic cats has been confirmed.
Li et al. wrote that SARS-CoV-2 may be less able than SARS-CoV-1 to pass from humans to animals.
Subsections (0):
, Section: Hypothesized intermediate hosts (1):
In the outbreak of SARS-CoV-1, palm civets, raccoon dogs, ferret badgers, red foxes, domestic cats, and rice field rats were possible vectors. Graham and Baric wrote that human and civet infections likely stemmed from an unknown common progenitor. Patrick Berche wrote that the emergences of SARS-CoV-1 and MERS-CoV appeared to be sequential processes involving intermediate hosts, co-infections, and recombination. In contrast with the rapid identification of animal hosts for SARS-CoV-1 and MERS-CoV, no direct animal source for SARS-CoV-2 has been found. Holmes et al. wrote that the lack of intermediate host is likely because the right animal has not been tested so far. Frutos et al. proposed that rather than a discrete spillover event, SARS-CoV-2 arose in accordance with a circulation model, involving repeated horizontal transfer among humans, bats, and other mammals without establishing significant reservoirs in any of them until the pandemic.

Pangolins have been considered a possible reservoir of SARS-CoV-2. Pangolins are sometimes sold in wet markets in China, where they are considered a culinary delicacy and a component of traditional medicine. The highest sequence similarity to the SARS-CoV-2 spike receptor binding domain was found in a coronavirus infecting Sunda pangolins in Guangdong province. Pangolins are frequently smuggled to China. Lytras et al. wrote that, consistent with a lack of reported infections of pangolins in Malaysia, they were likely infected after being trafficked into China.
The SARS-CoV-2 receptor binding domain shares more synonymous substitutions with a pangolin-CoV than RaTG13. The binding potential of SARS-CoV-2 to pangolin ACE2 however is very low. The receptor binding domain of SARS-CoV-2 has been hypothesized to originate from recombination of the relevant portion of pangolin-CoV with an RaTG13-like virus.
Deer mice are highly susceptible to SARS-CoV-2, making them potential reservoir or intermediate hosts.
Raccoon dogs could be capable of transmitting SARS-CoV-2 to other animals under farm-like conditions. Transmission between raccoon dogs was shown under laboratory conditions.
White-tailed deer are a potential vector for SARS-CoV-2.
Subsections (0):
, Section: Wet market hypothesis (1):
Spillover has been proposed to have occurred at one or more wet markets in China. Wild and semi-wild game animals are commonly traded and consumed in China, and this practice has expanded in recent decades. The close contact among animals in unsanitary conditions creates the potential for diseases to thrive. In the 2002 outbreak in Guangdong, most living animals in the markets showed serological evidence of exposure to SARS-CoV-1.

Many early cases were associated with the Huanan seafood market in Wuhan. The first documented COVID-19 infection was in a worker at a seafood stall in the Huanan market. Sequences from that patient have not been published; however, SARS-CoV-2 belonging to lineage B/L were detected in environmental samples from the patient's stall. No bats or pangolins were reported to be at the market between May 2017 and November 2019. Raccoon dogs, which are hypothesized to be succeptible to SARS-CoV-2, were at the market. A survey by He et al. in 2021 identified 102 mammal-affecting viruses in Chinese game animals, 65 of which were identified then for the first time. They did not find any SARS-like viruses, but did find evidence for the transmission of a MERS-like virus from bats to hedgehogs.
Between January 1 and March 30, epidemiologists from China CDC collected 457 samples from animal matter including carcasses and feces and collected 923 environmental samples. All animal samples tested negative for SARS-CoV-2. SARS-CoV-2 was found in 73 environmental samples. Live virus was isolated from three samples, two of which came from stalls belonging to known patients. No significant association was found between environmental virus titer and the type of product sold at particular stalls. SARS-CoV-2 was identified in all four sewer wells in the market. Overground drainage from the surrounding area concentrated under the market.
One environmental sample contained lineage A/S SARS-CoV-2, while all others belonged to lineage B/L. The sample containing lineage A/S also contained evidence of humans and livestock, but no wild animals. Overall, wildlife including racoon dogs were detected at very low levels and mostly associated with negative samples. Liu et al. wrote that there was not enough information to determine the origin of the virus. In particular, they wrote that the evidence does not prove the presence of an infected raccoon dog or the occurrence of multiple zoonotic spillovers at the market as proposed by Pekar et al.
Subsections (0):
, Section: Origins of variants (1):
The World Health Organization defines variants of concern as a variant with evidence of increase transmissibility, severity, or immune escape. All variants of concern so far independently evolved from the original strain, rather than from each other.
The evolution of the Omicron variant appeared to be more rapid than other variants. Theories for the origin of the omicron variant include long-term circulation among humans outside areas where genetic surveillance was performed, mutation in an immunocompromised individual, or adaptation in an animal species after reverse zoonosis. The Omicron variant is proposed to have originated in mice.
Subsections (0):
, Section: Notes (1):

Subsections (0):
, Section: References (1):

Subsections (1):
Section: Citations (2):


=== Bibliography ===
Subsections (0):
]"
18,"Category:Origins (id: 29739395, ns: 14)",0,Category:AIDS origin hypotheses,,[]
19,"Category:Origins (id: 29739395, ns: 14)",0,Category:Beginnings,,[]
20,"Category:Origins (id: 29739395, ns: 14)",0,Category:Causes of conditions,,[]
21,"Category:Origins (id: 29739395, ns: 14)",0,Category:Causes of events,"==== Category:Causes of events ====
Propose renaming Category:Causes of events to Category:Causes of events by type of event
Nominator's rationale: This category should be renamed. The name evokes to find here causes of events but there are Causes of events by type of event! W like wiki good to know 03:37, 30 January 2022 (UTC)",[]
22,"Category:Origins (id: 29739395, ns: 14)",0,Category:Cradle of civilization,"Articles relating to areas regarded as the cradle of civilization, any location where civilization is understood to have independently emerged. The term has frequently been applied to a variety of regions, in particular to Ancient India, Ancient China, the Ancient Near East, which contained the Fertile Crescent, and the pre-Columbian Peru and Mesoamerica.",[]
23,"Category:Origins (id: 29739395, ns: 14)",0,Category:Cosmogony,,[]
24,"Category:Origins (id: 29739395, ns: 14)",0,Category:Creators of sports,,[]
25,"Category:Origins (id: 29739395, ns: 14)",0,Category:Creators of writing systems,,[]
26,"Category:Origins (id: 29739395, ns: 14)",0,Category:Etymology,"Etymology is the study of the history of words, their origins, and how their form and meaning have changed over time.",[]
27,"Category:Origins (id: 29739395, ns: 14)",0,Category:Evolution,"Evolution is any process of growth or development that entails change. The word stems from the Latin evolutio meaning ""unfolding"" and before the late 19th century was confined to referring to goal-directed, pre-programmed processes such as embryological development. A pre-programmed task, as in a military maneuver, using this definition, may be termed an ""evolution."" After the publication of Charles Darwin's The Origin of Species in 1859, ""evolution"" became primarily associated with biological evolution as a non-guided process for the differentiation of forms of life from a common ancestor. Evolution can also refer to stellar evolution, chemical evolution, cultural evolution, spiritual evolution or the evolution of an idea. Other kinds of evolution include evolutionary algorithms (which include genetic algorithms) which attempt to mimic processes similar to biological evolution in a computer program, most frequently as an optimization technique and as an experimental framework for the computational modelling of evolution. It is also invoked as a concept in ideas on emergent order.",[]
28,"Category:Origins (id: 29739395, ns: 14)",0,Category:Genealogy,,[]
29,"Category:Origins (id: 29739395, ns: 14)",0,Category:Intention,This category is for articles which deal with the concept of intention or intentional behavior.,[]
30,"Category:Origins (id: 29739395, ns: 14)",0,Category:Origins of Islam,,[]
31,"Category:Origins (id: 29739395, ns: 14)",0,Category:Languages by origin,This is a category for genealogical groups of languages.,[]
32,"Category:Origins (id: 29739395, ns: 14)",0,Category:Origin of life,Abiogenesis or biopoiesis is the natural process of life arising from non-living matter such as simple organic compounds.,[]
33,"Category:Origins (id: 29739395, ns: 14)",0,Category:Origins of music genres,,[]
34,"Category:Origins (id: 29739395, ns: 14)",0,Category:Origin myths,"Articles relating to origin myths, a type of myth that explains the beginnings of a natural or social aspect of the world. One specific kind of origin myth is the creation or cosmogonic myth, which narrates the formation of the universe. However, numerous cultures have stories that take place after the initial origin.",[]
35,"Category:Origins (id: 29739395, ns: 14)",0,Category:Origin stories,,[]
36,"Category:Origins (id: 29739395, ns: 14)",0,Category:Works by source,,[]
37,"Category:Origins (id: 29739395, ns: 14)",0,Category:Writing systems by origin,,[]
